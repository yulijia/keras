## Autogenerated. Do not modify manually.


# <class 'keras.src.layers.rnn.abstract_rnn_cell.AbstractRNNCell'>
#' Abstract object representing an RNN cell
#'
#' @details
#' See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)
#' for details about the usage of RNN API.
#'
#' This is the base class for implementing RNN cells with custom behavior.
#'
#' Every `RNNCell` must have the properties below and implement `call` with
#' the signature `(output, next_state) = call(input, state)`.
#'
#' ```python
#'   class MinimalRNNCell(AbstractRNNCell):
#'
#'     def __init__(self, units, **kwargs):
#'       self.units = units
#'       super(MinimalRNNCell, self).__init__(**kwargs)
#'
#'     @property
#'     def state_size(self):
#'       return self.units
#'
#'     def build(self, input_shape):
#'       self.kernel = self.add_weight(shape=(input_shape[-1], self.units),
#'                                     initializer='uniform',
#'                                     name='kernel')
#'       self.recurrent_kernel = self.add_weight(
#'           shape=(self.units, self.units),
#'           initializer='uniform',
#'           name='recurrent_kernel')
#'       self.built = TRUE
#'
#'     def call(self, inputs, states):
#'       prev_output = states[0]
#'       h = backend.dot(inputs, self.kernel)
#'       output = h + backend.dot(prev_output, self.recurrent_kernel)
#'       return output, output
#' ```
#'
#' This definition of cell differs from the definition used in the literature.
#' In the literature, 'cell' refers to an object with a single scalar output.
#' This definition refers to a horizontal array of such units.
#'
#' An RNN cell, in the most abstract setting, is anything that has
#' a state and performs some operation that takes a matrix of inputs.
#' This operation results in an output matrix with `self.output_size` columns.
#' If `self.state_size` is an integer, this operation also results in a new
#' state matrix with `self.state_size` columns.  If `self.state_size` is a
#' (possibly nested list of) TensorShape object(s), then it should return a
#' matching structure of Tensors having shape `[batch_size].concatenate(s)`
#' for each `s` in `self.batch_size`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_abstract_rnn_cell <-
function(...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape))
    do.call(keras$layers$AbstractRNNCell, args)
}


# <class 'keras.src.layers.core.activation.Activation'>
#' Applies an activation function to an output
#'
#' @details
#'
#' Usage:
#'
#' ```python
#' >>> layer = tf.keras.layers.Activation('relu')
#' >>> output = layer([-3.0, -1.0, 0.0, 2.0])
#' >>> list(output.numpy())
#' [0.0, 0.0, 0.0, 2.0]
#' >>> layer = tf.keras.layers.Activation(tf.nn.relu)
#' >>> output = layer([-3.0, -1.0, 0.0, 2.0])
#' >>> list(output.numpy())
#' [0.0, 0.0, 0.0, 2.0]
#' ```
#'
#' Input shape:
#'   Arbitrary. Use the keyword argument `input_shape`
#'   (list of integers, does not include the batch axis)
#'   when using this layer as the first layer in a model.
#'
#' Output shape:
#'   Same shape as input.
#'
#' @param activation
#' Activation function, such as `tf.nn.relu`, or string name of
#' built-in activation function, such as "relu".
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_activation <-
function(object, activation, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$Activation, object, args)
}


# <class 'keras.src.layers.regularization.activity_regularization.ActivityRegularization'>
#' Layer that applies an update to the cost function based input activity
#'
#' @details
#'
#' Input shape:
#'   Arbitrary. Use the keyword argument `input_shape`
#'   (list of integers, does not include the samples axis)
#'   when using this layer as the first layer in a model.
#'
#' Output shape:
#'   Same shape as input.
#'
#' @param l1
#' L1 regularization factor (positive float).
#'
#' @param l2
#' L2 regularization factor (positive float).
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_activity_regularization <-
function(object, l1 = 0, l2 = 0, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$ActivityRegularization, object,
        args)
}


# <class 'keras.src.layers.merging.add.Add'>
#' Layer that adds a list of inputs
#'
#' @details
#' It takes as input a list of tensors,
#' all of the same shape, and returns
#' a single tensor (also of the same shape).
#'
#' ```python
#' >>> input_shape = (2, 3, 4)
#' >>> x1 = tf.random.normal(input_shape)
#' >>> x2 = tf.random.normal(input_shape)
#' >>> y = tf.keras.layers.Add()([x1, x2])
#' >>> print(y.shape)
#' (2, 3, 4)
#' ```
#'
#' Used in a functional model:
#'
#' ```python
#' >>> input1 = tf.keras.layers.Input(shape=(16,))
#' >>> x1 = tf.keras.layers.Dense(8, activation='relu')(input1)
#' >>> input2 = tf.keras.layers.Input(shape=(32,))
#' >>> x2 = tf.keras.layers.Dense(8, activation='relu')(input2)
#' >>> # equivalent to `added = tf.keras.layers.add([x1, x2])`
#' >>> added = tf.keras.layers.Add()([x1, x2])
#' >>> out = tf.keras.layers.Dense(4)(added)
#' >>> model = tf.keras.models.Model(inputs=[input1, input2], outputs=out)
#' ```
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_add <-
function(inputs, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = c("...", "inputs"))
    dots <- split_dots_named_unnamed(list(...))
    if (missing(inputs))
        inputs <- NULL
    else if (!is.null(inputs) && !is.list(inputs))
        inputs <- list(inputs)
    inputs <- c(inputs, dots$unnamed)
    args <- c(args, dots$named)
    layer <- do.call(keras$layers$Add, args)
    if (length(inputs))
        layer(inputs)
    else layer
}


# <class 'keras.src.layers.attention.additive_attention.AdditiveAttention'>
#' Additive attention layer, a.k.a. Bahdanau-style attention
#'
#' @details
#' Inputs are `query` tensor of shape `[batch_size, Tq, dim]`, `value` tensor
#' of shape `[batch_size, Tv, dim]` and `key` tensor of shape
#' `[batch_size, Tv, dim]`. The calculation follows the steps:
#'
#' 1. Reshape `query` and `key` into shapes `[batch_size, Tq, 1, dim]`
#'     and `[batch_size, 1, Tv, dim]` respectively.
#' 2. Calculate scores with shape `[batch_size, Tq, Tv]` as a non-linear
#'     sum: `scores = tf.reduce_sum(tf.tanh(query + key), axis=-1)`
#' 3. Use scores to calculate a distribution with shape
#'     `[batch_size, Tq, Tv]`: `distribution = tf.nn.softmax(scores)`.
#' 4. Use `distribution` to create a linear combination of `value` with
#'     shape `[batch_size, Tq, dim]`:
#'    `return tf.matmul(distribution, value)`.
#'
#' Call arguments:
#'     inputs: List of the following tensors:
#'         * query: Query `Tensor` of shape `[batch_size, Tq, dim]`.
#'         * value: Value `Tensor` of shape `[batch_size, Tv, dim]`.
#'         * key: Optional key `Tensor` of shape `[batch_size, Tv, dim]`.
#'             If not given, will use `value` for both `key` and `value`,
#'             which is the most common case.
#'     mask: List of the following tensors:
#'         * query_mask: A boolean mask `Tensor` of shape `[batch_size, Tq]`.
#'             If given, the output will be zero at the positions where
#'             `mask==FALSE`.
#'         * value_mask: A boolean mask `Tensor` of shape `[batch_size, Tv]`.
#'             If given, will apply the mask such that values at positions
#'             where `mask==FALSE` do not contribute to the result.
#'     training: Python boolean indicating whether the layer should behave in
#'         training mode (adding dropout) or in inference mode (no dropout).
#'     return_attention_scores: bool, it `TRUE`, returns the attention scores
#'         (after masking and softmax) as an additional output argument.
#'     use_causal_mask: Boolean. Set to `TRUE` for decoder self-attention. Adds
#'         a mask such that position `i` cannot attend to positions `j > i`.
#'         This prevents the flow of information from the future towards the
#'         past. Defaults to `FALSE`.
#'
#' Output:
#'
#'     Attention outputs of shape `[batch_size, Tq, dim]`.
#'     [Optional] Attention scores after masking and softmax with shape
#'         `[batch_size, Tq, Tv]`.
#'
#' The meaning of `query`, `value` and `key` depend on the application. In the
#' case of text similarity, for example, `query` is the sequence embeddings of
#' the first piece of text and `value` is the sequence embeddings of the second
#' piece of text. `key` is usually the same tensor as `value`.
#'
#' Here is a code example for using `AdditiveAttention` in a CNN+Attention
#' network:
#'
#' ```python
#' # Variable-length int sequences.
#' query_input = tf.keras.Input(shape=(NULL,), dtype='int32')
#' value_input = tf.keras.Input(shape=(NULL,), dtype='int32')
#'
#' # Embedding lookup.
#' token_embedding = tf.keras.layers.Embedding(max_tokens, dimension)
#' # Query embeddings of shape [batch_size, Tq, dimension].
#' query_embeddings = token_embedding(query_input)
#' # Value embeddings of shape [batch_size, Tv, dimension].
#' value_embeddings = token_embedding(value_input)
#'
#' # CNN layer.
#' cnn_layer = tf.keras.layers.Conv1D(
#'     filters=100,
#'     kernel_size=4,
#'     # Use 'same' padding so outputs have the same shape as inputs.
#'     padding='same')
#' # Query encoding of shape [batch_size, Tq, filters].
#' query_seq_encoding = cnn_layer(query_embeddings)
#' # Value encoding of shape [batch_size, Tv, filters].
#' value_seq_encoding = cnn_layer(value_embeddings)
#'
#' # Query-value attention of shape [batch_size, Tq, filters].
#' query_value_attention_seq = tf.keras.layers.AdditiveAttention()(
#'     [query_seq_encoding, value_seq_encoding])
#'
#' # Reduce over the sequence axis to produce encodings of shape
#' # [batch_size, filters].
#' query_encoding = tf.keras.layers.GlobalAveragePooling1D()(
#'     query_seq_encoding)
#' query_value_attention = tf.keras.layers.GlobalAveragePooling1D()(
#'     query_value_attention_seq)
#'
#' # Concatenate query and document encodings to produce a DNN input layer.
#' input_layer = tf.keras.layers.Concatenate()(
#'     [query_encoding, query_value_attention])
#'
#' # Add DNN layers, and create Model.
#' # ...
#' ```
#'
#' @param use_scale
#' If `TRUE`, will create a variable to scale the attention
#' scores.
#'
#' @param dropout
#' Float between 0 and 1. Fraction of the units to drop for the
#' attention scores. Defaults to `0.0`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_additive_attention <-
function(object, use_scale = TRUE, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$AdditiveAttention, object, args)
}


# <class 'keras.src.layers.regularization.alpha_dropout.AlphaDropout'>
#' Applies Alpha Dropout to the input
#'
#' @details
#' Alpha Dropout is a `Dropout` that keeps mean and variance of inputs
#' to their original values, in order to ensure the self-normalizing property
#' even after this dropout.
#' Alpha Dropout fits well to Scaled Exponential Linear Units
#' by randomly setting activations to the negative saturation value.
#'
#' Call arguments:
#'   inputs: Input tensor (of any rank).
#'   training: Python boolean indicating whether the layer should behave in
#'     training mode (adding dropout) or in inference mode (doing nothing).
#'
#' Input shape:
#'   Arbitrary. Use the keyword argument `input_shape`
#'   (list of integers, does not include the samples axis)
#'   when using this layer as the first layer in a model.
#'
#' Output shape:
#'   Same shape as input.
#'
#' @param rate
#' float, drop probability (as with `Dropout`).
#' The multiplicative noise will have
#' standard deviation `sqrt(rate / (1 - rate))`.
#'
#' @param seed
#' Integer, optional random seed to enable deterministic behavior.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_alpha_dropout <-
function(object, rate, noise_shape = NULL, seed = NULL, ...)
{
    args <- capture_args(match.call(), list(seed = as_nullable_integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$AlphaDropout, object, args)
}


# <class 'keras.src.layers.attention.attention.Attention'>
#' Dot-product attention layer, a.k.a. Luong-style attention
#'
#' @details
#' Inputs are `query` tensor of shape `[batch_size, Tq, dim]`, `value` tensor
#' of shape `[batch_size, Tv, dim]` and `key` tensor of shape
#' `[batch_size, Tv, dim]`. The calculation follows the steps:
#'
#' 1. Calculate scores with shape `[batch_size, Tq, Tv]` as a `query`-`key` dot
#'     product: `scores = tf.matmul(query, key, transpose_b=TRUE)`.
#' 2. Use scores to calculate a distribution with shape
#'     `[batch_size, Tq, Tv]`: `distribution = tf.nn.softmax(scores)`.
#' 3. Use `distribution` to create a linear combination of `value` with
#'      shape `[batch_size, Tq, dim]`:
#'      `return tf.matmul(distribution, value)`.
#'
#' Call arguments:
#'     inputs: List of the following tensors:
#'         * query: Query `Tensor` of shape `[batch_size, Tq, dim]`.
#'         * value: Value `Tensor` of shape `[batch_size, Tv, dim]`.
#'         * key: Optional key `Tensor` of shape `[batch_size, Tv, dim]`. If
#'             not given, will use `value` for both `key` and `value`, which is
#'             the most common case.
#'     mask: List of the following tensors:
#'         * query_mask: A boolean mask `Tensor` of shape `[batch_size, Tq]`.
#'             If given, the output will be zero at the positions where
#'             `mask==FALSE`.
#'         * value_mask: A boolean mask `Tensor` of shape `[batch_size, Tv]`.
#'             If given, will apply the mask such that values at positions
#'              where `mask==FALSE` do not contribute to the result.
#'     return_attention_scores: bool, it `TRUE`, returns the attention scores
#'         (after masking and softmax) as an additional output argument.
#'     training: Python boolean indicating whether the layer should behave in
#'         training mode (adding dropout) or in inference mode (no dropout).
#'     use_causal_mask: Boolean. Set to `TRUE` for decoder self-attention. Adds
#'         a mask such that position `i` cannot attend to positions `j > i`.
#'         This prevents the flow of information from the future towards the
#'         past.
#'         Defaults to `FALSE`.
#'
#' Output:
#'
#'     Attention outputs of shape `[batch_size, Tq, dim]`.
#'     [Optional] Attention scores after masking and softmax with shape
#'         `[batch_size, Tq, Tv]`.
#'
#' The meaning of `query`, `value` and `key` depend on the application. In the
#' case of text similarity, for example, `query` is the sequence embeddings of
#' the first piece of text and `value` is the sequence embeddings of the second
#' piece of text. `key` is usually the same tensor as `value`.
#'
#' Here is a code example for using `Attention` in a CNN+Attention network:
#'
#' ```python
#' # Variable-length int sequences.
#' query_input = tf.keras.Input(shape=(NULL,), dtype='int32')
#' value_input = tf.keras.Input(shape=(NULL,), dtype='int32')
#'
#' # Embedding lookup.
#' token_embedding = tf.keras.layers.Embedding(input_dim=1000, output_dim=64)
#' # Query embeddings of shape [batch_size, Tq, dimension].
#' query_embeddings = token_embedding(query_input)
#' # Value embeddings of shape [batch_size, Tv, dimension].
#' value_embeddings = token_embedding(value_input)
#'
#' # CNN layer.
#' cnn_layer = tf.keras.layers.Conv1D(
#'     filters=100,
#'     kernel_size=4,
#'     # Use 'same' padding so outputs have the same shape as inputs.
#'     padding='same')
#' # Query encoding of shape [batch_size, Tq, filters].
#' query_seq_encoding = cnn_layer(query_embeddings)
#' # Value encoding of shape [batch_size, Tv, filters].
#' value_seq_encoding = cnn_layer(value_embeddings)
#'
#' # Query-value attention of shape [batch_size, Tq, filters].
#' query_value_attention_seq = tf.keras.layers.Attention()(
#'     [query_seq_encoding, value_seq_encoding])
#'
#' # Reduce over the sequence axis to produce encodings of shape
#' # [batch_size, filters].
#' query_encoding = tf.keras.layers.GlobalAveragePooling1D()(
#'     query_seq_encoding)
#' query_value_attention = tf.keras.layers.GlobalAveragePooling1D()(
#'     query_value_attention_seq)
#'
#' # Concatenate query and document encodings to produce a DNN input layer.
#' input_layer = tf.keras.layers.Concatenate()(
#'     [query_encoding, query_value_attention])
#'
#' # Add DNN layers, and create Model.
#' # ...
#' ```
#'
#' @param use_scale
#' If `TRUE`, will create a scalar variable to scale the
#' attention scores.
#'
#' @param dropout
#' Float between 0 and 1. Fraction of the units to drop for the
#' attention scores. Defaults to 0.0.
#'
#' @param score_mode
#' Function to use to compute attention scores, one of
#' `{"dot", "concat"}`. `"dot"` refers to the dot product between the
#' query and key vectors. `"concat"` refers to the hyperbolic tangent
#' of the concatenation of the query and key vectors.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_attention <-
function(object, use_scale = FALSE, score_mode = "dot", ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$Attention, object, args)
}


# <class 'keras.src.layers.merging.average.Average'>
#' Layer that averages a list of inputs element-wise
#'
#' @details
#' It takes as input a list of tensors, all of the same shape, and returns
#' a single tensor (also of the same shape).
#'
#' Example:
#'
#' ```python
#' >>> x1 = np.ones((2, 2))
#' >>> x2 = np.zeros((2, 2))
#' >>> y = tf.keras.layers.Average()([x1, x2])
#' >>> y.numpy().tolist()
#' [[0.5, 0.5], [0.5, 0.5]]
#' ```
#'
#' Usage in a functional model:
#'
#' ```python
#' >>> input1 = tf.keras.layers.Input(shape=(16,))
#' >>> x1 = tf.keras.layers.Dense(8, activation='relu')(input1)
#' >>> input2 = tf.keras.layers.Input(shape=(32,))
#' >>> x2 = tf.keras.layers.Dense(8, activation='relu')(input2)
#' >>> avg = tf.keras.layers.Average()([x1, x2])
#' >>> out = tf.keras.layers.Dense(4)(avg)
#' >>> model = tf.keras.models.Model(inputs=[input1, input2], outputs=out)
#' ```
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_average <-
function(inputs, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = c("...", "inputs"))
    dots <- split_dots_named_unnamed(list(...))
    if (missing(inputs))
        inputs <- NULL
    else if (!is.null(inputs) && !is.list(inputs))
        inputs <- list(inputs)
    inputs <- c(inputs, dots$unnamed)
    args <- c(args, dots$named)
    layer <- do.call(keras$layers$Average, args)
    if (length(inputs))
        layer(inputs)
    else layer
}


# <class 'keras.src.layers.pooling.average_pooling1d.AveragePooling1D'>
#' Average pooling for temporal data
#'
#' @details
#' Downsamples the input representation by taking the average value over the
#' window defined by `pool_size`. The window is shifted by `strides`.  The
#' resulting output when using "valid" padding option has a shape of:
#' `output_shape = (input_shape - pool_size + 1) / strides)`
#'
#' The resulting output shape when using the "same" padding option is:
#' `output_shape = input_shape / strides`
#'
#' For example, for strides=1 and padding="valid":
#'
#' ```python
#' >>> x = tf.constant([1., 2., 3., 4., 5.])
#' >>> x = tf.reshape(x, [1, 5, 1])
#' >>> x
#' <tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=
#'   array([[[1.],
#'           [2.],
#'           [3.],
#'           [4.],
#'           [5.]], dtype=float32)>
#' >>> avg_pool_1d = tf.keras.layers.AveragePooling1D(pool_size=2,
#' ...    strides=1, padding='valid')
#' >>> avg_pool_1d(x)
#' <tf.Tensor: shape=(1, 4, 1), dtype=float32, numpy=
#' array([[[1.5],
#'         [2.5],
#'         [3.5],
#'         [4.5]]], dtype=float32)>
#' ```
#'
#' For example, for strides=2 and padding="valid":
#'
#' ```python
#' >>> x = tf.constant([1., 2., 3., 4., 5.])
#' >>> x = tf.reshape(x, [1, 5, 1])
#' >>> x
#' <tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=
#'   array([[[1.],
#'           [2.],
#'           [3.],
#'           [4.],
#'           [5.]], dtype=float32)>
#' >>> avg_pool_1d = tf.keras.layers.AveragePooling1D(pool_size=2,
#' ...    strides=2, padding='valid')
#' >>> avg_pool_1d(x)
#' <tf.Tensor: shape=(1, 2, 1), dtype=float32, numpy=
#' array([[[1.5],
#'         [3.5]]], dtype=float32)>
#' ```
#'
#' For example, for strides=1 and padding="same":
#'
#' ```python
#' >>> x = tf.constant([1., 2., 3., 4., 5.])
#' >>> x = tf.reshape(x, [1, 5, 1])
#' >>> x
#' <tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=
#'   array([[[1.],
#'           [2.],
#'           [3.],
#'           [4.],
#'           [5.]], dtype=float32)>
#' >>> avg_pool_1d = tf.keras.layers.AveragePooling1D(pool_size=2,
#' ...    strides=1, padding='same')
#' >>> avg_pool_1d(x)
#' <tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=
#' array([[[1.5],
#'         [2.5],
#'         [3.5],
#'         [4.5],
#'         [5.]]], dtype=float32)>
#' ```
#'
#' Input shape:
#'   - If `data_format='channels_last'`:
#'     3D tensor with shape `(batch_size, steps, features)`.
#'   - If `data_format='channels_first'`:
#'     3D tensor with shape `(batch_size, features, steps)`.
#'
#' Output shape:
#'   - If `data_format='channels_last'`:
#'     3D tensor with shape `(batch_size, downsampled_steps, features)`.
#'   - If `data_format='channels_first'`:
#'     3D tensor with shape `(batch_size, features, downsampled_steps)`.
#'
#' @param pool_size
#' Integer, size of the average pooling windows.
#'
#' @param strides
#' Integer, or NULL. Factor by which to downscale.
#' E.g. 2 will halve the input.
#' If NULL, it will default to `pool_size`.
#'
#' @param padding
#' One of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding evenly to
#' the left/right or up/down of the input such that output has the same
#' height/width dimension as the input.
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch, steps, features)` while `channels_first`
#' corresponds to inputs with shape
#' `(batch, features, steps)`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_average_pooling_1d <-
function(object, pool_size = 2L, strides = NULL, padding = "valid",
    data_format = "channels_last", ...)
{
    args <- capture_args(match.call(), list(pool_size = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape, strides = as_nullable_integer),
        ignore = "object")
    create_layer(keras$layers$AveragePooling1D, object, args)
}


# <class 'keras.src.layers.pooling.average_pooling2d.AveragePooling2D'>
#' Average pooling operation for spatial data
#'
#' @details
#' Downsamples the input along its spatial dimensions (height and width)
#' by taking the average value over an input window
#' (of size defined by `pool_size`) for each channel of the input.
#' The window is shifted by `strides` along each dimension.
#'
#' The resulting output when using `"valid"` padding option has a shape
#' (number of rows or columns) of:
#' `output_shape = math.floor((input_shape - pool_size) / strides) + 1`
#' (when `input_shape >= pool_size`)
#'
#' The resulting output shape when using the `"same"` padding option is:
#' `output_shape = math.floor((input_shape - 1) / strides) + 1`
#'
#' For example, for `strides=(1, 1)` and `padding="valid"`:
#'
#' ```python
#' >>> x = tf.constant([[1., 2., 3.],
#' ...                  [4., 5., 6.],
#' ...                  [7., 8., 9.]])
#' >>> x = tf.reshape(x, [1, 3, 3, 1])
#' >>> avg_pool_2d = tf.keras.layers.AveragePooling2D(pool_size=(2, 2),
#' ...    strides=(1, 1), padding='valid')
#' >>> avg_pool_2d(x)
#' <tf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy=
#'   array([[[[3.],
#'            [4.]],
#'           [[6.],
#'            [7.]]]], dtype=float32)>
#' ```
#'
#' For example, for `stride=(2, 2)` and `padding="valid"`:
#'
#' ```python
#' >>> x = tf.constant([[1., 2., 3., 4.],
#' ...                  [5., 6., 7., 8.],
#' ...                  [9., 10., 11., 12.]])
#' >>> x = tf.reshape(x, [1, 3, 4, 1])
#' >>> avg_pool_2d = tf.keras.layers.AveragePooling2D(pool_size=(2, 2),
#' ...    strides=(2, 2), padding='valid')
#' >>> avg_pool_2d(x)
#' <tf.Tensor: shape=(1, 1, 2, 1), dtype=float32, numpy=
#'   array([[[[3.5],
#'            [5.5]]]], dtype=float32)>
#' ```
#'
#' For example, for `strides=(1, 1)` and `padding="same"`:
#'
#' ```python
#' >>> x = tf.constant([[1., 2., 3.],
#' ...                  [4., 5., 6.],
#' ...                  [7., 8., 9.]])
#' >>> x = tf.reshape(x, [1, 3, 3, 1])
#' >>> avg_pool_2d = tf.keras.layers.AveragePooling2D(pool_size=(2, 2),
#' ...    strides=(1, 1), padding='same')
#' >>> avg_pool_2d(x)
#' <tf.Tensor: shape=(1, 3, 3, 1), dtype=float32, numpy=
#'   array([[[[3.],
#'            [4.],
#'            [4.5]],
#'           [[6.],
#'            [7.],
#'            [7.5]],
#'           [[7.5],
#'            [8.5],
#'            [9.]]]], dtype=float32)>
#' ```
#'
#' Input shape:
#'   - If `data_format='channels_last'`:
#'     4D tensor with shape `(batch_size, rows, cols, channels)`.
#'   - If `data_format='channels_first'`:
#'     4D tensor with shape `(batch_size, channels, rows, cols)`.
#'
#' Output shape:
#'   - If `data_format='channels_last'`:
#'     4D tensor with shape `(batch_size, pooled_rows, pooled_cols, channels)`.
#'   - If `data_format='channels_first'`:
#'     4D tensor with shape `(batch_size, channels, pooled_rows, pooled_cols)`.
#'
#' @param pool_size
#' integer or list of 2 integers,
#' factors by which to downscale (vertical, horizontal).
#' `(2, 2)` will halve the input in both spatial dimension.
#' If only one integer is specified, the same window length
#' will be used for both dimensions.
#'
#' @param strides
#' Integer, list of 2 integers, or NULL.
#' Strides values.
#' If NULL, it will default to `pool_size`.
#'
#' @param padding
#' One of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding evenly to
#' the left/right or up/down of the input such that output has the same
#' height/width dimension as the input.
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch, height, width, channels)` while `channels_first`
#' corresponds to inputs with shape
#' `(batch, channels, height, width)`.
#' When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#'  `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_average_pooling_2d <-
function(object, pool_size = list(2L, 2L), strides = NULL, padding = "valid",
    data_format = NULL, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape,
        pool_size = as.integer, strides = as_nullable_integer),
        ignore = "object")
    create_layer(keras$layers$AveragePooling2D, object, args)
}


# <class 'keras.src.layers.pooling.average_pooling3d.AveragePooling3D'>
#' Average pooling operation for 3D data (spatial or spatio-temporal)
#'
#' @details
#' Downsamples the input along its spatial dimensions (depth, height, and
#' width) by taking the average value over an input window
#' (of size defined by `pool_size`) for each channel of the input.
#' The window is shifted by `strides` along each dimension.
#'
#' Input shape:
#'   - If `data_format='channels_last'`:
#'     5D tensor with shape:
#'     `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`
#'   - If `data_format='channels_first'`:
#'     5D tensor with shape:
#'     `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`
#'
#' Output shape:
#'   - If `data_format='channels_last'`:
#'     5D tensor with shape:
#'     `(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)`
#'   - If `data_format='channels_first'`:
#'     5D tensor with shape:
#'     `(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)`
#'
#' Example:
#'
#' ```python
#' depth = 30
#' height = 30
#' width = 30
#' input_channels = 3
#'
#' inputs = tf.keras.Input(shape=(depth, height, width, input_channels))
#' layer = tf.keras.layers.AveragePooling3D(pool_size=3)
#' outputs = layer(inputs)  # Shape: (batch_size, 10, 10, 10, 3)
#' ```
#'
#' @param pool_size
#' list of 3 integers,
#' factors by which to downscale (dim1, dim2, dim3).
#' `(2, 2, 2)` will halve the size of the 3D input in each dimension.
#'
#' @param strides
#' list of 3 integers, or NULL. Strides values.
#'
#' @param padding
#' One of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding evenly to
#' the left/right or up/down of the input such that output has the same
#' height/width dimension as the input.
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`
#' while `channels_first` corresponds to inputs with shape
#' `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.
#' When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#'  `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_average_pooling_3d <-
function(object, pool_size = list(2L, 2L, 2L), strides = NULL,
    padding = "valid", data_format = NULL, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape,
        pool_size = as.integer, strides = as_nullable_integer),
        ignore = "object")
    create_layer(keras$layers$AveragePooling3D, object, args)
}


# <class 'keras.src.layers.pooling.average_pooling1d.AveragePooling1D'>
#' Average pooling for temporal data
#'
#' @details
#' Downsamples the input representation by taking the average value over the
#' window defined by `pool_size`. The window is shifted by `strides`.  The
#' resulting output when using "valid" padding option has a shape of:
#' `output_shape = (input_shape - pool_size + 1) / strides)`
#'
#' The resulting output shape when using the "same" padding option is:
#' `output_shape = input_shape / strides`
#'
#' For example, for strides=1 and padding="valid":
#'
#' ```python
#' >>> x = tf.constant([1., 2., 3., 4., 5.])
#' >>> x = tf.reshape(x, [1, 5, 1])
#' >>> x
#' <tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=
#'   array([[[1.],
#'           [2.],
#'           [3.],
#'           [4.],
#'           [5.]], dtype=float32)>
#' >>> avg_pool_1d = tf.keras.layers.AveragePooling1D(pool_size=2,
#' ...    strides=1, padding='valid')
#' >>> avg_pool_1d(x)
#' <tf.Tensor: shape=(1, 4, 1), dtype=float32, numpy=
#' array([[[1.5],
#'         [2.5],
#'         [3.5],
#'         [4.5]]], dtype=float32)>
#' ```
#'
#' For example, for strides=2 and padding="valid":
#'
#' ```python
#' >>> x = tf.constant([1., 2., 3., 4., 5.])
#' >>> x = tf.reshape(x, [1, 5, 1])
#' >>> x
#' <tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=
#'   array([[[1.],
#'           [2.],
#'           [3.],
#'           [4.],
#'           [5.]], dtype=float32)>
#' >>> avg_pool_1d = tf.keras.layers.AveragePooling1D(pool_size=2,
#' ...    strides=2, padding='valid')
#' >>> avg_pool_1d(x)
#' <tf.Tensor: shape=(1, 2, 1), dtype=float32, numpy=
#' array([[[1.5],
#'         [3.5]]], dtype=float32)>
#' ```
#'
#' For example, for strides=1 and padding="same":
#'
#' ```python
#' >>> x = tf.constant([1., 2., 3., 4., 5.])
#' >>> x = tf.reshape(x, [1, 5, 1])
#' >>> x
#' <tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=
#'   array([[[1.],
#'           [2.],
#'           [3.],
#'           [4.],
#'           [5.]], dtype=float32)>
#' >>> avg_pool_1d = tf.keras.layers.AveragePooling1D(pool_size=2,
#' ...    strides=1, padding='same')
#' >>> avg_pool_1d(x)
#' <tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=
#' array([[[1.5],
#'         [2.5],
#'         [3.5],
#'         [4.5],
#'         [5.]]], dtype=float32)>
#' ```
#'
#' Input shape:
#'   - If `data_format='channels_last'`:
#'     3D tensor with shape `(batch_size, steps, features)`.
#'   - If `data_format='channels_first'`:
#'     3D tensor with shape `(batch_size, features, steps)`.
#'
#' Output shape:
#'   - If `data_format='channels_last'`:
#'     3D tensor with shape `(batch_size, downsampled_steps, features)`.
#'   - If `data_format='channels_first'`:
#'     3D tensor with shape `(batch_size, features, downsampled_steps)`.
#'
#' @param pool_size
#' Integer, size of the average pooling windows.
#'
#' @param strides
#' Integer, or NULL. Factor by which to downscale.
#' E.g. 2 will halve the input.
#' If NULL, it will default to `pool_size`.
#'
#' @param padding
#' One of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding evenly to
#' the left/right or up/down of the input such that output has the same
#' height/width dimension as the input.
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch, steps, features)` while `channels_first`
#' corresponds to inputs with shape
#' `(batch, features, steps)`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_average_pooling_1d <-
function(object, pool_size = 2L, strides = NULL, padding = "valid",
    data_format = "channels_last", ...)
{
    args <- capture_args(match.call(), list(pool_size = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape, strides = as_nullable_integer),
        ignore = "object")
    create_layer(keras$layers$AveragePooling1D, object, args)
}


# <class 'keras.src.layers.pooling.average_pooling2d.AveragePooling2D'>
#' Average pooling operation for spatial data
#'
#' @details
#' Downsamples the input along its spatial dimensions (height and width)
#' by taking the average value over an input window
#' (of size defined by `pool_size`) for each channel of the input.
#' The window is shifted by `strides` along each dimension.
#'
#' The resulting output when using `"valid"` padding option has a shape
#' (number of rows or columns) of:
#' `output_shape = math.floor((input_shape - pool_size) / strides) + 1`
#' (when `input_shape >= pool_size`)
#'
#' The resulting output shape when using the `"same"` padding option is:
#' `output_shape = math.floor((input_shape - 1) / strides) + 1`
#'
#' For example, for `strides=(1, 1)` and `padding="valid"`:
#'
#' ```python
#' >>> x = tf.constant([[1., 2., 3.],
#' ...                  [4., 5., 6.],
#' ...                  [7., 8., 9.]])
#' >>> x = tf.reshape(x, [1, 3, 3, 1])
#' >>> avg_pool_2d = tf.keras.layers.AveragePooling2D(pool_size=(2, 2),
#' ...    strides=(1, 1), padding='valid')
#' >>> avg_pool_2d(x)
#' <tf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy=
#'   array([[[[3.],
#'            [4.]],
#'           [[6.],
#'            [7.]]]], dtype=float32)>
#' ```
#'
#' For example, for `stride=(2, 2)` and `padding="valid"`:
#'
#' ```python
#' >>> x = tf.constant([[1., 2., 3., 4.],
#' ...                  [5., 6., 7., 8.],
#' ...                  [9., 10., 11., 12.]])
#' >>> x = tf.reshape(x, [1, 3, 4, 1])
#' >>> avg_pool_2d = tf.keras.layers.AveragePooling2D(pool_size=(2, 2),
#' ...    strides=(2, 2), padding='valid')
#' >>> avg_pool_2d(x)
#' <tf.Tensor: shape=(1, 1, 2, 1), dtype=float32, numpy=
#'   array([[[[3.5],
#'            [5.5]]]], dtype=float32)>
#' ```
#'
#' For example, for `strides=(1, 1)` and `padding="same"`:
#'
#' ```python
#' >>> x = tf.constant([[1., 2., 3.],
#' ...                  [4., 5., 6.],
#' ...                  [7., 8., 9.]])
#' >>> x = tf.reshape(x, [1, 3, 3, 1])
#' >>> avg_pool_2d = tf.keras.layers.AveragePooling2D(pool_size=(2, 2),
#' ...    strides=(1, 1), padding='same')
#' >>> avg_pool_2d(x)
#' <tf.Tensor: shape=(1, 3, 3, 1), dtype=float32, numpy=
#'   array([[[[3.],
#'            [4.],
#'            [4.5]],
#'           [[6.],
#'            [7.],
#'            [7.5]],
#'           [[7.5],
#'            [8.5],
#'            [9.]]]], dtype=float32)>
#' ```
#'
#' Input shape:
#'   - If `data_format='channels_last'`:
#'     4D tensor with shape `(batch_size, rows, cols, channels)`.
#'   - If `data_format='channels_first'`:
#'     4D tensor with shape `(batch_size, channels, rows, cols)`.
#'
#' Output shape:
#'   - If `data_format='channels_last'`:
#'     4D tensor with shape `(batch_size, pooled_rows, pooled_cols, channels)`.
#'   - If `data_format='channels_first'`:
#'     4D tensor with shape `(batch_size, channels, pooled_rows, pooled_cols)`.
#'
#' @param pool_size
#' integer or list of 2 integers,
#' factors by which to downscale (vertical, horizontal).
#' `(2, 2)` will halve the input in both spatial dimension.
#' If only one integer is specified, the same window length
#' will be used for both dimensions.
#'
#' @param strides
#' Integer, list of 2 integers, or NULL.
#' Strides values.
#' If NULL, it will default to `pool_size`.
#'
#' @param padding
#' One of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding evenly to
#' the left/right or up/down of the input such that output has the same
#' height/width dimension as the input.
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch, height, width, channels)` while `channels_first`
#' corresponds to inputs with shape
#' `(batch, channels, height, width)`.
#' When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#'  `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_average_pooling_2d <-
function(object, pool_size = list(2L, 2L), strides = NULL, padding = "valid",
    data_format = NULL, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape,
        pool_size = as.integer, strides = as_nullable_integer),
        ignore = "object")
    create_layer(keras$layers$AveragePooling2D, object, args)
}


# <class 'keras.src.layers.pooling.average_pooling3d.AveragePooling3D'>
#' Average pooling operation for 3D data (spatial or spatio-temporal)
#'
#' @details
#' Downsamples the input along its spatial dimensions (depth, height, and
#' width) by taking the average value over an input window
#' (of size defined by `pool_size`) for each channel of the input.
#' The window is shifted by `strides` along each dimension.
#'
#' Input shape:
#'   - If `data_format='channels_last'`:
#'     5D tensor with shape:
#'     `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`
#'   - If `data_format='channels_first'`:
#'     5D tensor with shape:
#'     `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`
#'
#' Output shape:
#'   - If `data_format='channels_last'`:
#'     5D tensor with shape:
#'     `(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)`
#'   - If `data_format='channels_first'`:
#'     5D tensor with shape:
#'     `(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)`
#'
#' Example:
#'
#' ```python
#' depth = 30
#' height = 30
#' width = 30
#' input_channels = 3
#'
#' inputs = tf.keras.Input(shape=(depth, height, width, input_channels))
#' layer = tf.keras.layers.AveragePooling3D(pool_size=3)
#' outputs = layer(inputs)  # Shape: (batch_size, 10, 10, 10, 3)
#' ```
#'
#' @param pool_size
#' list of 3 integers,
#' factors by which to downscale (dim1, dim2, dim3).
#' `(2, 2, 2)` will halve the size of the 3D input in each dimension.
#'
#' @param strides
#' list of 3 integers, or NULL. Strides values.
#'
#' @param padding
#' One of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding evenly to
#' the left/right or up/down of the input such that output has the same
#' height/width dimension as the input.
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`
#' while `channels_first` corresponds to inputs with shape
#' `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.
#' When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#'  `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_average_pooling_3d <-
function(object, pool_size = list(2L, 2L, 2L), strides = NULL,
    padding = "valid", data_format = NULL, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape,
        pool_size = as.integer, strides = as_nullable_integer),
        ignore = "object")
    create_layer(keras$layers$AveragePooling3D, object, args)
}


# <class 'keras.src.layers.normalization.batch_normalization.BatchNormalization'>
#' Layer that normalizes its inputs
#'
#' @details
#' Batch normalization applies a transformation that maintains the mean output
#' close to 0 and the output standard deviation close to 1.
#'
#' Importantly, batch normalization works differently during training and
#' during inference.
#'
#' **During training** (i.e. when using `fit()` or when calling the layer/model
#' with the argument `training=TRUE`), the layer normalizes its output using
#' the mean and standard deviation of the current batch of inputs. That is to
#' say, for each channel being normalized, the layer returns
#' `gamma * (batch - mean(batch)) / sqrt(var(batch) + epsilon) + beta`, where:
#'
#' - `epsilon` is small constant (configurable as part of the constructor
#' arguments)
#' - `gamma` is a learned scaling factor (initialized as 1), which
#' can be disabled by passing `scale=FALSE` to the constructor.
#' - `beta` is a learned offset factor (initialized as 0), which
#' can be disabled by passing `center=FALSE` to the constructor.
#'
#' **During inference** (i.e. when using `evaluate()` or `predict()` or when
#' calling the layer/model with the argument `training=FALSE` (which is the
#' default), the layer normalizes its output using a moving average of the
#' mean and standard deviation of the batches it has seen during training. That
#' is to say, it returns
#' `gamma * (batch - self.moving_mean) / sqrt(self.moving_var+epsilon) + beta`.
#'
#' `self.moving_mean` and `self.moving_var` are non-trainable variables that
#' are updated each time the layer in called in training mode, as such:
#'
#' - `moving_mean = moving_mean * momentum + mean(batch) * (1 - momentum)`
#' - `moving_var = moving_var * momentum + var(batch) * (1 - momentum)`
#'
#' As such, the layer will only normalize its inputs during inference
#' *after having been trained on data that has similar statistics as the
#' inference data*.
#'
#' When `synchronized=TRUE` is set and if this layer is used within a
#' `tf.distribute` strategy, there will be an `allreduce` call
#' to aggregate batch statistics across all replicas at every
#' training step. Setting `synchronized` has no impact when the model is
#' trained without specifying any distribution strategy.
#'
#' Example usage:
#'
#' ```python
#' strategy = tf.distribute.MirroredStrategy()
#'
#' with strategy.scope():
#'   model = tf.keras.Sequential()
#'   model.add(tf.keras.layers.Dense(16))
#'   model.add(tf.keras.layers.BatchNormalization(synchronized=TRUE))
#' ```
#'
#' Call arguments:
#'   inputs: Input tensor (of any rank).
#'   training: Python boolean indicating whether the layer should behave in
#'     training mode or in inference mode.
#'     - `training=TRUE`: The layer will normalize its inputs using the mean
#'       and variance of the current batch of inputs.
#'     - `training=FALSE`: The layer will normalize its inputs using the mean
#'       and variance of its moving statistics, learned during training.
#'
#' Input shape:
#'   Arbitrary. Use the keyword argument `input_shape` (list of
#'   integers, does not include the samples axis) when using this layer as the
#'   first layer in a model.
#'
#' Output shape:
#'   Same shape as input.
#'
#' Reference:
#'   - [Ioffe and Szegedy, 2015](https://arxiv.org/abs/1502.03167).
#'
#' **About setting `layer.trainable = FALSE` on a `BatchNormalization` layer:**
#'
#' The meaning of setting `layer.trainable = FALSE` is to freeze the layer,
#' i.e. its internal state will not change during training:
#' its trainable weights will not be updated
#' during `fit()` or `train_on_batch()`, and its state updates will not be run.
#'
#' Usually, this does not necessarily mean that the layer is run in inference
#' mode (which is normally controlled by the `training` argument that can
#' be passed when calling a layer). "Frozen state" and "inference mode"
#' are two separate concepts.
#'
#' However, in the case of the `BatchNormalization` layer, **setting
#' `trainable = FALSE` on the layer means that the layer will be
#' subsequently run in inference mode** (meaning that it will use
#' the moving mean and the moving variance to normalize the current batch,
#' rather than using the mean and variance of the current batch).
#'
#' This behavior has been introduced in TensorFlow 2.0, in order
#' to enable `layer.trainable = FALSE` to produce the most commonly
#' expected behavior in the convnet fine-tuning use case.
#'
#' Note that:
#'   - Setting `trainable` on an model containing other layers will
#'     recursively set the `trainable` value of all inner layers.
#'   - If the value of the `trainable`
#'     attribute is changed after calling `compile()` on a model,
#'     the new value doesn't take effect for this model
#'     until `compile()` is called again.
#'
#' @param axis
#' Integer, the axis that should be normalized (typically the features
#' axis). For instance, after a `Conv2D` layer with
#' `data_format="channels_first"`, set `axis=1` in `BatchNormalization`.
#'
#' @param momentum
#' Momentum for the moving average.
#'
#' @param epsilon
#' Small float added to variance to avoid dividing by zero.
#'
#' @param center
#' If TRUE, add offset of `beta` to normalized tensor. If FALSE,
#' `beta` is ignored.
#'
#' @param scale
#' If TRUE, multiply by `gamma`. If FALSE, `gamma` is not used. When
#' the next layer is linear (also e.g. `nn.relu`), this can be disabled
#' since the scaling will be done by the next layer.
#'
#' @param beta_initializer
#' Initializer for the beta weight.
#'
#' @param gamma_initializer
#' Initializer for the gamma weight.
#'
#' @param moving_mean_initializer
#' Initializer for the moving mean.
#'
#' @param moving_variance_initializer
#' Initializer for the moving variance.
#'
#' @param beta_regularizer
#' Optional regularizer for the beta weight.
#'
#' @param gamma_regularizer
#' Optional regularizer for the gamma weight.
#'
#' @param beta_constraint
#' Optional constraint for the beta weight.
#'
#' @param gamma_constraint
#' Optional constraint for the gamma weight.
#'
#' @param synchronized
#' If TRUE, synchronizes the global batch statistics (mean and
#' variance) for the layer across all devices at each training step in a
#' distributed training strategy. If FALSE, each replica uses its own
#' local batch statistics. Only relevant when used inside a
#' `tf.distribute` strategy.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_batch_normalization <-
function(object, axis = -1L, momentum = 0.99, epsilon = 0.001,
    center = TRUE, scale = TRUE, beta_initializer = "zeros",
    gamma_initializer = "ones", moving_mean_initializer = "zeros",
    moving_variance_initializer = "ones", beta_regularizer = NULL,
    gamma_regularizer = NULL, beta_constraint = NULL, gamma_constraint = NULL,
    synchronized = FALSE, ...)
{
    args <- capture_args(match.call(), list(axis = as_axis, input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$BatchNormalization, object, args)
}


# <class 'keras.src.layers.rnn.bidirectional.Bidirectional'>
#' Bidirectional wrapper for RNNs
#'
#' @details
#'
#' Call arguments:
#'   The call arguments for this layer are the same as those of the wrapped RNN
#'     layer.
#'   Beware that when passing the `initial_state` argument during the call of
#'   this layer, the first half in the list of elements in the `initial_state`
#'   list will be passed to the forward RNN call and the last half in the list
#'   of elements will be passed to the backward RNN call.
#'
#'   ValueError:
#'     1. If `layer` or `backward_layer` is not a `Layer` instance.
#'
#' ```python
#' model = Sequential()
#' model.add(Bidirectional(LSTM(10, return_sequences=TRUE),
#'                              input_shape=(5, 10)))
#' model.add(Bidirectional(LSTM(10)))
#' model.add(Dense(5))
#' model.add(Activation('softmax'))
#' model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
#'
#' # With custom backward layer
#' model = Sequential()
#' forward_layer = LSTM(10, return_sequences=TRUE)
#' backward_layer = LSTM(10, activation='relu', return_sequences=TRUE,
#'                       go_backwards=TRUE)
#' model.add(Bidirectional(forward_layer, backward_layer=backward_layer,
#'                         input_shape=(5, 10)))
#' model.add(Dense(5))
#' model.add(Activation('softmax'))
#' model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
#' ```
#'
#' @param layer
#' `keras.layers.RNN` instance, such as `keras.layers.LSTM` or
#' `keras.layers.GRU`. It could also be a `keras.layers.Layer` instance
#' that meets the following criteria:
#' 1. Be a sequence-processing layer (accepts 3D+ inputs).
#' 2. Have a `go_backwards`, `return_sequences` and `return_state`
#'   attribute (with the same semantics as for the `RNN` class).
#' 3. Have an `input_spec` attribute.
#' 4. Implement serialization via `get_config()` and `from_config()`.
#' Note that the recommended way to create new RNN layers is to write a
#' custom RNN cell and use it with `keras.layers.RNN`, instead of
#' subclassing `keras.layers.Layer` directly.
#' - When the `returns_sequences` is true, the output of the masked
#' timestep will be zero regardless of the layer's original
#' `zero_output_for_mask` value.
#'
#' @param merge_mode
#' Mode by which outputs of the forward and backward RNNs will be
#' combined. One of {'sum', 'mul', 'concat', 'ave', NULL}. If NULL, the
#' outputs will not be combined, they will be returned as a list. Default
#' value is 'concat'.
#'
#' @param backward_layer
#' Optional `keras.layers.RNN`, or `keras.layers.Layer`
#' instance to be used to handle backwards input processing.
#' If `backward_layer` is not provided, the layer instance passed as the
#' `layer` argument will be used to generate the backward layer
#' automatically.
#' Note that the provided `backward_layer` layer should have properties
#' matching those of the `layer` argument, in particular it should have the
#' same values for `stateful`, `return_states`, `return_sequences`, etc.
#' In addition, `backward_layer` and `layer` should have different
#' `go_backwards` argument values.
#' A `ValueError` will be raised if these requirements are not met.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_bidirectional <-
function(object, layer, merge_mode = "concat", weights = NULL,
    backward_layer = NULL, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$Bidirectional, object, args)
}


# <class 'keras.src.layers.preprocessing.category_encoding.CategoryEncoding'>
#' A preprocessing layer which encodes integer features
#'
#' @details
#' This layer provides options for condensing data into a categorical encoding
#' when the total number of tokens are known in advance. It accepts integer
#' values as inputs, and it outputs a dense or sparse representation of those
#' inputs. For integer inputs where the total number of tokens is not known,
#' use `tf.keras.layers.IntegerLookup` instead.
#'
#' For an overview and full list of preprocessing layers, see the preprocessing
#' [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).
#'
#' **One-hot encoding data**
#'
#' ```python
#' >>> layer = tf.keras.layers.CategoryEncoding(
#' ...           num_tokens=4, output_mode="one_hot")
#' >>> layer([3, 2, 0, 1])
#' <tf.Tensor: shape=(4, 4), dtype=float32, numpy=
#'   array([[0., 0., 0., 1.],
#'          [0., 0., 1., 0.],
#'          [1., 0., 0., 0.],
#'          [0., 1., 0., 0.]], dtype=float32)>
#' ```
#'
#' **Multi-hot encoding data**
#'
#' ```python
#' >>> layer = tf.keras.layers.CategoryEncoding(
#' ...           num_tokens=4, output_mode="multi_hot")
#' >>> layer([[0, 1], [0, 0], [1, 2], [3, 1]])
#' <tf.Tensor: shape=(4, 4), dtype=float32, numpy=
#'   array([[1., 1., 0., 0.],
#'          [1., 0., 0., 0.],
#'          [0., 1., 1., 0.],
#'          [0., 1., 0., 1.]], dtype=float32)>
#' ```
#'
#' **Using weighted inputs in `"count"` mode**
#'
#' ```python
#' >>> layer = tf.keras.layers.CategoryEncoding(
#' ...           num_tokens=4, output_mode="count")
#' >>> count_weights = np.array([[.1, .2], [.1, .1], [.2, .3], [.4, .2]])
#' >>> layer([[0, 1], [0, 0], [1, 2], [3, 1]], count_weights=count_weights)
#' <tf.Tensor: shape=(4, 4), dtype=float64, numpy=
#'   array([[0.1, 0.2, 0. , 0. ],
#'          [0.2, 0. , 0. , 0. ],
#'          [0. , 0.2, 0.3, 0. ],
#'          [0. , 0.2, 0. , 0.4]], dtype=float32)>
#' ```
#'
#' Call arguments:
#'   inputs: A 1D or 2D tensor of integer inputs.
#'   count_weights: A tensor in the same shape as `inputs` indicating the
#'     weight for each sample value when summing up in `count` mode. Not used
#'     in `"multi_hot"` or `"one_hot"` modes.
#'
#' @param num_tokens
#' The total number of tokens the layer should support. All
#' inputs to the layer must integers in the range `0 <= value <
#' num_tokens`, or an error will be thrown.
#'
#' @param output_mode
#' Specification for the output of the layer.
#' Values can be `"one_hot"`, `"multi_hot"` or
#' `"count"`, configuring the layer as follows:
#'   - `"one_hot"`: Encodes each individual element in the input into an
#'     array of `num_tokens` size, containing a 1 at the element index. If
#'     the last dimension is size 1, will encode on that dimension. If the
#'     last dimension is not size 1, will append a new dimension for the
#'     encoded output.
#'   - `"multi_hot"`: Encodes each sample in the input into a single array
#'     of `num_tokens` size, containing a 1 for each vocabulary term
#'     present in the sample. Treats the last dimension as the sample
#'     dimension, if input shape is `(..., sample_length)`, output shape
#'     will be `(..., num_tokens)`.
#'   - `"count"`: Like `"multi_hot"`, but the int array contains a count of
#'     the number of times the token at that index appeared in the sample.
#' For all output modes, currently only output up to rank 2 is supported.
#' Defaults to `"multi_hot"`.
#'
#' @param sparse
#' Boolean. If true, returns a `SparseTensor` instead of a dense
#' `Tensor`. Defaults to `FALSE`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_category_encoding <-
function(object, num_tokens = NULL, output_mode = "multi_hot",
    sparse = FALSE, ...)
{
    args <- capture_args(match.call(), list(num_tokens = as_nullable_integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$CategoryEncoding, object, args)
}


# <class 'keras.src.layers.preprocessing.image_preprocessing.CenterCrop'>
#' A preprocessing layer which crops images
#'
#' @details
#' This layers crops the central portion of the images to a target size. If an
#' image is smaller than the target size, it will be resized and cropped
#' so as to return the largest possible window in the image that matches
#' the target aspect ratio.
#'
#' Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and
#' of integer or floating point dtype.
#' By default, the layer will output floats.
#'
#' For an overview and full list of preprocessing layers, see the preprocessing
#' [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).
#'
#' Input shape:
#'     3D (unbatched) or 4D (batched) tensor with shape:
#'     `(..., height, width, channels)`, in `"channels_last"` format.
#'
#' Output shape:
#'     3D (unbatched) or 4D (batched) tensor with shape:
#'     `(..., target_height, target_width, channels)`.
#'
#' If the input height/width is even and the target height/width is odd (or
#' inversely), the input image is left-padded by 1 pixel.
#'
#' @param height
#' Integer, the height of the output shape.
#'
#' @param width
#' Integer, the width of the output shape.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_center_crop <-
function(object, height, width, ...)
{
    args <- capture_args(match.call(), list(height = as.integer,
        width = as.integer, input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$CenterCrop, object, args)
}


# <class 'keras.src.layers.merging.concatenate.Concatenate'>
#' Layer that concatenates a list of inputs
#'
#' @details
#' It takes as input a list of tensors, all of the same shape except
#' for the concatenation axis, and returns a single tensor that is the
#' concatenation of all inputs.
#'
#' ```python
#' >>> x = np.arange(20).reshape(2, 2, 5)
#' >>> print(x)
#' [[[ 0  1  2  3  4]
#'   [ 5  6  7  8  9]]
#'  [[10 11 12 13 14]
#'   [15 16 17 18 19]]]
#' >>> y = np.arange(20, 30).reshape(2, 1, 5)
#' >>> print(y)
#' [[[20 21 22 23 24]]
#'  [[25 26 27 28 29]]]
#' >>> tf.keras.layers.Concatenate(axis=1)([x, y])
#' <tf.Tensor: shape=(2, 3, 5), dtype=int64, numpy=
#' array([[[ 0,  1,  2,  3,  4],
#'         [ 5,  6,  7,  8,  9],
#'         [20, 21, 22, 23, 24]],
#'        [[10, 11, 12, 13, 14],
#'         [15, 16, 17, 18, 19],
#'         [25, 26, 27, 28, 29]]])>
#' ```
#'
#' ```python
#' >>> x1 = tf.keras.layers.Dense(8)(np.arange(10).reshape(5, 2))
#' >>> x2 = tf.keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))
#' >>> concatted = tf.keras.layers.Concatenate()([x1, x2])
#' >>> concatted.shape
#' TensorShape([5, 16])
#' ```
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_concatenate <-
function(inputs, ..., axis = -1L)
{
    args <- capture_args(match.call(), list(axis = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = c("...",
        "inputs"))
    dots <- split_dots_named_unnamed(list(...))
    if (missing(inputs))
        inputs <- NULL
    else if (!is.null(inputs) && !is.list(inputs))
        inputs <- list(inputs)
    inputs <- c(inputs, dots$unnamed)
    args <- c(args, dots$named)
    layer <- do.call(keras$layers$Concatenate, args)
    if (length(inputs))
        layer(inputs)
    else layer
}


# <class 'keras.src.layers.convolutional.conv1d.Conv1D'>
#' 1D convolution layer (e.g. temporal convolution)
#'
#' @details
#' This layer creates a convolution kernel that is convolved
#' with the layer input over a single spatial (or temporal) dimension
#' to produce a tensor of outputs.
#' If `use_bias` is TRUE, a bias vector is created and added to the outputs.
#' Finally, if `activation` is not `NULL`,
#' it is applied to the outputs as well.
#'
#' When using this layer as the first layer in a model,
#' provide an `input_shape` argument
#' (list of integers or `NULL`, e.g.
#' `(10, 128)` for sequences of 10 vectors of 128-dimensional vectors,
#' or `(NULL, 128)` for variable-length sequences of 128-dimensional vectors.
#'
#' ```python
#' >>> # The inputs are 128-length vectors with 10 timesteps, and the
#' >>> # batch size is 4.
#' >>> input_shape = (4, 10, 128)
#' >>> x = tf.random.normal(input_shape)
#' >>> y = tf.keras.layers.Conv1D(
#' ... 32, 3, activation='relu',input_shape=input_shape[1:])(x)
#' >>> print(y.shape)
#' (4, 8, 32)
#' ```
#'
#' ```python
#' >>> # With extended batch shape [4, 7] (e.g. weather data where batch
#' >>> # dimensions correspond to spatial location and the third dimension
#' >>> # corresponds to time.)
#' >>> input_shape = (4, 7, 10, 128)
#' >>> x = tf.random.normal(input_shape)
#' >>> y = tf.keras.layers.Conv1D(
#' ... 32, 3, activation='relu', input_shape=input_shape[2:])(x)
#' >>> print(y.shape)
#' (4, 7, 8, 32)
#' ```
#'
#' Input shape:
#'   3+D tensor with shape: `batch_shape + (steps, input_dim)`
#'
#' Output shape:
#'   3+D tensor with shape: `batch_shape + (new_steps, filters)`
#'     `steps` value might have changed due to padding or strides.
#'
#'   A tensor of rank 3 representing
#'
#' @param filters
#' Integer, the dimensionality of the output space
#' (i.e. the number of output filters in the convolution).
#'
#' @param kernel_size
#' An integer or list of a single integer,
#' specifying the length of the 1D convolution window.
#'
#' @param strides
#' An integer or list of a single integer,
#' specifying the stride length of the convolution.
#' Specifying any stride value != 1 is incompatible with specifying
#' any `dilation_rate` value != 1.
#'
#' @param padding
#' One of `"valid"`, `"same"` or `"causal"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding with zeros
#' evenly to the left/right or up/down of the input such that output has
#' the same height/width dimension as the input.
#' `"causal"` results in causal (dilated) convolutions, e.g. `output[t]`
#' does not depend on `input[t+1:]`. Useful when modeling temporal data
#' where the model should not violate the temporal order.
#' See [WaveNet: A Generative Model for Raw Audio, section
#'   2.1](https://arxiv.org/abs/1609.03499).
#'
#' @param data_format
#' A string, one of `channels_last` (default) or
#' `channels_first`. The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape `(batch_size, width,
#' channels)` while `channels_first` corresponds to inputs with shape
#' `(batch_size, channels, width)`. Note that the `channels_first` format
#' is currently not supported by TensorFlow on CPU.
#'
#' @param dilation_rate
#' an integer or list of a single integer, specifying
#' the dilation rate to use for dilated convolution.
#' Currently, specifying any `dilation_rate` value != 1 is
#' incompatible with specifying any `strides` value != 1.
#'
#' @param groups
#' A positive integer specifying the number of groups in which the
#' input is split along the channel axis. Each group is convolved
#' separately with `filters / groups` filters. The output is the
#' concatenation of all the `groups` results along the channel axis.
#' Input channels and `filters` must both be divisible by `groups`.
#'
#' @param activation
#' Activation function to use.
#' If you don't specify anything, no activation is applied
#' (see `keras.activations`).
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix
#' (see `keras.initializers`). Defaults to 'glorot_uniform'.
#'
#' @param bias_initializer
#' Initializer for the bias vector
#' (see `keras.initializers`). Defaults to 'zeros'.
#'
#' @param kernel_regularizer
#' Regularizer function applied to
#' the `kernel` weights matrix (see `keras.regularizers`).
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector
#' (see `keras.regularizers`).
#'
#' @param activity_regularizer
#' Regularizer function applied to
#' the output of the layer (its "activation")
#' (see `keras.regularizers`).
#'
#' @param kernel_constraint
#' Constraint function applied to the kernel matrix
#' (see `keras.constraints`).
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector
#' (see `keras.constraints`).
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_conv_1d <-
function(object, filters, kernel_size, strides = 1L, padding = "valid",
    data_format = "channels_last", dilation_rate = 1L, groups = 1L,
    activation = NULL, use_bias = TRUE, kernel_initializer = "glorot_uniform",
    bias_initializer = "zeros", kernel_regularizer = NULL, bias_regularizer = NULL,
    activity_regularizer = NULL, kernel_constraint = NULL, bias_constraint = NULL,
    ...)
{
    args <- capture_args(match.call(), list(filters = as.integer,
        kernel_size = as_integer_or_integer_tuple, strides = as_integer_or_integer_tuple,
        dilation_rate = as_integer_or_integer_tuple, groups = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$Conv1D, object, args)
}


# <class 'keras.src.layers.convolutional.conv1d_transpose.Conv1DTranspose'>
#' Transposed convolution layer (sometimes called Deconvolution)
#'
#' @details
#' The need for transposed convolutions generally arises
#' from the desire to use a transformation going in the opposite direction
#' of a normal convolution, i.e., from something that has the shape of the
#' output of some convolution to something that has the shape of its input
#' while maintaining a connectivity pattern that is compatible with
#' said convolution.
#'
#' When using this layer as the first layer in a model,
#' provide the keyword argument `input_shape`
#' (list of integers or `NULL`, does not include the sample axis),
#' e.g. `input_shape=(128, 3)` for data with 128 time steps and 3 channels.
#'
#' Input shape:
#'   3D tensor with shape:
#'   `(batch_size, steps, channels)`
#'
#' Output shape:
#'   3D tensor with shape:
#'   `(batch_size, new_steps, filters)`
#'   If `output_padding` is specified:
#'   ```
#'   new_timesteps = ((timesteps - 1) * strides + kernel_size -
#'   2 * padding + output_padding)
#'   ```
#'
#'   A tensor of rank 3 representing
#'
#' References:
#'   - [A guide to convolution arithmetic for deep learning](
#'     https://arxiv.org/abs/1603.07285v1)
#'   - [Deconvolutional Networks](
#'     https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)
#'
#' @param filters
#' Integer, the dimensionality of the output space
#' (i.e. the number of output filters in the convolution).
#'
#' @param kernel_size
#' An integer length of the 1D convolution window.
#'
#' @param strides
#' An integer specifying the stride of the convolution along the
#' time dimension. Specifying a stride value != 1 is incompatible with
#' specifying a `dilation_rate` value != 1. Defaults to `1`.
#'
#' @param padding
#' one of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding with zeros
#' evenly to the left/right or up/down of the input such that output has
#' the same height/width dimension as the input.
#'
#' @param output_padding
#' An integer specifying the amount of padding along
#' the time dimension of the output tensor.
#' The amount of output padding must be lower than the stride.
#' If set to `NULL` (default), the output shape is inferred.
#'
#' @param data_format
#' A string, one of `channels_last` (default) or
#' `channels_first`.  The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch_size, length, channels)` while `channels_first` corresponds to
#' inputs with shape `(batch_size, channels, length)`.
#'
#' @param dilation_rate
#' an integer, specifying
#' the dilation rate to use for dilated convolution.
#' Currently, specifying a `dilation_rate` value != 1 is
#' incompatible with specifying a stride value != 1.
#' Also dilation rate larger than 1 is not currently supported.
#'
#' @param activation
#' Activation function to use.
#' If you don't specify anything, no activation is applied
#' (see `keras.activations`).
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix
#' (see `keras.initializers`). Defaults to 'glorot_uniform'.
#'
#' @param bias_initializer
#' Initializer for the bias vector
#' (see `keras.initializers`). Defaults to 'zeros'.
#'
#' @param kernel_regularizer
#' Regularizer function applied to
#' the `kernel` weights matrix (see `keras.regularizers`).
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector
#' (see `keras.regularizers`).
#'
#' @param activity_regularizer
#' Regularizer function applied to
#' the output of the layer (its "activation") (see `keras.regularizers`).
#'
#' @param kernel_constraint
#' Constraint function applied to the kernel matrix
#' (see `keras.constraints`).
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector
#' (see `keras.constraints`).
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_conv_1d_transpose <-
function(object, filters, kernel_size, strides = 1L, padding = "valid",
    output_padding = NULL, data_format = NULL, dilation_rate = 1L,
    activation = NULL, use_bias = TRUE, kernel_initializer = "glorot_uniform",
    bias_initializer = "zeros", kernel_regularizer = NULL, bias_regularizer = NULL,
    activity_regularizer = NULL, kernel_constraint = NULL, bias_constraint = NULL,
    ...)
{
    args <- capture_args(match.call(), list(filters = as.integer,
        kernel_size = as_integer_or_integer_tuple, strides = as_integer_or_integer_tuple,
        dilation_rate = as_integer_or_integer_tuple, input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$Conv1DTranspose, object, args)
}


# <class 'keras.src.layers.convolutional.conv2d.Conv2D'>
#' 2D convolution layer (e.g. spatial convolution over images)
#'
#' @details
#' This layer creates a convolution kernel that is convolved
#' with the layer input to produce a tensor of
#' outputs. If `use_bias` is TRUE,
#' a bias vector is created and added to the outputs. Finally, if
#' `activation` is not `NULL`, it is applied to the outputs as well.
#'
#' When using this layer as the first layer in a model,
#' provide the keyword argument `input_shape`
#' (list of integers or `NULL`, does not include the sample axis),
#' e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures
#' in `data_format="channels_last"`. You can use `NULL` when
#' a dimension has variable size.
#'
#' ```python
#' >>> # The inputs are 28x28 RGB images with `channels_last` and the batch
#' >>> # size is 4.
#' >>> input_shape = (4, 28, 28, 3)
#' >>> x = tf.random.normal(input_shape)
#' >>> y = tf.keras.layers.Conv2D(
#' ... 2, 3, activation='relu', input_shape=input_shape[1:])(x)
#' >>> print(y.shape)
#' (4, 26, 26, 2)
#' ```
#'
#' ```python
#' >>> # With `dilation_rate` as 2.
#' >>> input_shape = (4, 28, 28, 3)
#' >>> x = tf.random.normal(input_shape)
#' >>> y = tf.keras.layers.Conv2D(
#' ...     2, 3,
#' ...     activation='relu',
#' ...     dilation_rate=2,
#' ...     input_shape=input_shape[1:])(x)
#' >>> print(y.shape)
#' (4, 24, 24, 2)
#' ```
#'
#' ```python
#' >>> # With `padding` as "same".
#' >>> input_shape = (4, 28, 28, 3)
#' >>> x = tf.random.normal(input_shape)
#' >>> y = tf.keras.layers.Conv2D(
#' ... 2, 3, activation='relu', padding="same", input_shape=input_shape[1:])(x)
#' >>> print(y.shape)
#' (4, 28, 28, 2)
#' ```
#'
#' ```python
#' >>> # With extended batch shape [4, 7]:
#' >>> input_shape = (4, 7, 28, 28, 3)
#' >>> x = tf.random.normal(input_shape)
#' >>> y = tf.keras.layers.Conv2D(
#' ... 2, 3, activation='relu', input_shape=input_shape[2:])(x)
#' >>> print(y.shape)
#' (4, 7, 26, 26, 2)
#' ```
#'
#' Input shape:
#'   4+D tensor with shape: `batch_shape + (channels, rows, cols)` if
#'     `data_format='channels_first'`
#'   or 4+D tensor with shape: `batch_shape + (rows, cols, channels)` if
#'     `data_format='channels_last'`.
#'
#' Output shape:
#'   4+D tensor with shape: `batch_shape + (filters, new_rows, new_cols)` if
#'   `data_format='channels_first'` or 4+D tensor with shape: `batch_shape +
#'     (new_rows, new_cols, filters)` if `data_format='channels_last'`.  `rows`
#'     and `cols` values might have changed due to padding.
#'
#'   A tensor of rank 4+ representing
#'
#' @param filters
#' Integer, the dimensionality of the output space (i.e. the number
#' of output filters in the convolution).
#'
#' @param kernel_size
#' An integer or list of 2 integers, specifying the height
#' and width of the 2D convolution window. Can be a single integer to
#' specify the same value for all spatial dimensions.
#'
#' @param strides
#' An integer or list of 2 integers, specifying the strides of
#' the convolution along the height and width. Can be a single integer to
#' specify the same value for all spatial dimensions. Specifying any stride
#' value != 1 is incompatible with specifying any `dilation_rate` value !=
#' 1.
#'
#' @param padding
#' one of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding with zeros
#' evenly to the left/right or up/down of the input. When `padding="same"`
#' and `strides=1`, the output has the same size as the input.
#'
#' @param data_format
#' A string, one of `channels_last` (default) or
#' `channels_first`.  The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape `(batch_size, height,
#' width, channels)` while `channels_first` corresponds to inputs with
#' shape `(batch_size, channels, height, width)`. If left unspecified, it
#' uses the `image_data_format` value found in your Keras config file at
#' `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Note that the `channels_first` format is currently not
#' supported by TensorFlow on CPU. Defaults to 'channels_last'.
#'
#' @param dilation_rate
#' an integer or list of 2 integers, specifying the
#' dilation rate to use for dilated convolution. Can be a single integer to
#' specify the same value for all spatial dimensions. Currently, specifying
#' any `dilation_rate` value != 1 is incompatible with specifying any
#' stride value != 1.
#'
#' @param groups
#' A positive integer specifying the number of groups in which the
#' input is split along the channel axis. Each group is convolved
#' separately with `filters / groups` filters. The output is the
#' concatenation of all the `groups` results along the channel axis. Input
#' channels and `filters` must both be divisible by `groups`.
#'
#' @param activation
#' Activation function to use. If you don't specify anything, no
#' activation is applied (see `keras.activations`).
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix (see
#' `keras.initializers`). Defaults to 'glorot_uniform'.
#'
#' @param bias_initializer
#' Initializer for the bias vector (see
#' `keras.initializers`). Defaults to 'zeros'.
#'
#' @param kernel_regularizer
#' Regularizer function applied to the `kernel` weights
#' matrix (see `keras.regularizers`).
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector (see
#' `keras.regularizers`).
#'
#' @param activity_regularizer
#' Regularizer function applied to the output of the
#' layer (its "activation") (see `keras.regularizers`).
#'
#' @param kernel_constraint
#' Constraint function applied to the kernel matrix (see
#' `keras.constraints`).
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector (see
#' `keras.constraints`).
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_conv_2d <-
function(object, filters, kernel_size, strides = list(1L, 1L),
    padding = "valid", data_format = NULL, dilation_rate = list(
        1L, 1L), groups = 1L, activation = NULL, use_bias = TRUE,
    kernel_initializer = "glorot_uniform", bias_initializer = "zeros",
    kernel_regularizer = NULL, bias_regularizer = NULL, activity_regularizer = NULL,
    kernel_constraint = NULL, bias_constraint = NULL, ...)
{
    args <- capture_args(match.call(), list(filters = as.integer,
        kernel_size = as_integer_or_integer_tuple, groups = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape, dilation_rate = as_integer_or_integer_tuple,
        strides = as_integer_or_integer_tuple), ignore = "object")
    create_layer(keras$layers$Conv2D, object, args)
}


# <class 'keras.src.layers.convolutional.conv2d_transpose.Conv2DTranspose'>
#' Transposed convolution layer (sometimes called Deconvolution)
#'
#' @details
#' The need for transposed convolutions generally arises
#' from the desire to use a transformation going in the opposite direction
#' of a normal convolution, i.e., from something that has the shape of the
#' output of some convolution to something that has the shape of its input
#' while maintaining a connectivity pattern that is compatible with
#' said convolution.
#'
#' When using this layer as the first layer in a model,
#' provide the keyword argument `input_shape`
#' (list of integers or `NULL`, does not include the sample axis),
#' e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures
#' in `data_format="channels_last"`.
#'
#' Input shape:
#'   4D tensor with shape:
#'   `(batch_size, channels, rows, cols)` if data_format='channels_first'
#'   or 4D tensor with shape:
#'   `(batch_size, rows, cols, channels)` if data_format='channels_last'.
#'
#' Output shape:
#'   4D tensor with shape:
#'   `(batch_size, filters, new_rows, new_cols)` if
#'   data_format='channels_first'
#'   or 4D tensor with shape:
#'   `(batch_size, new_rows, new_cols, filters)` if
#'   data_format='channels_last'.  `rows` and `cols` values might have changed
#'   due to padding.
#'   If `output_padding` is specified:
#'   ```
#'   new_rows = ((rows - 1) * strides[0] + kernel_size[0] - 2 * padding[0] +
#'   output_padding[0])
#'   new_cols = ((cols - 1) * strides[1] + kernel_size[1] - 2 * padding[1] +
#'   output_padding[1])
#'   ```
#'
#'   A tensor of rank 4 representing
#'
#' References:
#'   - [A guide to convolution arithmetic for deep
#'     learning](https://arxiv.org/abs/1603.07285v1)
#'   - [Deconvolutional
#'     Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)
#'
#' @param filters
#' Integer, the dimensionality of the output space
#' (i.e. the number of output filters in the convolution).
#'
#' @param kernel_size
#' An integer or list of 2 integers, specifying the
#' height and width of the 2D convolution window.
#' Can be a single integer to specify the same value for
#' all spatial dimensions.
#'
#' @param strides
#' An integer or list of 2 integers,
#' specifying the strides of the convolution along the height and width.
#' Can be a single integer to specify the same value for
#' all spatial dimensions.
#' Specifying any stride value != 1 is incompatible with specifying
#' any `dilation_rate` value != 1.
#'
#' @param padding
#' one of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding with zeros
#' evenly to the left/right or up/down of the input such that output has
#' the same height/width dimension as the input.
#'
#' @param output_padding
#' An integer or list of 2 integers,
#' specifying the amount of padding along the height and width
#' of the output tensor.
#' Can be a single integer to specify the same value for all
#' spatial dimensions.
#' The amount of output padding along a given dimension must be
#' lower than the stride along that same dimension.
#' If set to `NULL` (default), the output shape is inferred.
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch_size, height, width, channels)` while `channels_first`
#' corresponds to inputs with shape
#' `(batch_size, channels, height, width)`.
#' When unspecified, uses `image_data_format` value found in your Keras
#' config file at `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to "channels_last".
#'
#' @param dilation_rate
#' an integer, specifying the dilation rate for all spatial
#' dimensions for dilated convolution. Specifying different dilation rates
#' for different dimensions is not supported.
#' Currently, specifying any `dilation_rate` value != 1 is
#' incompatible with specifying any stride value != 1.
#'
#' @param activation
#' Activation function to use.
#' If you don't specify anything, no activation is applied
#' (see `keras.activations`).
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix
#' (see `keras.initializers`). Defaults to 'glorot_uniform'.
#'
#' @param bias_initializer
#' Initializer for the bias vector
#' (see `keras.initializers`). Defaults to 'zeros'.
#'
#' @param kernel_regularizer
#' Regularizer function applied to
#' the `kernel` weights matrix (see `keras.regularizers`).
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector
#' (see `keras.regularizers`).
#'
#' @param activity_regularizer
#' Regularizer function applied to
#' the output of the layer (its "activation") (see `keras.regularizers`).
#'
#' @param kernel_constraint
#' Constraint function applied to the kernel matrix
#' (see `keras.constraints`).
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector
#' (see `keras.constraints`).
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_conv_2d_transpose <-
function(object, filters, kernel_size, strides = list(1L, 1L),
    padding = "valid", output_padding = NULL, data_format = NULL,
    dilation_rate = list(1L, 1L), activation = NULL, use_bias = TRUE,
    kernel_initializer = "glorot_uniform", bias_initializer = "zeros",
    kernel_regularizer = NULL, bias_regularizer = NULL, activity_regularizer = NULL,
    kernel_constraint = NULL, bias_constraint = NULL, ...)
{
    args <- capture_args(match.call(), list(filters = as.integer,
        kernel_size = as_integer_or_integer_tuple, input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape,
        dilation_rate = as_integer_or_integer_tuple, strides = as_integer_or_integer_tuple),
        ignore = "object")
    create_layer(keras$layers$Conv2DTranspose, object, args)
}


# <class 'keras.src.layers.convolutional.conv3d.Conv3D'>
#' 3D convolution layer (e.g. spatial convolution over volumes)
#'
#' @details
#' This layer creates a convolution kernel that is convolved
#' with the layer input to produce a tensor of
#' outputs. If `use_bias` is TRUE,
#' a bias vector is created and added to the outputs. Finally, if
#' `activation` is not `NULL`, it is applied to the outputs as well.
#'
#' When using this layer as the first layer in a model,
#' provide the keyword argument `input_shape`
#' (list of integers or `NULL`, does not include the sample axis),
#' e.g. `input_shape=(128, 128, 128, 1)` for 128x128x128 volumes
#' with a single channel,
#' in `data_format="channels_last"`.
#'
#' ```python
#' >>> # The inputs are 28x28x28 volumes with a single channel, and the
#' >>> # batch size is 4
#' >>> input_shape =(4, 28, 28, 28, 1)
#' >>> x = tf.random.normal(input_shape)
#' >>> y = tf.keras.layers.Conv3D(
#' ... 2, 3, activation='relu', input_shape=input_shape[1:])(x)
#' >>> print(y.shape)
#' (4, 26, 26, 26, 2)
#' ```
#'
#' ```python
#' >>> # With extended batch shape [4, 7], e.g. a batch of 4 videos of
#' >>> # 3D frames, with 7 frames per video.
#' >>> input_shape = (4, 7, 28, 28, 28, 1)
#' >>> x = tf.random.normal(input_shape)
#' >>> y = tf.keras.layers.Conv3D(
#' ... 2, 3, activation='relu', input_shape=input_shape[2:])(x)
#' >>> print(y.shape)
#' (4, 7, 26, 26, 26, 2)
#' ```
#'
#' Input shape:
#'   5+D tensor with shape: `batch_shape + (channels, conv_dim1, conv_dim2,
#'     conv_dim3)` if data_format='channels_first'
#'   or 5+D tensor with shape: `batch_shape + (conv_dim1, conv_dim2, conv_dim3,
#'     channels)` if data_format='channels_last'.
#'
#' Output shape:
#'   5+D tensor with shape: `batch_shape + (filters, new_conv_dim1,
#'     new_conv_dim2, new_conv_dim3)` if data_format='channels_first'
#'   or 5+D tensor with shape: `batch_shape + (new_conv_dim1, new_conv_dim2,
#'     new_conv_dim3, filters)` if data_format='channels_last'.
#'     `new_conv_dim1`, `new_conv_dim2` and `new_conv_dim3` values might have
#'     changed due to padding.
#'
#'   A tensor of rank 5+ representing
#'
#' @param filters
#' Integer, the dimensionality of the output space (i.e. the number
#' of output filters in the convolution).
#'
#' @param kernel_size
#' An integer or list of 3 integers, specifying the depth,
#' height and width of the 3D convolution window. Can be a single integer
#' to specify the same value for all spatial dimensions.
#'
#' @param strides
#' An integer or list of 3 integers, specifying the strides of
#' the convolution along each spatial dimension. Can be a single integer to
#' specify the same value for all spatial dimensions. Specifying any stride
#' value != 1 is incompatible with specifying any `dilation_rate` value !=
#' 1.
#'
#' @param padding
#' one of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding with zeros
#' evenly to the left/right or up/down of the input such that output has
#' the same height/width dimension as the input.
#'
#' @param data_format
#' A string, one of `channels_last` (default) or
#' `channels_first`.  The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape `batch_shape +
#' (spatial_dim1, spatial_dim2, spatial_dim3, channels)` while
#' `channels_first` corresponds to inputs with shape `batch_shape +
#' (channels, spatial_dim1, spatial_dim2, spatial_dim3)`. When unspecified,
#' uses `image_data_format` value found in your Keras config file at
#' `~/.keras/keras.json` (if exists) else 'channels_last'. Note that the
#' `channels_first` format is currently not supported by TensorFlow on CPU.
#' Defaults to 'channels_last'.
#'
#' @param dilation_rate
#' an integer or list of 3 integers, specifying the
#' dilation rate to use for dilated convolution. Can be a single integer to
#' specify the same value for all spatial dimensions. Currently, specifying
#' any `dilation_rate` value != 1 is incompatible with specifying any
#' stride value != 1.
#'
#' @param groups
#' A positive integer specifying the number of groups in which the
#' input is split along the channel axis. Each group is convolved
#' separately with `filters / groups` filters. The output is the
#' concatenation of all the `groups` results along the channel axis. Input
#' channels and `filters` must both be divisible by `groups`.
#'
#' @param activation
#' Activation function to use. If you don't specify anything, no
#' activation is applied (see `keras.activations`).
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix (see
#' `keras.initializers`). Defaults to 'glorot_uniform'.
#'
#' @param bias_initializer
#' Initializer for the bias vector (see
#' `keras.initializers`). Defaults to 'zeros'.
#'
#' @param kernel_regularizer
#' Regularizer function applied to the `kernel` weights
#' matrix (see `keras.regularizers`).
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector (see
#' `keras.regularizers`).
#'
#' @param activity_regularizer
#' Regularizer function applied to the output of the
#' layer (its "activation") (see `keras.regularizers`).
#'
#' @param kernel_constraint
#' Constraint function applied to the kernel matrix (see
#' `keras.constraints`).
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector (see
#' `keras.constraints`).
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_conv_3d <-
function(object, filters, kernel_size, strides = list(1L, 1L,
    1L), padding = "valid", data_format = NULL, dilation_rate = list(
    1L, 1L, 1L), groups = 1L, activation = NULL, use_bias = TRUE,
    kernel_initializer = "glorot_uniform", bias_initializer = "zeros",
    kernel_regularizer = NULL, bias_regularizer = NULL, activity_regularizer = NULL,
    kernel_constraint = NULL, bias_constraint = NULL, ...)
{
    args <- capture_args(match.call(), list(filters = as.integer,
        kernel_size = as_integer_or_integer_tuple, groups = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape, dilation_rate = as_integer_or_integer_tuple,
        strides = as_integer_or_integer_tuple), ignore = "object")
    create_layer(keras$layers$Conv3D, object, args)
}


# <class 'keras.src.layers.convolutional.conv3d_transpose.Conv3DTranspose'>
#' Transposed convolution layer (sometimes called Deconvolution)
#'
#' @details
#' The need for transposed convolutions generally arises
#' from the desire to use a transformation going in the opposite direction
#' of a normal convolution, i.e., from something that has the shape of the
#' output of some convolution to something that has the shape of its input
#' while maintaining a connectivity pattern that is compatible with
#' said convolution.
#'
#' When using this layer as the first layer in a model,
#' provide the keyword argument `input_shape`
#' (list of integers or `NULL`, does not include the sample axis),
#' e.g. `input_shape=(128, 128, 128, 3)` for a 128x128x128 volume with 3
#' channels if `data_format="channels_last"`.
#'
#' Input shape:
#'   5D tensor with shape:
#'   `(batch_size, channels, depth, rows, cols)` if
#'   data_format='channels_first'
#'   or 5D tensor with shape:
#'   `(batch_size, depth, rows, cols, channels)` if
#'   data_format='channels_last'.
#'
#' Output shape:
#'   5D tensor with shape:
#'   `(batch_size, filters, new_depth, new_rows, new_cols)` if
#'     data_format='channels_first'
#'   or 5D tensor with shape:
#'   `(batch_size, new_depth, new_rows, new_cols, filters)` if
#'     data_format='channels_last'.
#'   `depth` and `rows` and `cols` values might have changed due to padding.
#'   If `output_padding` is specified::
#'   ```
#'   new_depth = ((depth - 1) * strides[0] + kernel_size[0] - 2 * padding[0] +
#'   output_padding[0])
#'   new_rows = ((rows - 1) * strides[1] + kernel_size[1] - 2 * padding[1] +
#'   output_padding[1])
#'   new_cols = ((cols - 1) * strides[2] + kernel_size[2] - 2 * padding[2] +
#'   output_padding[2])
#'   ```
#'
#'   A tensor of rank 5 representing
#'
#' References:
#'   - [A guide to convolution arithmetic for deep
#'     learning](https://arxiv.org/abs/1603.07285v1)
#'   - [Deconvolutional
#'     Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)
#'
#' @param filters
#' Integer, the dimensionality of the output space
#' (i.e. the number of output filters in the convolution).
#'
#' @param kernel_size
#' An integer or list of 3 integers, specifying the
#' depth, height and width of the 3D convolution window.
#' Can be a single integer to specify the same value for
#' all spatial dimensions.
#'
#' @param strides
#' An integer or list of 3 integers,
#' specifying the strides of the convolution along the depth, height
#'   and width.
#' Can be a single integer to specify the same value for
#' all spatial dimensions.
#' Specifying any stride value != 1 is incompatible with specifying
#' any `dilation_rate` value != 1.
#'
#' @param padding
#' one of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding with zeros
#' evenly to the left/right or up/down of the input such that output has
#' the same height/width dimension as the input.
#'
#' @param output_padding
#' An integer or list of 3 integers,
#' specifying the amount of padding along the depth, height, and
#' width.
#' Can be a single integer to specify the same value for all
#' spatial dimensions.
#' The amount of output padding along a given dimension must be
#' lower than the stride along that same dimension.
#' If set to `NULL` (default), the output shape is inferred.
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch_size, depth, height, width, channels)` while `channels_first`
#' corresponds to inputs with shape
#' `(batch_size, channels, depth, height, width)`.
#' When unspecified, uses `image_data_format` value found in your Keras
#' config file at `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param dilation_rate
#' an integer or list of 3 integers, specifying
#' the dilation rate to use for dilated convolution.
#' Can be a single integer to specify the same value for
#' all spatial dimensions.
#' Currently, specifying any `dilation_rate` value != 1 is
#' incompatible with specifying any stride value != 1.
#'
#' @param activation
#' Activation function to use.
#' If you don't specify anything, no activation is applied
#' (see `keras.activations`).
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix
#' (see `keras.initializers`). Defaults to 'glorot_uniform'.
#'
#' @param bias_initializer
#' Initializer for the bias vector
#' (see `keras.initializers`). Defaults to 'zeros'.
#'
#' @param kernel_regularizer
#' Regularizer function applied to
#' the `kernel` weights matrix
#' (see `keras.regularizers`).
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector
#' (see `keras.regularizers`).
#'
#' @param activity_regularizer
#' Regularizer function applied to
#' the output of the layer (its "activation")
#' (see `keras.regularizers`).
#'
#' @param kernel_constraint
#' Constraint function applied to the kernel matrix
#' (see `keras.constraints`).
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector
#' (see `keras.constraints`).
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_conv_3d_transpose <-
function(object, filters, kernel_size, strides = list(1L, 1L,
    1L), padding = "valid", output_padding = NULL, data_format = NULL,
    dilation_rate = list(1L, 1L, 1L), activation = NULL, use_bias = TRUE,
    kernel_initializer = "glorot_uniform", bias_initializer = "zeros",
    kernel_regularizer = NULL, bias_regularizer = NULL, activity_regularizer = NULL,
    kernel_constraint = NULL, bias_constraint = NULL, ...)
{
    args <- capture_args(match.call(), list(filters = as.integer,
        kernel_size = as_integer_or_integer_tuple, input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape,
        dilation_rate = as_integer_or_integer_tuple, strides = as_integer_or_integer_tuple),
        ignore = "object")
    create_layer(keras$layers$Conv3DTranspose, object, args)
}


# <class 'keras.src.layers.rnn.conv_lstm1d.ConvLSTM1D'>
#' 1D Convolutional LSTM
#'
#' @details
#' Similar to an LSTM layer, but the input transformations
#' and recurrent transformations are both convolutional.
#'
#' Call arguments:
#'   inputs: A 4D tensor.
#'   mask: Binary tensor of shape `(samples, timesteps)` indicating whether a
#'     given timestep should be masked.
#'   training: Python boolean indicating whether the layer should behave in
#'     training mode or in inference mode. This argument is passed to the cell
#'     when calling it. This is only relevant if `dropout` or
#'     `recurrent_dropout` are set.
#'   initial_state: List of initial state tensors to be passed to the first
#'     call of the cell.
#' Input shape: - If data_format='channels_first'
#'       4D tensor with shape: `(samples, time, channels, rows)` - If
#'         data_format='channels_last'
#'       4D tensor with shape: `(samples, time, rows, channels)`
#' Output shape:
#'   - If `return_state`: a list of tensors. The first tensor is the output.
#'     The remaining tensors are the last states,
#'     each 3D tensor with shape: `(samples, filters, new_rows)` if
#'       data_format='channels_first'
#'     or shape: `(samples, new_rows, filters)` if data_format='channels_last'.
#'       `rows` values might have changed due to padding.
#'   - If `return_sequences`: 4D tensor with shape: `(samples, timesteps,
#'     filters, new_rows)` if data_format='channels_first'
#'     or shape: `(samples, timesteps, new_rows, filters)` if
#'       data_format='channels_last'.
#'   - Else, 3D tensor with shape: `(samples, filters, new_rows)` if
#'     data_format='channels_first'
#'     or shape: `(samples, new_rows, filters)` if data_format='channels_last'.
#'
#' References:
#'   - [Shi et al., 2015](http://arxiv.org/abs/1506.04214v1)
#'   (the current implementation does not include the feedback loop on the
#'   cells output).
#'
#' @param filters
#' Integer, the dimensionality of the output space (i.e. the number
#' of output filters in the convolution).
#'
#' @param kernel_size
#' An integer or list of n integers, specifying the
#' dimensions of the convolution window.
#'
#' @param strides
#' An integer or list of n integers, specifying the strides of
#' the convolution. Specifying any stride value != 1 is incompatible with
#' specifying any `dilation_rate` value != 1.
#'
#' @param padding
#' One of `"valid"` or `"same"` (case-insensitive). `"valid"` means
#' no padding. `"same"` results in padding evenly to the left/right or
#' up/down of the input such that output has the same height/width
#' dimension as the input.
#'
#' @param data_format
#' A string, one of `channels_last` (default) or
#' `channels_first`.  The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape `(batch, time, ...,
#' channels)` while `channels_first` corresponds to inputs with shape
#' `(batch, time, channels, ...)`. When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#' `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param dilation_rate
#' An integer or list of n integers, specifying the
#' dilation rate to use for dilated convolution. Currently, specifying any
#' `dilation_rate` value != 1 is incompatible with specifying any `strides`
#' value != 1.
#'
#' @param activation
#' Activation function to use. By default hyperbolic tangent
#' activation function is applied (`tanh(x)`).
#'
#' @param recurrent_activation
#' Activation function to use for the recurrent step.
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix, used for
#' the linear transformation of the inputs.
#'
#' @param recurrent_initializer
#' Initializer for the `recurrent_kernel` weights
#' matrix, used for the linear transformation of the recurrent state.
#'
#' @param bias_initializer
#' Initializer for the bias vector.
#'
#' @param unit_forget_bias
#' Boolean. If TRUE, add 1 to the bias of the forget gate
#' at initialization. Use in combination with `bias_initializer="zeros"`.
#' This is recommended in [Jozefowicz et al., 2015](
#' http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)
#'
#' @param kernel_regularizer
#' Regularizer function applied to the `kernel` weights
#' matrix.
#'
#' @param recurrent_regularizer
#' Regularizer function applied to the
#' `recurrent_kernel` weights matrix.
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector.
#'
#' @param activity_regularizer
#' Regularizer function applied to.
#'
#' @param kernel_constraint
#' Constraint function applied to the `kernel` weights
#' matrix.
#'
#' @param recurrent_constraint
#' Constraint function applied to the
#' `recurrent_kernel` weights matrix.
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector.
#'
#' @param return_sequences
#' Boolean. Whether to return the last output in the output
#' sequence, or the full sequence. (default FALSE)
#'
#' @param return_state
#' Boolean Whether to return the last state in addition to the
#' output. (default FALSE)
#'
#' @param go_backwards
#' Boolean (default FALSE). If TRUE, process the input sequence
#' backwards.
#'
#' @param stateful
#' Boolean (default FALSE). If TRUE, the last state for each sample
#' at index i in a batch will be used as initial state for the sample of
#' index i in the following batch.
#'
#' @param dropout
#' Float between 0 and 1. Fraction of the units to drop for the
#' linear transformation of the inputs.
#'
#' @param recurrent_dropout
#' Float between 0 and 1. Fraction of the units to drop
#' for the linear transformation of the recurrent state.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_conv_lstm_1d <-
function(object, filters, kernel_size, strides = 1L, padding = "valid",
    data_format = NULL, dilation_rate = 1L, activation = "tanh",
    recurrent_activation = "hard_sigmoid", use_bias = TRUE, kernel_initializer = "glorot_uniform",
    recurrent_initializer = "orthogonal", bias_initializer = "zeros",
    unit_forget_bias = TRUE, kernel_regularizer = NULL, recurrent_regularizer = NULL,
    bias_regularizer = NULL, activity_regularizer = NULL, kernel_constraint = NULL,
    recurrent_constraint = NULL, bias_constraint = NULL, return_sequences = FALSE,
    return_state = FALSE, go_backwards = FALSE, stateful = FALSE,
    dropout = 0, recurrent_dropout = 0, ...)
{
    args <- capture_args(match.call(), list(filters = as.integer,
        kernel_size = as_integer_or_integer_tuple, strides = as_integer_or_integer_tuple,
        dilation_rate = as_integer_or_integer_tuple, input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$ConvLSTM1D, object, args)
}


# <class 'keras.src.layers.rnn.conv_lstm2d.ConvLSTM2D'>
#' 2D Convolutional LSTM
#'
#' @details
#' Similar to an LSTM layer, but the input transformations
#' and recurrent transformations are both convolutional.
#'
#' Call arguments:
#'   inputs: A 5D tensor.
#'   mask: Binary tensor of shape `(samples, timesteps)` indicating whether a
#'     given timestep should be masked.
#'   training: Python boolean indicating whether the layer should behave in
#'     training mode or in inference mode. This argument is passed to the cell
#'     when calling it. This is only relevant if `dropout` or
#'     `recurrent_dropout` are set.
#'   initial_state: List of initial state tensors to be passed to the first
#'     call of the cell.
#' Input shape: - If data_format='channels_first'
#'       5D tensor with shape: `(samples, time, channels, rows, cols)` - If
#'         data_format='channels_last'
#'       5D tensor with shape: `(samples, time, rows, cols, channels)`
#' Output shape:
#'   - If `return_state`: a list of tensors. The first tensor is the output.
#'     The remaining tensors are the last states,
#'     each 4D tensor with shape: `(samples, filters, new_rows, new_cols)` if
#'       data_format='channels_first'
#'     or shape: `(samples, new_rows, new_cols, filters)` if
#'       data_format='channels_last'. `rows` and `cols` values might have
#'       changed due to padding.
#'   - If `return_sequences`: 5D tensor with shape: `(samples, timesteps,
#'     filters, new_rows, new_cols)` if data_format='channels_first'
#'     or shape: `(samples, timesteps, new_rows, new_cols, filters)` if
#'       data_format='channels_last'.
#'   - Else, 4D tensor with shape: `(samples, filters, new_rows, new_cols)` if
#'     data_format='channels_first'
#'     or shape: `(samples, new_rows, new_cols, filters)` if
#'       data_format='channels_last'.
#'
#' References:
#'   - [Shi et al., 2015](http://arxiv.org/abs/1506.04214v1)
#'   (the current implementation does not include the feedback loop on the
#'   cells output).
#'
#' @param filters
#' Integer, the dimensionality of the output space (i.e. the number
#' of output filters in the convolution).
#'
#' @param kernel_size
#' An integer or list of n integers, specifying the
#' dimensions of the convolution window.
#'
#' @param strides
#' An integer or list of n integers, specifying the strides of
#' the convolution. Specifying any stride value != 1 is incompatible with
#' specifying any `dilation_rate` value != 1.
#'
#' @param padding
#' One of `"valid"` or `"same"` (case-insensitive). `"valid"` means
#' no padding. `"same"` results in padding evenly to the left/right or
#' up/down of the input such that output has the same height/width
#' dimension as the input.
#'
#' @param data_format
#' A string, one of `channels_last` (default) or
#' `channels_first`.  The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape `(batch, time, ...,
#' channels)` while `channels_first` corresponds to inputs with shape
#' `(batch, time, channels, ...)`. When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#' `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param dilation_rate
#' An integer or list of n integers, specifying the
#' dilation rate to use for dilated convolution. Currently, specifying any
#' `dilation_rate` value != 1 is incompatible with specifying any `strides`
#' value != 1.
#'
#' @param activation
#' Activation function to use. By default hyperbolic tangent
#' activation function is applied (`tanh(x)`).
#'
#' @param recurrent_activation
#' Activation function to use for the recurrent step.
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix, used for
#' the linear transformation of the inputs.
#'
#' @param recurrent_initializer
#' Initializer for the `recurrent_kernel` weights
#' matrix, used for the linear transformation of the recurrent state.
#'
#' @param bias_initializer
#' Initializer for the bias vector.
#'
#' @param unit_forget_bias
#' Boolean. If TRUE, add 1 to the bias of the forget gate
#' at initialization. Use in combination with `bias_initializer="zeros"`.
#' This is recommended in [Jozefowicz et al., 2015](
#' http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)
#'
#' @param kernel_regularizer
#' Regularizer function applied to the `kernel` weights
#' matrix.
#'
#' @param recurrent_regularizer
#' Regularizer function applied to the
#' `recurrent_kernel` weights matrix.
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector.
#'
#' @param activity_regularizer
#' Regularizer function applied to.
#'
#' @param kernel_constraint
#' Constraint function applied to the `kernel` weights
#' matrix.
#'
#' @param recurrent_constraint
#' Constraint function applied to the
#' `recurrent_kernel` weights matrix.
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector.
#'
#' @param return_sequences
#' Boolean. Whether to return the last output in the output
#' sequence, or the full sequence. (default FALSE)
#'
#' @param return_state
#' Boolean Whether to return the last state in addition to the
#' output. (default FALSE)
#'
#' @param go_backwards
#' Boolean (default FALSE). If TRUE, process the input sequence
#' backwards.
#'
#' @param stateful
#' Boolean (default FALSE). If TRUE, the last state for each sample
#' at index i in a batch will be used as initial state for the sample of
#' index i in the following batch.
#'
#' @param dropout
#' Float between 0 and 1. Fraction of the units to drop for the
#' linear transformation of the inputs.
#'
#' @param recurrent_dropout
#' Float between 0 and 1. Fraction of the units to drop
#' for the linear transformation of the recurrent state.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_conv_lstm_2d <-
function(object, filters, kernel_size, strides = list(1L, 1L),
    padding = "valid", data_format = NULL, dilation_rate = list(
        1L, 1L), activation = "tanh", recurrent_activation = "hard_sigmoid",
    use_bias = TRUE, kernel_initializer = "glorot_uniform", recurrent_initializer = "orthogonal",
    bias_initializer = "zeros", unit_forget_bias = TRUE, kernel_regularizer = NULL,
    recurrent_regularizer = NULL, bias_regularizer = NULL, activity_regularizer = NULL,
    kernel_constraint = NULL, recurrent_constraint = NULL, bias_constraint = NULL,
    return_sequences = FALSE, return_state = FALSE, go_backwards = FALSE,
    stateful = FALSE, dropout = 0, recurrent_dropout = 0, ...)
{
    args <- capture_args(match.call(), list(filters = as.integer,
        kernel_size = as_integer_or_integer_tuple, input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape,
        dilation_rate = as_integer_or_integer_tuple, strides = as_integer_or_integer_tuple),
        ignore = "object")
    create_layer(keras$layers$ConvLSTM2D, object, args)
}


# <class 'keras.src.layers.rnn.conv_lstm3d.ConvLSTM3D'>
#' 3D Convolutional LSTM
#'
#' @details
#' Similar to an LSTM layer, but the input transformations
#' and recurrent transformations are both convolutional.
#'
#' Call arguments:
#'   inputs: A 6D tensor.
#'   mask: Binary tensor of shape `(samples, timesteps)` indicating whether a
#'     given timestep should be masked.
#'   training: Python boolean indicating whether the layer should behave in
#'     training mode or in inference mode. This argument is passed to the cell
#'     when calling it. This is only relevant if `dropout` or
#'     `recurrent_dropout` are set.
#'   initial_state: List of initial state tensors to be passed to the first
#'     call of the cell.
#' Input shape: - If data_format='channels_first'
#'       6D tensor with shape: `(samples, time, channels, rows, cols, depth)` -
#'         If data_format='channels_last'
#'       5D tensor with shape: `(samples, time, rows, cols, depth, channels)`
#' Output shape:
#'   - If `return_state`: a list of tensors. The first tensor is the output.
#'     The remaining tensors are the last states,
#'     each 5D tensor with shape: `(samples, filters, new_rows, new_cols,
#'       new_depth)` if data_format='channels_first'
#'     or shape: `(samples, new_rows, new_cols, new_depth, filters)` if
#'       data_format='channels_last'. `rows`, `cols`, and `depth` values might
#'       have changed due to padding.
#'   - If `return_sequences`: 6D tensor with shape: `(samples, timesteps,
#'     filters, new_rows, new_cols, new_depth)` if data_format='channels_first'
#'     or shape: `(samples, timesteps, new_rows, new_cols, new_depth, filters)`
#'       if data_format='channels_last'.
#'   - Else, 5D tensor with shape: `(samples, filters, new_rows, new_cols,
#'     new_depth)` if data_format='channels_first'
#'     or shape: `(samples, new_rows, new_cols, new_depth, filters)` if
#'       data_format='channels_last'.
#'
#' References:
#'   - [Shi et al., 2015](http://arxiv.org/abs/1506.04214v1)
#'   (the current implementation does not include the feedback loop on the
#'   cells output).
#'
#' @param filters
#' Integer, the dimensionality of the output space (i.e. the number
#' of output filters in the convolution).
#'
#' @param kernel_size
#' An integer or list of n integers, specifying the
#' dimensions of the convolution window.
#'
#' @param strides
#' An integer or list of n integers, specifying the strides of
#' the convolution. Specifying any stride value != 1 is incompatible with
#' specifying any `dilation_rate` value != 1.
#'
#' @param padding
#' One of `"valid"` or `"same"` (case-insensitive). `"valid"` means
#' no padding. `"same"` results in padding evenly to the left/right or
#' up/down of the input such that output has the same height/width
#' dimension as the input.
#'
#' @param data_format
#' A string, one of `channels_last` (default) or
#' `channels_first`. The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape `(batch, time, ...,
#' channels)` while `channels_first` corresponds to inputs with shape
#' `(batch, time, channels, ...)`. When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#' `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param dilation_rate
#' An integer or list of n integers, specifying the
#' dilation rate to use for dilated convolution. Currently, specifying any
#' `dilation_rate` value != 1 is incompatible with specifying any `strides`
#' value != 1.
#'
#' @param activation
#' Activation function to use. By default hyperbolic tangent
#' activation function is applied (`tanh(x)`).
#'
#' @param recurrent_activation
#' Activation function to use for the recurrent step.
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix, used for
#' the linear transformation of the inputs.
#'
#' @param recurrent_initializer
#' Initializer for the `recurrent_kernel` weights
#' matrix, used for the linear transformation of the recurrent state.
#'
#' @param bias_initializer
#' Initializer for the bias vector.
#'
#' @param unit_forget_bias
#' Boolean. If TRUE, add 1 to the bias of the forget gate
#' at initialization. Use in combination with `bias_initializer="zeros"`.
#' This is recommended in [Jozefowicz et al., 2015](
#' http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)
#'
#' @param kernel_regularizer
#' Regularizer function applied to the `kernel` weights
#' matrix.
#'
#' @param recurrent_regularizer
#' Regularizer function applied to the
#' `recurrent_kernel` weights matrix.
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector.
#'
#' @param activity_regularizer
#' Regularizer function applied to.
#'
#' @param kernel_constraint
#' Constraint function applied to the `kernel` weights
#' matrix.
#'
#' @param recurrent_constraint
#' Constraint function applied to the
#' `recurrent_kernel` weights matrix.
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector.
#'
#' @param return_sequences
#' Boolean. Whether to return the last output in the output
#' sequence, or the full sequence. (default FALSE)
#'
#' @param return_state
#' Boolean Whether to return the last state in addition to the
#' output. (default FALSE)
#'
#' @param go_backwards
#' Boolean (default FALSE). If TRUE, process the input sequence
#' backwards.
#'
#' @param stateful
#' Boolean (default FALSE). If TRUE, the last state for each sample
#' at index i in a batch will be used as initial state for the sample of
#' index i in the following batch.
#'
#' @param dropout
#' Float between 0 and 1. Fraction of the units to drop for the
#' linear transformation of the inputs.
#'
#' @param recurrent_dropout
#' Float between 0 and 1. Fraction of the units to drop
#' for the linear transformation of the recurrent state.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_conv_lstm_3d <-
function(object, filters, kernel_size, strides = list(1L, 1L,
    1L), padding = "valid", data_format = NULL, dilation_rate = list(
    1L, 1L, 1L), activation = "tanh", recurrent_activation = "hard_sigmoid",
    use_bias = TRUE, kernel_initializer = "glorot_uniform", recurrent_initializer = "orthogonal",
    bias_initializer = "zeros", unit_forget_bias = TRUE, kernel_regularizer = NULL,
    recurrent_regularizer = NULL, bias_regularizer = NULL, activity_regularizer = NULL,
    kernel_constraint = NULL, recurrent_constraint = NULL, bias_constraint = NULL,
    return_sequences = FALSE, return_state = FALSE, go_backwards = FALSE,
    stateful = FALSE, dropout = 0, recurrent_dropout = 0, ...)
{
    args <- capture_args(match.call(), list(filters = as.integer,
        kernel_size = as_integer_or_integer_tuple, input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape,
        dilation_rate = as_integer_or_integer_tuple, strides = as_integer_or_integer_tuple),
        ignore = "object")
    create_layer(keras$layers$ConvLSTM3D, object, args)
}


# <class 'keras.src.layers.convolutional.conv1d.Conv1D'>
#' 1D convolution layer (e.g. temporal convolution)
#'
#' @details
#' This layer creates a convolution kernel that is convolved
#' with the layer input over a single spatial (or temporal) dimension
#' to produce a tensor of outputs.
#' If `use_bias` is TRUE, a bias vector is created and added to the outputs.
#' Finally, if `activation` is not `NULL`,
#' it is applied to the outputs as well.
#'
#' When using this layer as the first layer in a model,
#' provide an `input_shape` argument
#' (list of integers or `NULL`, e.g.
#' `(10, 128)` for sequences of 10 vectors of 128-dimensional vectors,
#' or `(NULL, 128)` for variable-length sequences of 128-dimensional vectors.
#'
#' ```python
#' >>> # The inputs are 128-length vectors with 10 timesteps, and the
#' >>> # batch size is 4.
#' >>> input_shape = (4, 10, 128)
#' >>> x = tf.random.normal(input_shape)
#' >>> y = tf.keras.layers.Conv1D(
#' ... 32, 3, activation='relu',input_shape=input_shape[1:])(x)
#' >>> print(y.shape)
#' (4, 8, 32)
#' ```
#'
#' ```python
#' >>> # With extended batch shape [4, 7] (e.g. weather data where batch
#' >>> # dimensions correspond to spatial location and the third dimension
#' >>> # corresponds to time.)
#' >>> input_shape = (4, 7, 10, 128)
#' >>> x = tf.random.normal(input_shape)
#' >>> y = tf.keras.layers.Conv1D(
#' ... 32, 3, activation='relu', input_shape=input_shape[2:])(x)
#' >>> print(y.shape)
#' (4, 7, 8, 32)
#' ```
#'
#' Input shape:
#'   3+D tensor with shape: `batch_shape + (steps, input_dim)`
#'
#' Output shape:
#'   3+D tensor with shape: `batch_shape + (new_steps, filters)`
#'     `steps` value might have changed due to padding or strides.
#'
#'   A tensor of rank 3 representing
#'
#' @param filters
#' Integer, the dimensionality of the output space
#' (i.e. the number of output filters in the convolution).
#'
#' @param kernel_size
#' An integer or list of a single integer,
#' specifying the length of the 1D convolution window.
#'
#' @param strides
#' An integer or list of a single integer,
#' specifying the stride length of the convolution.
#' Specifying any stride value != 1 is incompatible with specifying
#' any `dilation_rate` value != 1.
#'
#' @param padding
#' One of `"valid"`, `"same"` or `"causal"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding with zeros
#' evenly to the left/right or up/down of the input such that output has
#' the same height/width dimension as the input.
#' `"causal"` results in causal (dilated) convolutions, e.g. `output[t]`
#' does not depend on `input[t+1:]`. Useful when modeling temporal data
#' where the model should not violate the temporal order.
#' See [WaveNet: A Generative Model for Raw Audio, section
#'   2.1](https://arxiv.org/abs/1609.03499).
#'
#' @param data_format
#' A string, one of `channels_last` (default) or
#' `channels_first`. The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape `(batch_size, width,
#' channels)` while `channels_first` corresponds to inputs with shape
#' `(batch_size, channels, width)`. Note that the `channels_first` format
#' is currently not supported by TensorFlow on CPU.
#'
#' @param dilation_rate
#' an integer or list of a single integer, specifying
#' the dilation rate to use for dilated convolution.
#' Currently, specifying any `dilation_rate` value != 1 is
#' incompatible with specifying any `strides` value != 1.
#'
#' @param groups
#' A positive integer specifying the number of groups in which the
#' input is split along the channel axis. Each group is convolved
#' separately with `filters / groups` filters. The output is the
#' concatenation of all the `groups` results along the channel axis.
#' Input channels and `filters` must both be divisible by `groups`.
#'
#' @param activation
#' Activation function to use.
#' If you don't specify anything, no activation is applied
#' (see `keras.activations`).
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix
#' (see `keras.initializers`). Defaults to 'glorot_uniform'.
#'
#' @param bias_initializer
#' Initializer for the bias vector
#' (see `keras.initializers`). Defaults to 'zeros'.
#'
#' @param kernel_regularizer
#' Regularizer function applied to
#' the `kernel` weights matrix (see `keras.regularizers`).
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector
#' (see `keras.regularizers`).
#'
#' @param activity_regularizer
#' Regularizer function applied to
#' the output of the layer (its "activation")
#' (see `keras.regularizers`).
#'
#' @param kernel_constraint
#' Constraint function applied to the kernel matrix
#' (see `keras.constraints`).
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector
#' (see `keras.constraints`).
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_conv_1d <-
function(object, filters, kernel_size, strides = 1L, padding = "valid",
    data_format = "channels_last", dilation_rate = 1L, groups = 1L,
    activation = NULL, use_bias = TRUE, kernel_initializer = "glorot_uniform",
    bias_initializer = "zeros", kernel_regularizer = NULL, bias_regularizer = NULL,
    activity_regularizer = NULL, kernel_constraint = NULL, bias_constraint = NULL,
    ...)
{
    args <- capture_args(match.call(), list(filters = as.integer,
        kernel_size = as_integer_or_integer_tuple, strides = as_integer_or_integer_tuple,
        dilation_rate = as_integer_or_integer_tuple, groups = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$Conv1D, object, args)
}


# <class 'keras.src.layers.convolutional.conv1d_transpose.Conv1DTranspose'>
#' Transposed convolution layer (sometimes called Deconvolution)
#'
#' @details
#' The need for transposed convolutions generally arises
#' from the desire to use a transformation going in the opposite direction
#' of a normal convolution, i.e., from something that has the shape of the
#' output of some convolution to something that has the shape of its input
#' while maintaining a connectivity pattern that is compatible with
#' said convolution.
#'
#' When using this layer as the first layer in a model,
#' provide the keyword argument `input_shape`
#' (list of integers or `NULL`, does not include the sample axis),
#' e.g. `input_shape=(128, 3)` for data with 128 time steps and 3 channels.
#'
#' Input shape:
#'   3D tensor with shape:
#'   `(batch_size, steps, channels)`
#'
#' Output shape:
#'   3D tensor with shape:
#'   `(batch_size, new_steps, filters)`
#'   If `output_padding` is specified:
#'   ```
#'   new_timesteps = ((timesteps - 1) * strides + kernel_size -
#'   2 * padding + output_padding)
#'   ```
#'
#'   A tensor of rank 3 representing
#'
#' References:
#'   - [A guide to convolution arithmetic for deep learning](
#'     https://arxiv.org/abs/1603.07285v1)
#'   - [Deconvolutional Networks](
#'     https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)
#'
#' @param filters
#' Integer, the dimensionality of the output space
#' (i.e. the number of output filters in the convolution).
#'
#' @param kernel_size
#' An integer length of the 1D convolution window.
#'
#' @param strides
#' An integer specifying the stride of the convolution along the
#' time dimension. Specifying a stride value != 1 is incompatible with
#' specifying a `dilation_rate` value != 1. Defaults to `1`.
#'
#' @param padding
#' one of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding with zeros
#' evenly to the left/right or up/down of the input such that output has
#' the same height/width dimension as the input.
#'
#' @param output_padding
#' An integer specifying the amount of padding along
#' the time dimension of the output tensor.
#' The amount of output padding must be lower than the stride.
#' If set to `NULL` (default), the output shape is inferred.
#'
#' @param data_format
#' A string, one of `channels_last` (default) or
#' `channels_first`.  The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch_size, length, channels)` while `channels_first` corresponds to
#' inputs with shape `(batch_size, channels, length)`.
#'
#' @param dilation_rate
#' an integer, specifying
#' the dilation rate to use for dilated convolution.
#' Currently, specifying a `dilation_rate` value != 1 is
#' incompatible with specifying a stride value != 1.
#' Also dilation rate larger than 1 is not currently supported.
#'
#' @param activation
#' Activation function to use.
#' If you don't specify anything, no activation is applied
#' (see `keras.activations`).
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix
#' (see `keras.initializers`). Defaults to 'glorot_uniform'.
#'
#' @param bias_initializer
#' Initializer for the bias vector
#' (see `keras.initializers`). Defaults to 'zeros'.
#'
#' @param kernel_regularizer
#' Regularizer function applied to
#' the `kernel` weights matrix (see `keras.regularizers`).
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector
#' (see `keras.regularizers`).
#'
#' @param activity_regularizer
#' Regularizer function applied to
#' the output of the layer (its "activation") (see `keras.regularizers`).
#'
#' @param kernel_constraint
#' Constraint function applied to the kernel matrix
#' (see `keras.constraints`).
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector
#' (see `keras.constraints`).
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_conv_1d_transpose <-
function(object, filters, kernel_size, strides = 1L, padding = "valid",
    output_padding = NULL, data_format = NULL, dilation_rate = 1L,
    activation = NULL, use_bias = TRUE, kernel_initializer = "glorot_uniform",
    bias_initializer = "zeros", kernel_regularizer = NULL, bias_regularizer = NULL,
    activity_regularizer = NULL, kernel_constraint = NULL, bias_constraint = NULL,
    ...)
{
    args <- capture_args(match.call(), list(filters = as.integer,
        kernel_size = as_integer_or_integer_tuple, strides = as_integer_or_integer_tuple,
        dilation_rate = as_integer_or_integer_tuple, input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$Conv1DTranspose, object, args)
}


# <class 'keras.src.layers.convolutional.conv2d.Conv2D'>
#' 2D convolution layer (e.g. spatial convolution over images)
#'
#' @details
#' This layer creates a convolution kernel that is convolved
#' with the layer input to produce a tensor of
#' outputs. If `use_bias` is TRUE,
#' a bias vector is created and added to the outputs. Finally, if
#' `activation` is not `NULL`, it is applied to the outputs as well.
#'
#' When using this layer as the first layer in a model,
#' provide the keyword argument `input_shape`
#' (list of integers or `NULL`, does not include the sample axis),
#' e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures
#' in `data_format="channels_last"`. You can use `NULL` when
#' a dimension has variable size.
#'
#' ```python
#' >>> # The inputs are 28x28 RGB images with `channels_last` and the batch
#' >>> # size is 4.
#' >>> input_shape = (4, 28, 28, 3)
#' >>> x = tf.random.normal(input_shape)
#' >>> y = tf.keras.layers.Conv2D(
#' ... 2, 3, activation='relu', input_shape=input_shape[1:])(x)
#' >>> print(y.shape)
#' (4, 26, 26, 2)
#' ```
#'
#' ```python
#' >>> # With `dilation_rate` as 2.
#' >>> input_shape = (4, 28, 28, 3)
#' >>> x = tf.random.normal(input_shape)
#' >>> y = tf.keras.layers.Conv2D(
#' ...     2, 3,
#' ...     activation='relu',
#' ...     dilation_rate=2,
#' ...     input_shape=input_shape[1:])(x)
#' >>> print(y.shape)
#' (4, 24, 24, 2)
#' ```
#'
#' ```python
#' >>> # With `padding` as "same".
#' >>> input_shape = (4, 28, 28, 3)
#' >>> x = tf.random.normal(input_shape)
#' >>> y = tf.keras.layers.Conv2D(
#' ... 2, 3, activation='relu', padding="same", input_shape=input_shape[1:])(x)
#' >>> print(y.shape)
#' (4, 28, 28, 2)
#' ```
#'
#' ```python
#' >>> # With extended batch shape [4, 7]:
#' >>> input_shape = (4, 7, 28, 28, 3)
#' >>> x = tf.random.normal(input_shape)
#' >>> y = tf.keras.layers.Conv2D(
#' ... 2, 3, activation='relu', input_shape=input_shape[2:])(x)
#' >>> print(y.shape)
#' (4, 7, 26, 26, 2)
#' ```
#'
#' Input shape:
#'   4+D tensor with shape: `batch_shape + (channels, rows, cols)` if
#'     `data_format='channels_first'`
#'   or 4+D tensor with shape: `batch_shape + (rows, cols, channels)` if
#'     `data_format='channels_last'`.
#'
#' Output shape:
#'   4+D tensor with shape: `batch_shape + (filters, new_rows, new_cols)` if
#'   `data_format='channels_first'` or 4+D tensor with shape: `batch_shape +
#'     (new_rows, new_cols, filters)` if `data_format='channels_last'`.  `rows`
#'     and `cols` values might have changed due to padding.
#'
#'   A tensor of rank 4+ representing
#'
#' @param filters
#' Integer, the dimensionality of the output space (i.e. the number
#' of output filters in the convolution).
#'
#' @param kernel_size
#' An integer or list of 2 integers, specifying the height
#' and width of the 2D convolution window. Can be a single integer to
#' specify the same value for all spatial dimensions.
#'
#' @param strides
#' An integer or list of 2 integers, specifying the strides of
#' the convolution along the height and width. Can be a single integer to
#' specify the same value for all spatial dimensions. Specifying any stride
#' value != 1 is incompatible with specifying any `dilation_rate` value !=
#' 1.
#'
#' @param padding
#' one of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding with zeros
#' evenly to the left/right or up/down of the input. When `padding="same"`
#' and `strides=1`, the output has the same size as the input.
#'
#' @param data_format
#' A string, one of `channels_last` (default) or
#' `channels_first`.  The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape `(batch_size, height,
#' width, channels)` while `channels_first` corresponds to inputs with
#' shape `(batch_size, channels, height, width)`. If left unspecified, it
#' uses the `image_data_format` value found in your Keras config file at
#' `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Note that the `channels_first` format is currently not
#' supported by TensorFlow on CPU. Defaults to 'channels_last'.
#'
#' @param dilation_rate
#' an integer or list of 2 integers, specifying the
#' dilation rate to use for dilated convolution. Can be a single integer to
#' specify the same value for all spatial dimensions. Currently, specifying
#' any `dilation_rate` value != 1 is incompatible with specifying any
#' stride value != 1.
#'
#' @param groups
#' A positive integer specifying the number of groups in which the
#' input is split along the channel axis. Each group is convolved
#' separately with `filters / groups` filters. The output is the
#' concatenation of all the `groups` results along the channel axis. Input
#' channels and `filters` must both be divisible by `groups`.
#'
#' @param activation
#' Activation function to use. If you don't specify anything, no
#' activation is applied (see `keras.activations`).
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix (see
#' `keras.initializers`). Defaults to 'glorot_uniform'.
#'
#' @param bias_initializer
#' Initializer for the bias vector (see
#' `keras.initializers`). Defaults to 'zeros'.
#'
#' @param kernel_regularizer
#' Regularizer function applied to the `kernel` weights
#' matrix (see `keras.regularizers`).
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector (see
#' `keras.regularizers`).
#'
#' @param activity_regularizer
#' Regularizer function applied to the output of the
#' layer (its "activation") (see `keras.regularizers`).
#'
#' @param kernel_constraint
#' Constraint function applied to the kernel matrix (see
#' `keras.constraints`).
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector (see
#' `keras.constraints`).
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_conv_2d <-
function(object, filters, kernel_size, strides = list(1L, 1L),
    padding = "valid", data_format = NULL, dilation_rate = list(
        1L, 1L), groups = 1L, activation = NULL, use_bias = TRUE,
    kernel_initializer = "glorot_uniform", bias_initializer = "zeros",
    kernel_regularizer = NULL, bias_regularizer = NULL, activity_regularizer = NULL,
    kernel_constraint = NULL, bias_constraint = NULL, ...)
{
    args <- capture_args(match.call(), list(filters = as.integer,
        kernel_size = as_integer_or_integer_tuple, groups = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape, dilation_rate = as_integer_or_integer_tuple,
        strides = as_integer_or_integer_tuple), ignore = "object")
    create_layer(keras$layers$Conv2D, object, args)
}


# <class 'keras.src.layers.convolutional.conv2d_transpose.Conv2DTranspose'>
#' Transposed convolution layer (sometimes called Deconvolution)
#'
#' @details
#' The need for transposed convolutions generally arises
#' from the desire to use a transformation going in the opposite direction
#' of a normal convolution, i.e., from something that has the shape of the
#' output of some convolution to something that has the shape of its input
#' while maintaining a connectivity pattern that is compatible with
#' said convolution.
#'
#' When using this layer as the first layer in a model,
#' provide the keyword argument `input_shape`
#' (list of integers or `NULL`, does not include the sample axis),
#' e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures
#' in `data_format="channels_last"`.
#'
#' Input shape:
#'   4D tensor with shape:
#'   `(batch_size, channels, rows, cols)` if data_format='channels_first'
#'   or 4D tensor with shape:
#'   `(batch_size, rows, cols, channels)` if data_format='channels_last'.
#'
#' Output shape:
#'   4D tensor with shape:
#'   `(batch_size, filters, new_rows, new_cols)` if
#'   data_format='channels_first'
#'   or 4D tensor with shape:
#'   `(batch_size, new_rows, new_cols, filters)` if
#'   data_format='channels_last'.  `rows` and `cols` values might have changed
#'   due to padding.
#'   If `output_padding` is specified:
#'   ```
#'   new_rows = ((rows - 1) * strides[0] + kernel_size[0] - 2 * padding[0] +
#'   output_padding[0])
#'   new_cols = ((cols - 1) * strides[1] + kernel_size[1] - 2 * padding[1] +
#'   output_padding[1])
#'   ```
#'
#'   A tensor of rank 4 representing
#'
#' References:
#'   - [A guide to convolution arithmetic for deep
#'     learning](https://arxiv.org/abs/1603.07285v1)
#'   - [Deconvolutional
#'     Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)
#'
#' @param filters
#' Integer, the dimensionality of the output space
#' (i.e. the number of output filters in the convolution).
#'
#' @param kernel_size
#' An integer or list of 2 integers, specifying the
#' height and width of the 2D convolution window.
#' Can be a single integer to specify the same value for
#' all spatial dimensions.
#'
#' @param strides
#' An integer or list of 2 integers,
#' specifying the strides of the convolution along the height and width.
#' Can be a single integer to specify the same value for
#' all spatial dimensions.
#' Specifying any stride value != 1 is incompatible with specifying
#' any `dilation_rate` value != 1.
#'
#' @param padding
#' one of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding with zeros
#' evenly to the left/right or up/down of the input such that output has
#' the same height/width dimension as the input.
#'
#' @param output_padding
#' An integer or list of 2 integers,
#' specifying the amount of padding along the height and width
#' of the output tensor.
#' Can be a single integer to specify the same value for all
#' spatial dimensions.
#' The amount of output padding along a given dimension must be
#' lower than the stride along that same dimension.
#' If set to `NULL` (default), the output shape is inferred.
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch_size, height, width, channels)` while `channels_first`
#' corresponds to inputs with shape
#' `(batch_size, channels, height, width)`.
#' When unspecified, uses `image_data_format` value found in your Keras
#' config file at `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to "channels_last".
#'
#' @param dilation_rate
#' an integer, specifying the dilation rate for all spatial
#' dimensions for dilated convolution. Specifying different dilation rates
#' for different dimensions is not supported.
#' Currently, specifying any `dilation_rate` value != 1 is
#' incompatible with specifying any stride value != 1.
#'
#' @param activation
#' Activation function to use.
#' If you don't specify anything, no activation is applied
#' (see `keras.activations`).
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix
#' (see `keras.initializers`). Defaults to 'glorot_uniform'.
#'
#' @param bias_initializer
#' Initializer for the bias vector
#' (see `keras.initializers`). Defaults to 'zeros'.
#'
#' @param kernel_regularizer
#' Regularizer function applied to
#' the `kernel` weights matrix (see `keras.regularizers`).
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector
#' (see `keras.regularizers`).
#'
#' @param activity_regularizer
#' Regularizer function applied to
#' the output of the layer (its "activation") (see `keras.regularizers`).
#'
#' @param kernel_constraint
#' Constraint function applied to the kernel matrix
#' (see `keras.constraints`).
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector
#' (see `keras.constraints`).
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_conv_2d_transpose <-
function(object, filters, kernel_size, strides = list(1L, 1L),
    padding = "valid", output_padding = NULL, data_format = NULL,
    dilation_rate = list(1L, 1L), activation = NULL, use_bias = TRUE,
    kernel_initializer = "glorot_uniform", bias_initializer = "zeros",
    kernel_regularizer = NULL, bias_regularizer = NULL, activity_regularizer = NULL,
    kernel_constraint = NULL, bias_constraint = NULL, ...)
{
    args <- capture_args(match.call(), list(filters = as.integer,
        kernel_size = as_integer_or_integer_tuple, input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape,
        dilation_rate = as_integer_or_integer_tuple, strides = as_integer_or_integer_tuple),
        ignore = "object")
    create_layer(keras$layers$Conv2DTranspose, object, args)
}


# <class 'keras.src.layers.convolutional.conv3d.Conv3D'>
#' 3D convolution layer (e.g. spatial convolution over volumes)
#'
#' @details
#' This layer creates a convolution kernel that is convolved
#' with the layer input to produce a tensor of
#' outputs. If `use_bias` is TRUE,
#' a bias vector is created and added to the outputs. Finally, if
#' `activation` is not `NULL`, it is applied to the outputs as well.
#'
#' When using this layer as the first layer in a model,
#' provide the keyword argument `input_shape`
#' (list of integers or `NULL`, does not include the sample axis),
#' e.g. `input_shape=(128, 128, 128, 1)` for 128x128x128 volumes
#' with a single channel,
#' in `data_format="channels_last"`.
#'
#' ```python
#' >>> # The inputs are 28x28x28 volumes with a single channel, and the
#' >>> # batch size is 4
#' >>> input_shape =(4, 28, 28, 28, 1)
#' >>> x = tf.random.normal(input_shape)
#' >>> y = tf.keras.layers.Conv3D(
#' ... 2, 3, activation='relu', input_shape=input_shape[1:])(x)
#' >>> print(y.shape)
#' (4, 26, 26, 26, 2)
#' ```
#'
#' ```python
#' >>> # With extended batch shape [4, 7], e.g. a batch of 4 videos of
#' >>> # 3D frames, with 7 frames per video.
#' >>> input_shape = (4, 7, 28, 28, 28, 1)
#' >>> x = tf.random.normal(input_shape)
#' >>> y = tf.keras.layers.Conv3D(
#' ... 2, 3, activation='relu', input_shape=input_shape[2:])(x)
#' >>> print(y.shape)
#' (4, 7, 26, 26, 26, 2)
#' ```
#'
#' Input shape:
#'   5+D tensor with shape: `batch_shape + (channels, conv_dim1, conv_dim2,
#'     conv_dim3)` if data_format='channels_first'
#'   or 5+D tensor with shape: `batch_shape + (conv_dim1, conv_dim2, conv_dim3,
#'     channels)` if data_format='channels_last'.
#'
#' Output shape:
#'   5+D tensor with shape: `batch_shape + (filters, new_conv_dim1,
#'     new_conv_dim2, new_conv_dim3)` if data_format='channels_first'
#'   or 5+D tensor with shape: `batch_shape + (new_conv_dim1, new_conv_dim2,
#'     new_conv_dim3, filters)` if data_format='channels_last'.
#'     `new_conv_dim1`, `new_conv_dim2` and `new_conv_dim3` values might have
#'     changed due to padding.
#'
#'   A tensor of rank 5+ representing
#'
#' @param filters
#' Integer, the dimensionality of the output space (i.e. the number
#' of output filters in the convolution).
#'
#' @param kernel_size
#' An integer or list of 3 integers, specifying the depth,
#' height and width of the 3D convolution window. Can be a single integer
#' to specify the same value for all spatial dimensions.
#'
#' @param strides
#' An integer or list of 3 integers, specifying the strides of
#' the convolution along each spatial dimension. Can be a single integer to
#' specify the same value for all spatial dimensions. Specifying any stride
#' value != 1 is incompatible with specifying any `dilation_rate` value !=
#' 1.
#'
#' @param padding
#' one of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding with zeros
#' evenly to the left/right or up/down of the input such that output has
#' the same height/width dimension as the input.
#'
#' @param data_format
#' A string, one of `channels_last` (default) or
#' `channels_first`.  The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape `batch_shape +
#' (spatial_dim1, spatial_dim2, spatial_dim3, channels)` while
#' `channels_first` corresponds to inputs with shape `batch_shape +
#' (channels, spatial_dim1, spatial_dim2, spatial_dim3)`. When unspecified,
#' uses `image_data_format` value found in your Keras config file at
#' `~/.keras/keras.json` (if exists) else 'channels_last'. Note that the
#' `channels_first` format is currently not supported by TensorFlow on CPU.
#' Defaults to 'channels_last'.
#'
#' @param dilation_rate
#' an integer or list of 3 integers, specifying the
#' dilation rate to use for dilated convolution. Can be a single integer to
#' specify the same value for all spatial dimensions. Currently, specifying
#' any `dilation_rate` value != 1 is incompatible with specifying any
#' stride value != 1.
#'
#' @param groups
#' A positive integer specifying the number of groups in which the
#' input is split along the channel axis. Each group is convolved
#' separately with `filters / groups` filters. The output is the
#' concatenation of all the `groups` results along the channel axis. Input
#' channels and `filters` must both be divisible by `groups`.
#'
#' @param activation
#' Activation function to use. If you don't specify anything, no
#' activation is applied (see `keras.activations`).
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix (see
#' `keras.initializers`). Defaults to 'glorot_uniform'.
#'
#' @param bias_initializer
#' Initializer for the bias vector (see
#' `keras.initializers`). Defaults to 'zeros'.
#'
#' @param kernel_regularizer
#' Regularizer function applied to the `kernel` weights
#' matrix (see `keras.regularizers`).
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector (see
#' `keras.regularizers`).
#'
#' @param activity_regularizer
#' Regularizer function applied to the output of the
#' layer (its "activation") (see `keras.regularizers`).
#'
#' @param kernel_constraint
#' Constraint function applied to the kernel matrix (see
#' `keras.constraints`).
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector (see
#' `keras.constraints`).
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_conv_3d <-
function(object, filters, kernel_size, strides = list(1L, 1L,
    1L), padding = "valid", data_format = NULL, dilation_rate = list(
    1L, 1L, 1L), groups = 1L, activation = NULL, use_bias = TRUE,
    kernel_initializer = "glorot_uniform", bias_initializer = "zeros",
    kernel_regularizer = NULL, bias_regularizer = NULL, activity_regularizer = NULL,
    kernel_constraint = NULL, bias_constraint = NULL, ...)
{
    args <- capture_args(match.call(), list(filters = as.integer,
        kernel_size = as_integer_or_integer_tuple, groups = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape, dilation_rate = as_integer_or_integer_tuple,
        strides = as_integer_or_integer_tuple), ignore = "object")
    create_layer(keras$layers$Conv3D, object, args)
}


# <class 'keras.src.layers.convolutional.conv3d_transpose.Conv3DTranspose'>
#' Transposed convolution layer (sometimes called Deconvolution)
#'
#' @details
#' The need for transposed convolutions generally arises
#' from the desire to use a transformation going in the opposite direction
#' of a normal convolution, i.e., from something that has the shape of the
#' output of some convolution to something that has the shape of its input
#' while maintaining a connectivity pattern that is compatible with
#' said convolution.
#'
#' When using this layer as the first layer in a model,
#' provide the keyword argument `input_shape`
#' (list of integers or `NULL`, does not include the sample axis),
#' e.g. `input_shape=(128, 128, 128, 3)` for a 128x128x128 volume with 3
#' channels if `data_format="channels_last"`.
#'
#' Input shape:
#'   5D tensor with shape:
#'   `(batch_size, channels, depth, rows, cols)` if
#'   data_format='channels_first'
#'   or 5D tensor with shape:
#'   `(batch_size, depth, rows, cols, channels)` if
#'   data_format='channels_last'.
#'
#' Output shape:
#'   5D tensor with shape:
#'   `(batch_size, filters, new_depth, new_rows, new_cols)` if
#'     data_format='channels_first'
#'   or 5D tensor with shape:
#'   `(batch_size, new_depth, new_rows, new_cols, filters)` if
#'     data_format='channels_last'.
#'   `depth` and `rows` and `cols` values might have changed due to padding.
#'   If `output_padding` is specified::
#'   ```
#'   new_depth = ((depth - 1) * strides[0] + kernel_size[0] - 2 * padding[0] +
#'   output_padding[0])
#'   new_rows = ((rows - 1) * strides[1] + kernel_size[1] - 2 * padding[1] +
#'   output_padding[1])
#'   new_cols = ((cols - 1) * strides[2] + kernel_size[2] - 2 * padding[2] +
#'   output_padding[2])
#'   ```
#'
#'   A tensor of rank 5 representing
#'
#' References:
#'   - [A guide to convolution arithmetic for deep
#'     learning](https://arxiv.org/abs/1603.07285v1)
#'   - [Deconvolutional
#'     Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)
#'
#' @param filters
#' Integer, the dimensionality of the output space
#' (i.e. the number of output filters in the convolution).
#'
#' @param kernel_size
#' An integer or list of 3 integers, specifying the
#' depth, height and width of the 3D convolution window.
#' Can be a single integer to specify the same value for
#' all spatial dimensions.
#'
#' @param strides
#' An integer or list of 3 integers,
#' specifying the strides of the convolution along the depth, height
#'   and width.
#' Can be a single integer to specify the same value for
#' all spatial dimensions.
#' Specifying any stride value != 1 is incompatible with specifying
#' any `dilation_rate` value != 1.
#'
#' @param padding
#' one of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding with zeros
#' evenly to the left/right or up/down of the input such that output has
#' the same height/width dimension as the input.
#'
#' @param output_padding
#' An integer or list of 3 integers,
#' specifying the amount of padding along the depth, height, and
#' width.
#' Can be a single integer to specify the same value for all
#' spatial dimensions.
#' The amount of output padding along a given dimension must be
#' lower than the stride along that same dimension.
#' If set to `NULL` (default), the output shape is inferred.
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch_size, depth, height, width, channels)` while `channels_first`
#' corresponds to inputs with shape
#' `(batch_size, channels, depth, height, width)`.
#' When unspecified, uses `image_data_format` value found in your Keras
#' config file at `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param dilation_rate
#' an integer or list of 3 integers, specifying
#' the dilation rate to use for dilated convolution.
#' Can be a single integer to specify the same value for
#' all spatial dimensions.
#' Currently, specifying any `dilation_rate` value != 1 is
#' incompatible with specifying any stride value != 1.
#'
#' @param activation
#' Activation function to use.
#' If you don't specify anything, no activation is applied
#' (see `keras.activations`).
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix
#' (see `keras.initializers`). Defaults to 'glorot_uniform'.
#'
#' @param bias_initializer
#' Initializer for the bias vector
#' (see `keras.initializers`). Defaults to 'zeros'.
#'
#' @param kernel_regularizer
#' Regularizer function applied to
#' the `kernel` weights matrix
#' (see `keras.regularizers`).
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector
#' (see `keras.regularizers`).
#'
#' @param activity_regularizer
#' Regularizer function applied to
#' the output of the layer (its "activation")
#' (see `keras.regularizers`).
#'
#' @param kernel_constraint
#' Constraint function applied to the kernel matrix
#' (see `keras.constraints`).
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector
#' (see `keras.constraints`).
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_conv_3d_transpose <-
function(object, filters, kernel_size, strides = list(1L, 1L,
    1L), padding = "valid", output_padding = NULL, data_format = NULL,
    dilation_rate = list(1L, 1L, 1L), activation = NULL, use_bias = TRUE,
    kernel_initializer = "glorot_uniform", bias_initializer = "zeros",
    kernel_regularizer = NULL, bias_regularizer = NULL, activity_regularizer = NULL,
    kernel_constraint = NULL, bias_constraint = NULL, ...)
{
    args <- capture_args(match.call(), list(filters = as.integer,
        kernel_size = as_integer_or_integer_tuple, input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape,
        dilation_rate = as_integer_or_integer_tuple, strides = as_integer_or_integer_tuple),
        ignore = "object")
    create_layer(keras$layers$Conv3DTranspose, object, args)
}


# <class 'keras.src.layers.reshaping.cropping1d.Cropping1D'>
#' Cropping layer for 1D input (e.g. temporal sequence)
#'
#' @details
#' It crops along the time dimension (axis 1).
#'
#' ```python
#' >>> input_shape = (2, 3, 2)
#' >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)
#' >>> print(x)
#' [[[ 0  1]
#'   [ 2  3]
#'   [ 4  5]]
#'  [[ 6  7]
#'   [ 8  9]
#'   [10 11]]]
#' >>> y = tf.keras.layers.Cropping1D(cropping=1)(x)
#' >>> print(y)
#' tf.Tensor(
#'   [[[2 3]]
#'    [[8 9]]], shape=(2, 1, 2), dtype=int64)
#' ```
#'
#' Input shape:
#'   3D tensor with shape `(batch_size, axis_to_crop, features)`
#'
#' Output shape:
#'   3D tensor with shape `(batch_size, cropped_axis, features)`
#'
#' @param cropping
#' Int or list of int (length 2)
#' How many units should be trimmed off at the beginning and end of
#' the cropping dimension (axis 1).
#' If a single int is provided, the same value will be used for both.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_cropping_1d <-
function(object, cropping = list(1L, 1L), ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$Cropping1D, object, args)
}


# <class 'keras.src.layers.reshaping.cropping2d.Cropping2D'>
#' Cropping layer for 2D input (e.g. picture)
#'
#' @details
#' It crops along spatial dimensions, i.e. height and width.
#'
#' ```python
#' >>> input_shape = (2, 28, 28, 3)
#' >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)
#' >>> y = tf.keras.layers.Cropping2D(cropping=((2, 2), (4, 4)))(x)
#' >>> print(y.shape)
#' (2, 24, 20, 3)
#' ```
#'
#' Input shape:
#'   4D tensor with shape:
#'   - If `data_format` is `"channels_last"`:
#'     `(batch_size, rows, cols, channels)`
#'   - If `data_format` is `"channels_first"`:
#'     `(batch_size, channels, rows, cols)`
#'
#' Output shape:
#'   4D tensor with shape:
#'   - If `data_format` is `"channels_last"`:
#'     `(batch_size, cropped_rows, cropped_cols, channels)`
#'   - If `data_format` is `"channels_first"`:
#'     `(batch_size, channels, cropped_rows, cropped_cols)`
#'
#' @param cropping
#' Int, or list of 2 ints, or list of 2 lists of 2 ints.
#' - If int: the same symmetric cropping
#'   is applied to height and width.
#' - If list of 2 ints:
#'   interpreted as two different
#'   symmetric cropping values for height and width:
#'   `(symmetric_height_crop, symmetric_width_crop)`.
#' - If list of 2 lists of 2 ints:
#'   interpreted as
#'   `((top_crop, bottom_crop), (left_crop, right_crop))`
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch_size, height, width, channels)` while `channels_first`
#' corresponds to inputs with shape
#' `(batch_size, channels, height, width)`.
#' When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#'  `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_cropping_2d <-
function(object, cropping = list(list(0L, 0L), list(0L, 0L)),
    data_format = NULL, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$Cropping2D, object, args)
}


# <class 'keras.src.layers.reshaping.cropping3d.Cropping3D'>
#' Cropping layer for 3D data (e.g. spatial or spatio-temporal)
#'
#' @details
#' Examples:
#'
#' ```python
#' >>> input_shape = (2, 28, 28, 10, 3)
#' >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)
#' >>> y = tf.keras.layers.Cropping3D(cropping=(2, 4, 2))(x)
#' >>> print(y.shape)
#' (2, 24, 20, 6, 3)
#' ```
#'
#' Input shape:
#'   5D tensor with shape:
#'   - If `data_format` is `"channels_last"`:
#'     `(batch_size, first_axis_to_crop, second_axis_to_crop,
#'     third_axis_to_crop, depth)`
#'   - If `data_format` is `"channels_first"`:
#'     `(batch_size, depth, first_axis_to_crop, second_axis_to_crop,
#'       third_axis_to_crop)`
#'
#' Output shape:
#'   5D tensor with shape:
#'   - If `data_format` is `"channels_last"`:
#'     `(batch_size, first_cropped_axis, second_cropped_axis,
#'     third_cropped_axis, depth)`
#'   - If `data_format` is `"channels_first"`:
#'     `(batch_size, depth, first_cropped_axis, second_cropped_axis,
#'       third_cropped_axis)`
#'
#' @param cropping
#' Int, or list of 3 ints, or list of 3 lists of 2 ints.
#' - If int: the same symmetric cropping
#'   is applied to depth, height, and width.
#' - If list of 3 ints: interpreted as two different
#'   symmetric cropping values for depth, height, and width:
#'   `(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop)`.
#' - If list of 3 lists of 2 ints: interpreted as
#'   `((left_dim1_crop, right_dim1_crop), (left_dim2_crop,
#'     right_dim2_crop), (left_dim3_crop, right_dim3_crop))`
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`
#' while `channels_first` corresponds to inputs with shape
#' `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.
#' When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#'  `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_cropping_3d <-
function(object, cropping = list(list(1L, 1L), list(1L, 1L),
    list(1L, 1L)), data_format = NULL, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$Cropping3D, object, args)
}


# <class 'keras.src.layers.core.dense.Dense'>
#' Just your regular densely-connected NN layer
#'
#' @details
#' `Dense` implements the operation:
#' `output = activation(dot(input, kernel) + bias)`
#' where `activation` is the element-wise activation function
#' passed as the `activation` argument, `kernel` is a weights matrix
#' created by the layer, and `bias` is a bias vector created by the layer
#' (only applicable if `use_bias` is `TRUE`). These are all attributes of
#' `Dense`.
#'
#' Note: If the input to the layer has a rank greater than 2, then `Dense`
#' computes the dot product between the `inputs` and the `kernel` along the
#' last axis of the `inputs` and axis 0 of the `kernel` (using `tf.tensordot`).
#' For example, if input has dimensions `(batch_size, d0, d1)`, then we create
#' a `kernel` with shape `(d1, units)`, and the `kernel` operates along axis 2
#' of the `input`, on every sub-tensor of shape `(1, 1, d1)` (there are
#' `batch_size * d0` such sub-tensors).  The output in this case will have
#' shape `(batch_size, d0, units)`.
#'
#' Besides, layer attributes cannot be modified after the layer has been called
#' once (except the `trainable` attribute).
#' When a popular kwarg `input_shape` is passed, then keras will create
#' an input layer to insert before the current layer. This can be treated
#' equivalent to explicitly defining an `InputLayer`.
#'
#' Example:
#'
#' ```python
#' >>> # Create a `Sequential` model and add a Dense layer as the first layer.
#' >>> model = tf.keras.models.Sequential()
#' >>> model.add(tf.keras.Input(shape=(16,)))
#' >>> model.add(tf.keras.layers.Dense(32, activation='relu'))
#' >>> # Now the model will take as input arrays of shape (NULL, 16)
#' >>> # and output arrays of shape (NULL, 32).
#' >>> # Note that after the first layer, you don't need to specify
#' >>> # the size of the input anymore:
#' >>> model.add(tf.keras.layers.Dense(32))
#' >>> model.output_shape
#' (NULL, 32)
#' ```
#'
#' Input shape:
#'     N-D tensor with shape: `(batch_size, ..., input_dim)`.
#'     The most common situation would be
#'     a 2D input with shape `(batch_size, input_dim)`.
#'
#' Output shape:
#'     N-D tensor with shape: `(batch_size, ..., units)`.
#'     For instance, for a 2D input with shape `(batch_size, input_dim)`,
#'     the output would have shape `(batch_size, units)`.
#'
#' @param units
#' Positive integer, dimensionality of the output space.
#'
#' @param activation
#' Activation function to use.
#' If you don't specify anything, no activation is applied
#' (ie. "linear" activation: `a(x) = x`).
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix.
#'
#' @param bias_initializer
#' Initializer for the bias vector.
#'
#' @param kernel_regularizer
#' Regularizer function applied to
#' the `kernel` weights matrix.
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector.
#'
#' @param activity_regularizer
#' Regularizer function applied to
#' the output of the layer (its "activation").
#'
#' @param kernel_constraint
#' Constraint function applied to
#' the `kernel` weights matrix.
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_dense <-
function(object, units, activation = NULL, use_bias = TRUE,
    kernel_initializer = "glorot_uniform", bias_initializer = "zeros",
    kernel_regularizer = NULL, bias_regularizer = NULL, activity_regularizer = NULL,
    kernel_constraint = NULL, bias_constraint = NULL, ...)
{
    args <- capture_args(match.call(), list(units = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$Dense, object, args)
}


# <class 'keras.src.feature_column.dense_features_v2.DenseFeatures'>
#' A layer that produces a dense `Tensor` based on given `feature_columns`
#'
#' @details
#' Generally a single example in training data is described with
#' FeatureColumns.  At the first layer of the model, this column oriented data
#' should be converted to a single `Tensor`.
#'
#' This layer can be called multiple times with different features.
#'
#' This is the V2 version of this layer that uses name_scopes to create
#' variables instead of variable_scopes. But this approach currently lacks
#' support for partitioned variables. In that case, use the V1 version instead.
#'
#' Example:
#'
#' ```python
#' price = tf.feature_column.numeric_column('price')
#' keywords_embedded = tf.feature_column.embedding_column(
#'     tf.feature_column.categorical_column_with_hash_bucket("keywords",
#'                                                           10000),
#'     dimensions=16)
#' columns = [price, keywords_embedded, ...]
#' feature_layer = tf.keras.layers.DenseFeatures(columns)
#'
#' features = tf.io.parse_example(
#'     ..., features=tf.feature_column.make_parse_example_spec(columns))
#' dense_tensor = feature_layer(features)
#' for units in [128, 64, 32]:
#'   dense_tensor = tf.keras.layers.Dense(units, activation='relu')(
#'     dense_tensor)
#' prediction = tf.keras.layers.Dense(1)(dense_tensor)
#' ```
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_dense_features <-
function(object, feature_columns, trainable = TRUE, name = NULL,
    ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$DenseFeatures, object, args)
}


# <class 'keras.src.layers.convolutional.depthwise_conv1d.DepthwiseConv1D'>
#' Depthwise 1D convolution
#'
#' @details
#' Depthwise convolution is a type of convolution in which each input channel
#' is convolved with a different kernel (called a depthwise kernel). You can
#' understand depthwise convolution as the first step in a depthwise separable
#' convolution.
#'
#' It is implemented via the following steps:
#'
#' - Split the input into individual channels.
#' - Convolve each channel with an individual depthwise kernel with
#'   `depth_multiplier` output channels.
#' - Concatenate the convolved outputs along the channels axis.
#'
#' Unlike a regular 1D convolution, depthwise convolution does not mix
#' information across different input channels.
#'
#' The `depth_multiplier` argument determines how many filter are applied to
#' one input channel. As such, it controls the amount of output channels that
#' are generated per input channel in the depthwise step.
#'
#' Input shape:
#'   3D tensor with shape: `[batch_size, channels, input_dim]` if
#'     data_format='channels_first'
#'   or 3D tensor with shape: `[batch_size, input_dim, channels]` if
#'     data_format='channels_last'.
#'
#' Output shape:
#'   3D tensor with shape:
#'    `[batch_size, channels * depth_multiplier, new_dims]`
#'     if `data_format='channels_first'`
#'     or 3D tensor with shape: `[batch_size,
#'     new_dims, channels * depth_multiplier]` if
#'     `data_format='channels_last'`. `new_dims` values might have
#'     changed due to padding.
#'
#'   A tensor of rank 3 representing
#'
#' @param kernel_size
#' An integer, specifying the height and width of the 1D
#' convolution window. Can be a single integer to specify the same value
#' for all spatial dimensions.
#'
#' @param strides
#' An integer, specifying the strides of the convolution along the
#' height and width. Can be a single integer to specify the same value for
#' all spatial dimensions. Specifying any stride value != 1 is incompatible
#' with specifying any `dilation_rate` value != 1.
#'
#' @param padding
#' one of `'valid'` or `'same'` (case-insensitive). `"valid"` means
#' no padding. `"same"` results in padding with zeros evenly to the
#' left/right or up/down of the input such that output has the same
#' height/width dimension as the input.
#'
#' @param depth_multiplier
#' The number of depthwise convolution output channels for
#' each input channel. The total number of depthwise convolution output
#' channels will be equal to `filters_in * depth_multiplier`.
#'
#' @param data_format
#' A string, one of `channels_last` (default) or
#' `channels_first`.  The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape `(batch_size, height,
#' width, channels)` while `channels_first` corresponds to inputs with
#' shape `(batch_size, channels, height, width)`. When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#' `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param dilation_rate
#' A single integer, specifying the dilation rate to use for
#' dilated convolution. Currently, specifying any `dilation_rate`
#' value != 1 is incompatible with specifying any stride value != 1.
#'
#' @param activation
#' Activation function to use. If you don't specify anything, no
#' activation is applied (see `keras.activations`).
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias vector.
#'
#' @param depthwise_initializer
#' Initializer for the depthwise kernel matrix (see
#' `keras.initializers`). If NULL, the default initializer
#' ('glorot_uniform') will be used.
#'
#' @param bias_initializer
#' Initializer for the bias vector (see
#' `keras.initializers`). If NULL, the default initializer ('zeros') will
#' be used.
#'
#' @param depthwise_regularizer
#' Regularizer function applied to the depthwise
#' kernel matrix (see `keras.regularizers`).
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector (see
#' `keras.regularizers`).
#'
#' @param activity_regularizer
#' Regularizer function applied to the output of the
#' layer (its 'activation') (see `keras.regularizers`).
#'
#' @param depthwise_constraint
#' Constraint function applied to the depthwise kernel
#' matrix (see `keras.constraints`).
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector (see
#' `keras.constraints`).
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_depthwise_conv_1d <-
function(object, kernel_size, strides = 1L, padding = "valid",
    depth_multiplier = 1L, data_format = NULL, dilation_rate = 1L,
    activation = NULL, use_bias = TRUE, depthwise_initializer = "glorot_uniform",
    bias_initializer = "zeros", depthwise_regularizer = NULL,
    bias_regularizer = NULL, activity_regularizer = NULL, depthwise_constraint = NULL,
    bias_constraint = NULL, ...)
{
    args <- capture_args(match.call(), list(kernel_size = as.integer,
        strides = as.integer, depth_multiplier = as.integer,
        dilation_rate = as.integer, input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$DepthwiseConv1D, object, args)
}


# <class 'keras.src.layers.convolutional.depthwise_conv2d.DepthwiseConv2D'>
#' Depthwise 2D convolution
#'
#' @details
#' Depthwise convolution is a type of convolution in which each input channel
#' is convolved with a different kernel (called a depthwise kernel). You can
#' understand depthwise convolution as the first step in a depthwise separable
#' convolution.
#'
#' It is implemented via the following steps:
#'
#' - Split the input into individual channels.
#' - Convolve each channel with an individual depthwise kernel with
#'   `depth_multiplier` output channels.
#' - Concatenate the convolved outputs along the channels axis.
#'
#' Unlike a regular 2D convolution, depthwise convolution does not mix
#' information across different input channels.
#'
#' The `depth_multiplier` argument determines how many filter are applied to
#' one input channel. As such, it controls the amount of output channels that
#' are generated per input channel in the depthwise step.
#'
#' Input shape:
#'   4D tensor with shape: `[batch_size, channels, rows, cols]` if
#'     data_format='channels_first'
#'   or 4D tensor with shape: `[batch_size, rows, cols, channels]` if
#'     data_format='channels_last'.
#'
#' Output shape:
#'   4D tensor with shape: `[batch_size, channels * depth_multiplier, new_rows,
#'     new_cols]` if `data_format='channels_first'`
#'     or 4D tensor with shape: `[batch_size,
#'     new_rows, new_cols, channels * depth_multiplier]` if
#'     `data_format='channels_last'`. `rows` and `cols` values might have
#'     changed due to padding.
#'
#'   A tensor of rank 4 representing
#'
#' @param kernel_size
#' An integer or list of 2 integers, specifying the height
#' and width of the 2D convolution window. Can be a single integer to
#' specify the same value for all spatial dimensions.
#'
#' @param strides
#' An integer or list of 2 integers, specifying the strides of
#' the convolution along the height and width. Can be a single integer to
#' specify the same value for all spatial dimensions. Current
#' implementation only supports equal length strides in row and
#' column dimensions. Specifying any stride value != 1 is incompatible
#' with specifying any `dilation_rate` value !=1.
#'
#' @param padding
#' one of `'valid'` or `'same'` (case-insensitive). `"valid"` means
#' no padding. `"same"` results in padding with zeros evenly to the
#' left/right or up/down of the input such that output has the same
#' height/width dimension as the input.
#'
#' @param depth_multiplier
#' The number of depthwise convolution output channels for
#' each input channel. The total number of depthwise convolution output
#' channels will be equal to `filters_in * depth_multiplier`.
#'
#' @param data_format
#' A string, one of `channels_last` (default) or
#' `channels_first`. The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape `(batch_size, height,
#' width, channels)` while `channels_first` corresponds to inputs with
#' shape `(batch_size, channels, height, width)`. When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#'  `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param dilation_rate
#' An integer or list of 2 integers, specifying the
#' dilation rate to use for dilated convolution. Currently, specifying any
#' `dilation_rate` value != 1 is incompatible with specifying any `strides`
#' value != 1.
#'
#' @param activation
#' Activation function to use. If you don't specify anything, no
#' activation is applied (see `keras.activations`).
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias vector.
#'
#' @param depthwise_initializer
#' Initializer for the depthwise kernel matrix (see
#' `keras.initializers`). If NULL, the default initializer
#' ('glorot_uniform') will be used.
#'
#' @param bias_initializer
#' Initializer for the bias vector (see
#' `keras.initializers`). If NULL, the default initializer ('zeros') will
#' be used.
#'
#' @param depthwise_regularizer
#' Regularizer function applied to the depthwise
#' kernel matrix (see `keras.regularizers`).
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector (see
#' `keras.regularizers`).
#'
#' @param activity_regularizer
#' Regularizer function applied to the output of the
#' layer (its 'activation') (see `keras.regularizers`).
#'
#' @param depthwise_constraint
#' Constraint function applied to the depthwise kernel
#' matrix (see `keras.constraints`).
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector (see
#' `keras.constraints`).
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_depthwise_conv_2d <-
function(object, kernel_size, strides = list(1L, 1L), padding = "valid",
    depth_multiplier = 1L, data_format = NULL, dilation_rate = list(
        1L, 1L), activation = NULL, use_bias = TRUE, depthwise_initializer = "glorot_uniform",
    bias_initializer = "zeros", depthwise_regularizer = NULL,
    bias_regularizer = NULL, activity_regularizer = NULL, depthwise_constraint = NULL,
    bias_constraint = NULL, ...)
{
    args <- capture_args(match.call(), list(kernel_size = as.integer,
        depth_multiplier = as.integer, input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$DepthwiseConv2D, object, args)
}


# <class 'keras.src.layers.preprocessing.discretization.Discretization'>
#' A preprocessing layer which buckets continuous features by ranges
#'
#' @details
#' This layer will place each element of its input data into one of several
#' contiguous ranges and output an integer index indicating which range each
#' element was placed in.
#'
#' For an overview and full list of preprocessing layers, see the preprocessing
#' [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).
#'
#' Input shape:
#'   Any `tf.Tensor` or `tf.RaggedTensor` of dimension 2 or higher.
#'
#' Output shape:
#'   Same as input shape.
#'
#' Arguments:
#'
#' Bucketize float values based on provided buckets.
#' ```python
#' >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])
#' >>> layer = tf.keras.layers.Discretization(bin_boundaries=[0., 1., 2.])
#' >>> layer(input)
#' <tf.Tensor: shape=(2, 4), dtype=int64, numpy=
#' array([[0, 2, 3, 1],
#'        [1, 3, 2, 1]])>
#' ```
#'
#' Bucketize float values based on a number of buckets to compute.
#' ```python
#' >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])
#' >>> layer = tf.keras.layers.Discretization(num_bins=4, epsilon=0.01)
#' >>> layer.adapt(input)
#' >>> layer(input)
#' <tf.Tensor: shape=(2, 4), dtype=int64, numpy=
#' array([[0, 2, 3, 2],
#'        [1, 3, 3, 1]])>
#' ```
#'
#' @param bin_boundaries
#' A list of bin boundaries. The leftmost and rightmost bins
#' will always extend to `-inf` and `inf`, so `bin_boundaries=[0., 1., 2.]`
#' generates bins `(-inf, 0.)`, `[0., 1.)`, `[1., 2.)`, and `[2., +inf)`.
#' If this option is set, `adapt()` should not be called.
#'
#' @param num_bins
#' The integer number of bins to compute. If this option is set,
#' `adapt()` should be called to learn the bin boundaries.
#'
#' @param epsilon
#' Error tolerance, typically a small fraction close to zero (e.g.
#' 0.01). Higher values of epsilon increase the quantile approximation, and
#' hence result in more unequal buckets, but could improve performance
#' and resource consumption.
#'
#' @param output_mode
#' Specification for the output of the layer. Values can be
#' `"int"`, `"one_hot"`, `"multi_hot"`, or
#' `"count"` configuring the layer as follows:
#'   - `"int"`: Return the discretized bin indices directly.
#'   - `"one_hot"`: Encodes each individual element in the input into an
#'     array the same size as `num_bins`, containing a 1 at the input's bin
#'     index. If the last dimension is size 1, will encode on that
#'     dimension.  If the last dimension is not size 1, will append a new
#'     dimension for the encoded output.
#'   - `"multi_hot"`: Encodes each sample in the input into a single array
#'     the same size as `num_bins`, containing a 1 for each bin index
#'     index present in the sample. Treats the last dimension as the sample
#'     dimension, if input shape is `(..., sample_length)`, output shape
#'     will be `(..., num_tokens)`.
#'   - `"count"`: As `"multi_hot"`, but the int array contains a count of
#'     the number of times the bin index appeared in the sample.
#' Defaults to `"int"`.
#'
#' @param sparse
#' Boolean. Only applicable to `"one_hot"`, `"multi_hot"`,
#' and `"count"` output modes. If TRUE, returns a `SparseTensor` instead of
#' a dense `Tensor`. Defaults to `FALSE`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_discretization <-
function(object, bin_boundaries = NULL, num_bins = NULL, epsilon = 0.01,
    output_mode = "int", sparse = FALSE, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$Discretization, object, args)
}


# <class 'keras.src.layers.merging.dot.Dot'>
#' Layer that computes a dot product between samples in two tensors
#'
#' @details
#' E.g. if applied to a list of two tensors `a` and `b` of shape
#' `(batch_size, n)`, the output will be a tensor of shape `(batch_size, 1)`
#' where each entry `i` will be the dot product between
#' `a[i]` and `b[i]`.
#'
#' ```python
#' >>> x = np.arange(10).reshape(1, 5, 2)
#' >>> print(x)
#' [[[0 1]
#'   [2 3]
#'   [4 5]
#'   [6 7]
#'   [8 9]]]
#' >>> y = np.arange(10, 20).reshape(1, 2, 5)
#' >>> print(y)
#' [[[10 11 12 13 14]
#'   [15 16 17 18 19]]]
#' >>> tf.keras.layers.Dot(axes=(1, 2))([x, y])
#' <tf.Tensor: shape=(1, 2, 2), dtype=int64, numpy=
#' array([[[260, 360],
#'         [320, 445]]])>
#' ```
#'
#' ```python
#' >>> x1 = tf.keras.layers.Dense(8)(np.arange(10).reshape(5, 2))
#' >>> x2 = tf.keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))
#' >>> dotted = tf.keras.layers.Dot(axes=1)([x1, x2])
#' >>> dotted.shape
#' TensorShape([5, 1])
#' ```
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_dot <-
function(inputs, ..., axes, normalize = FALSE)
{
    args <- capture_args(match.call(), list(axes = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = c("...",
        "inputs"))
    dots <- split_dots_named_unnamed(list(...))
    if (missing(inputs))
        inputs <- NULL
    else if (!is.null(inputs) && !is.list(inputs))
        inputs <- list(inputs)
    inputs <- c(inputs, dots$unnamed)
    args <- c(args, dots$named)
    layer <- do.call(keras$layers$Dot, args)
    if (length(inputs))
        layer(inputs)
    else layer
}


# <class 'keras.src.layers.regularization.dropout.Dropout'>
#' Applies Dropout to the input
#'
#' @details
#' The Dropout layer randomly sets input units to 0 with a frequency of `rate`
#' at each step during training time, which helps prevent overfitting.
#' Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over
#' all inputs is unchanged.
#'
#' Note that the Dropout layer only applies when `training` is set to TRUE
#' such that no values are dropped during inference. When using `model.fit`,
#' `training` will be appropriately set to TRUE automatically, and in other
#' contexts, you can set the kwarg explicitly to TRUE when calling the layer.
#'
#' (This is in contrast to setting `trainable=FALSE` for a Dropout layer.
#' `trainable` does not affect the layer's behavior, as Dropout does
#' not have any variables/weights that can be frozen during training.)
#'
#' ```python
#' >>> tf.random.set_seed(0)
#' >>> layer = tf.keras.layers.Dropout(.2, input_shape=(2,))
#' >>> data = np.arange(10).reshape(5, 2).astype(np.float32)
#' >>> print(data)
#' [[0. 1.]
#'  [2. 3.]
#'  [4. 5.]
#'  [6. 7.]
#'  [8. 9.]]
#' >>> outputs = layer(data, training=TRUE)
#' >>> print(outputs)
#' tf.Tensor(
#' [[ 0.    1.25]
#'  [ 2.5   3.75]
#'  [ 5.    6.25]
#'  [ 7.5   8.75]
#'  [10.    0.  ]], shape=(5, 2), dtype=float32)
#' ```
#'
#' Call arguments:
#'   inputs: Input tensor (of any rank).
#'   training: Python boolean indicating whether the layer should behave in
#'     training mode (adding dropout) or in inference mode (doing nothing).
#'
#' @param rate
#' Float between 0 and 1. Fraction of the input units to drop.
#'
#' @param noise_shape
#' 1D integer tensor representing the shape of the
#' binary dropout mask that will be multiplied with the input.
#' For instance, if your inputs have shape
#' `(batch_size, timesteps, features)` and
#' you want the dropout mask to be the same for all timesteps,
#' you can use `noise_shape=(batch_size, 1, features)`.
#'
#' @param seed
#' A Python integer to use as random seed.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_dropout <-
function(object, rate, noise_shape = NULL, seed = NULL, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$Dropout, object, args)
}


# <class 'keras.src.layers.core.einsum_dense.EinsumDense'>
#' A layer that uses `tf.einsum` as the backing computation
#'
#' @details
#' This layer can perform einsum calculations of arbitrary dimensionality.
#'
#' **Biased dense layer with einsums**
#'
#' This example shows how to instantiate a standard Keras dense layer using
#' einsum operations. This example is equivalent to
#' `tf.keras.layers.Dense(64, use_bias=TRUE)`.
#'
#' ```python
#' >>> layer = tf.keras.layers.EinsumDense("ab,bc->ac",
#' ...                                     output_shape=64,
#' ...                                     bias_axes="c")
#' >>> input_tensor = tf.keras.Input(shape=[32])
#' >>> output_tensor = layer(input_tensor)
#' >>> output_tensor
#' <... shape=(NULL, 64) dtype=...>
#' ```
#'
#' **Applying a dense layer to a sequence**
#'
#' This example shows how to instantiate a layer that applies the same dense
#' operation to every element in a sequence. Here, the `output_shape` has two
#' values (since there are two non-batch dimensions in the output); the first
#' dimension in the `output_shape` is `NULL`, because the sequence dimension
#' `b` has an unknown shape.
#'
#' ```python
#' >>> layer = tf.keras.layers.EinsumDense("abc,cd->abd",
#' ...                                     output_shape=(NULL, 64),
#' ...                                     bias_axes="d")
#' >>> input_tensor = tf.keras.Input(shape=[32, 128])
#' >>> output_tensor = layer(input_tensor)
#' >>> output_tensor
#' <... shape=(NULL, 32, 64) dtype=...>
#' ```
#'
#' **Applying a dense layer to a sequence using ellipses**
#'
#' This example shows how to instantiate a layer that applies the same dense
#' operation to every element in a sequence, but uses the ellipsis notation
#' instead of specifying the batch and sequence dimensions.
#'
#' Because we are using ellipsis notation and have specified only one axis, the
#' `output_shape` arg is a single value. When instantiated in this way, the
#' layer can handle any number of sequence dimensions - including the case
#' where no sequence dimension exists.
#'
#' ```python
#' >>> layer = tf.keras.layers.EinsumDense("...x,xy->...y",
#' ...                                     output_shape=64,
#' ...                                     bias_axes="y")
#' >>> input_tensor = tf.keras.Input(shape=[32, 128])
#' >>> output_tensor = layer(input_tensor)
#' >>> output_tensor
#' <... shape=(NULL, 32, 64) dtype=...>
#' ```
#'
#' @param equation
#' An equation describing the einsum to perform. This equation must
#' be a valid einsum string of the form `ab,bc->ac`, `...ab,bc->...ac`, or
#' `ab...,bc->ac...` where 'ab', 'bc', and 'ac' can be any valid einsum
#' axis expression sequence.
#'
#' @param output_shape
#' The expected shape of the output tensor (excluding the batch
#' dimension and any dimensions represented by ellipses). You can specify
#' NULL for any dimension that is unknown or can be inferred from the input
#' shape.
#'
#' @param activation
#' Activation function to use. If you don't specify anything, no
#' activation is applied (that is, a "linear" activation: `a(x) = x`).
#'
#' @param bias_axes
#' A string containing the output dimension(s) to apply a bias to.
#' Each character in the `bias_axes` string should correspond to a
#' character in the output portion of the `equation` string.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix.
#'
#' @param bias_initializer
#' Initializer for the bias vector.
#'
#' @param kernel_regularizer
#' Regularizer function applied to the `kernel` weights
#' matrix.
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector.
#'
#' @param activity_regularizer
#' Regularizer function applied to the output of the
#' layer (its "activation").
#'
#' @param kernel_constraint
#' Constraint function applied to the `kernel` weights
#' matrix.
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_einsum_dense <-
function(object, equation, output_shape, activation = NULL,
    bias_axes = NULL, kernel_initializer = "glorot_uniform",
    bias_initializer = "zeros", kernel_regularizer = NULL, bias_regularizer = NULL,
    activity_regularizer = NULL, kernel_constraint = NULL, bias_constraint = NULL,
    ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$EinsumDense, object, args)
}


# <class 'keras.src.layers.activation.elu.ELU'>
#' Exponential Linear Unit
#'
#' @details
#' It follows:
#'
#' ```
#'     f(x) =  alpha * (exp(x) - 1.) for x < 0
#'     f(x) = x for x >= 0
#' ```
#'
#' Input shape:
#'     Arbitrary. Use the keyword argument `input_shape`
#'     (list of integers, does not include the samples axis)
#'     when using this layer as the first layer in a model.
#'
#' Output shape:
#'     Same shape as the input.
#'
#' @param alpha
#' Scale for the negative factor.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_activation_elu <-
function(object, alpha = 1, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$ELU, object, args)
}


# <class 'keras.src.layers.core.embedding.Embedding'>
#' Turns positive integers (indexes) into dense vectors of fixed size
#'
#' @details
#' e.g. `[[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]`
#'
#' This layer can only be used on positive integer inputs of a fixed range. The
#' `tf.keras.layers.TextVectorization`, `tf.keras.layers.StringLookup`,
#' and `tf.keras.layers.IntegerLookup` preprocessing layers can help prepare
#' inputs for an `Embedding` layer.
#'
#' This layer accepts `tf.Tensor`, `tf.RaggedTensor` and `tf.SparseTensor`
#' input.
#'
#' Example:
#'
#' ```python
#' >>> model = tf.keras.Sequential()
#' >>> model.add(tf.keras.layers.Embedding(1000, 64, input_length=10))
#' >>> # The model will take as input an integer matrix of size (batch,
#' >>> # input_length), and the largest integer (i.e. word index) in the input
#' >>> # should be no larger than 999 (vocabulary size).
#' >>> # Now model.output_shape is (NULL, 10, 64), where `NULL` is the batch
#' >>> # dimension.
#' >>> input_array = np.random.randint(1000, size=(32, 10))
#' >>> model.compile('rmsprop', 'mse')
#' >>> output_array = model.predict(input_array)
#' >>> print(output_array.shape)
#' (32, 10, 64)
#' ```
#'
#' Input shape:
#'   2D tensor with shape: `(batch_size, input_length)`.
#'
#' Output shape:
#'   3D tensor with shape: `(batch_size, input_length, output_dim)`.
#'
#' **Note on variable placement:**
#' By default, if a GPU is available, the embedding matrix will be placed on
#' the GPU. This achieves the best performance, but it might cause issues:
#'
#' - You may be using an optimizer that does not support sparse GPU kernels.
#' In this case you will see an error upon training your model.
#' - Your embedding matrix may be too large to fit on your GPU. In this case
#' you will see an Out Of Memory (OOM) error.
#'
#' In such cases, you should place the embedding matrix on the CPU memory.
#' You can do so with a device scope, as such:
#'
#' ```python
#' with tf.device('cpu:0'):
#'   embedding_layer = Embedding(...)
#'   embedding_layer.build()
#' ```
#'
#' The pre-built `embedding_layer` instance can then be added to a `Sequential`
#' model (e.g. `model.add(embedding_layer)`), called in a Functional model
#' (e.g. `x = embedding_layer(x)`), or used in a subclassed model.
#'
#' @param input_dim
#' Integer. Size of the vocabulary,
#' i.e. maximum integer index + 1.
#'
#' @param output_dim
#' Integer. Dimension of the dense embedding.
#'
#' @param embeddings_initializer
#' Initializer for the `embeddings`
#' matrix (see `keras.initializers`).
#'
#' @param embeddings_regularizer
#' Regularizer function applied to
#' the `embeddings` matrix (see `keras.regularizers`).
#'
#' @param embeddings_constraint
#' Constraint function applied to
#' the `embeddings` matrix (see `keras.constraints`).
#'
#' @param mask_zero
#' Boolean, whether or not the input value 0 is a special
#' "padding" value that should be masked out. This is useful when using
#' recurrent layers which may take variable length input. If this is
#' `TRUE`, then all subsequent layers in the model need to support masking
#' or an exception will be raised. If mask_zero is set to TRUE, as a
#' consequence, index 0 cannot be used in the vocabulary (input_dim should
#' equal size of vocabulary + 1).
#'
#' @param input_length
#' Length of input sequences, when it is constant.
#' This argument is required if you are going to connect
#' `Flatten` then `Dense` layers upstream
#' (without it, the shape of the dense outputs cannot be computed).
#'
#' @param sparse
#' If TRUE, calling this layer returns a `tf.SparseTensor`. If FALSE,
#' the layer returns a dense `tf.Tensor`. For an entry with no features in
#' a sparse tensor (entry with value 0), the embedding vector of index 0 is
#' returned by default.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_embedding <-
function(object, input_dim, output_dim, embeddings_initializer = "uniform",
    embeddings_regularizer = NULL, activity_regularizer = NULL,
    embeddings_constraint = NULL, mask_zero = FALSE, input_length = NULL,
    sparse = FALSE, ...)
{
    args <- capture_args(match.call(), list(input_dim = as.integer,
        output_dim = as.integer, input_length = as_nullable_integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$Embedding, object, args)
}


# <class 'keras.src.layers.reshaping.flatten.Flatten'>
#' Flattens the input. Does not affect the batch size
#'
#' @details
#' Note: If inputs are shaped `(batch,)` without a feature axis, then
#' flattening adds an extra channel dimension and output shape is `(batch, 1)`.
#'
#' Example:
#'
#' ```python
#' >>> model = tf.keras.Sequential()
#' >>> model.add(tf.keras.layers.Conv2D(64, 3, 3, input_shape=(3, 32, 32)))
#' >>> model.output_shape
#' (NULL, 1, 10, 64)
#' ```
#'
#' ```python
#' >>> model.add(Flatten())
#' >>> model.output_shape
#' (NULL, 640)
#' ```
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch, ..., channels)` while `channels_first` corresponds to
#' inputs with shape `(batch, channels, ...)`.
#' When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#'  `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_flatten <-
function(object, data_format = NULL, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$Flatten, object, args)
}


# <class 'keras.src.layers.regularization.gaussian_dropout.GaussianDropout'>
#' Apply multiplicative 1-centered Gaussian noise
#'
#' @details
#' As it is a regularization layer, it is only active at training time.
#'
#' Call arguments:
#'   inputs: Input tensor (of any rank).
#'   training: Python boolean indicating whether the layer should behave in
#'     training mode (adding dropout) or in inference mode (doing nothing).
#'
#' Input shape:
#'   Arbitrary. Use the keyword argument `input_shape`
#'   (list of integers, does not include the samples axis)
#'   when using this layer as the first layer in a model.
#'
#' Output shape:
#'   Same shape as input.
#'
#' @param rate
#' Float, drop probability (as with `Dropout`).
#' The multiplicative noise will have
#' standard deviation `sqrt(rate / (1 - rate))`.
#'
#' @param seed
#' Integer, optional random seed to enable deterministic behavior.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_gaussian_dropout <-
function(object, rate, seed = NULL, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$GaussianDropout, object, args)
}


# <class 'keras.src.layers.regularization.gaussian_noise.GaussianNoise'>
#' Apply additive zero-centered Gaussian noise
#'
#' @details
#' This is useful to mitigate overfitting
#' (you could see it as a form of random data augmentation).
#' Gaussian Noise (GS) is a natural choice as corruption process
#' for real valued inputs.
#'
#' As it is a regularization layer, it is only active at training time.
#'
#' Call arguments:
#'   inputs: Input tensor (of any rank).
#'   training: Python boolean indicating whether the layer should behave in
#'     training mode (adding noise) or in inference mode (doing nothing).
#'
#' Input shape:
#'   Arbitrary. Use the keyword argument `input_shape`
#'   (list of integers, does not include the samples axis)
#'   when using this layer as the first layer in a model.
#'
#' Output shape:
#'   Same shape as input.
#'
#' @param stddev
#' Float, standard deviation of the noise distribution.
#'
#' @param seed
#' Integer, optional random seed to enable deterministic behavior.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_gaussian_noise <-
function(object, stddev, seed = NULL, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$GaussianNoise, object, args)
}


# <class 'keras.src.layers.pooling.global_average_pooling1d.GlobalAveragePooling1D'>
#' Global average pooling operation for temporal data
#'
#' @details
#'
#' ```python
#' >>> input_shape = (2, 3, 4)
#' >>> x = tf.random.normal(input_shape)
#' >>> y = tf.keras.layers.GlobalAveragePooling1D()(x)
#' >>> print(y.shape)
#' (2, 4)
#' ```
#'
#' Call arguments:
#'   inputs: A 3D tensor.
#'   mask: Binary tensor of shape `(batch_size, steps)` indicating whether
#'     a given step should be masked (excluded from the average).
#'
#' Input shape:
#'   - If `data_format='channels_last'`:
#'     3D tensor with shape:
#'     `(batch_size, steps, features)`
#'   - If `data_format='channels_first'`:
#'     3D tensor with shape:
#'     `(batch_size, features, steps)`
#'
#' Output shape:
#'   - If `keepdims`=FALSE:
#'     2D tensor with shape `(batch_size, features)`.
#'   - If `keepdims`=TRUE:
#'     - If `data_format='channels_last'`:
#'       3D tensor with shape `(batch_size, 1, features)`
#'     - If `data_format='channels_first'`:
#'       3D tensor with shape `(batch_size, features, 1)`
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch, steps, features)` while `channels_first`
#' corresponds to inputs with shape
#' `(batch, features, steps)`.
#'
#' @param keepdims
#' A boolean, whether to keep the temporal dimension or not.
#' If `keepdims` is `FALSE` (default), the rank of the tensor is reduced
#' for spatial dimensions.
#' If `keepdims` is `TRUE`, the temporal dimension are retained with
#' length 1.
#' The behavior is the same as for `tf.reduce_mean` or `np.mean`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_global_average_pooling_1d <-
function(object, data_format = "channels_last", ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape,
        pool_size = as.integer, strides = as_nullable_integer),
        ignore = "object")
    create_layer(keras$layers$GlobalAveragePooling1D, object,
        args)
}


# <class 'keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D'>
#' Global average pooling operation for spatial data
#'
#' @details
#'
#' ```python
#' >>> input_shape = (2, 4, 5, 3)
#' >>> x = tf.random.normal(input_shape)
#' >>> y = tf.keras.layers.GlobalAveragePooling2D()(x)
#' >>> print(y.shape)
#' (2, 3)
#' ```
#'
#' Input shape:
#'   - If `data_format='channels_last'`:
#'     4D tensor with shape `(batch_size, rows, cols, channels)`.
#'   - If `data_format='channels_first'`:
#'     4D tensor with shape `(batch_size, channels, rows, cols)`.
#'
#' Output shape:
#'   - If `keepdims`=FALSE:
#'     2D tensor with shape `(batch_size, channels)`.
#'   - If `keepdims`=TRUE:
#'     - If `data_format='channels_last'`:
#'       4D tensor with shape `(batch_size, 1, 1, channels)`
#'     - If `data_format='channels_first'`:
#'       4D tensor with shape `(batch_size, channels, 1, 1)`
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch, height, width, channels)` while `channels_first`
#' corresponds to inputs with shape
#' `(batch, channels, height, width)`.
#' When unspecified, uses `image_data_format` value found
#' in your Keras config file at `~/.keras/keras.json`
#' (if exists) else 'channels_last'. Defaults to 'channels_last'.
#'
#' @param keepdims
#' A boolean, whether to keep the spatial dimensions or not.
#' If `keepdims` is `FALSE` (default), the rank of the tensor is reduced
#' for spatial dimensions.
#' If `keepdims` is `TRUE`, the spatial dimensions are retained with
#' length 1.
#' The behavior is the same as for `tf.reduce_mean` or `np.mean`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_global_average_pooling_2d <-
function(object, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape,
        pool_size = as.integer, strides = as_nullable_integer),
        ignore = "object")
    create_layer(keras$layers$GlobalAveragePooling2D, object,
        args)
}


# <class 'keras.src.layers.pooling.global_average_pooling3d.GlobalAveragePooling3D'>
#' Global Average pooling operation for 3D data
#'
#' @details
#'
#' Input shape:
#'   - If `data_format='channels_last'`:
#'     5D tensor with shape:
#'     `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`
#'   - If `data_format='channels_first'`:
#'     5D tensor with shape:
#'     `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`
#'
#' Output shape:
#'   - If `keepdims`=FALSE:
#'     2D tensor with shape `(batch_size, channels)`.
#'   - If `keepdims`=TRUE:
#'     - If `data_format='channels_last'`:
#'       5D tensor with shape `(batch_size, 1, 1, 1, channels)`
#'     - If `data_format='channels_first'`:
#'       5D tensor with shape `(batch_size, channels, 1, 1, 1)`
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`
#' while `channels_first` corresponds to inputs with shape
#' `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.
#' When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#'  `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param keepdims
#' A boolean, whether to keep the spatial dimensions or not.
#' If `keepdims` is `FALSE` (default), the rank of the tensor is reduced
#' for spatial dimensions.
#' If `keepdims` is `TRUE`, the spatial dimensions are retained with
#' length 1.
#' The behavior is the same as for `tf.reduce_mean` or `np.mean`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_global_average_pooling_3d <-
function(object, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape,
        pool_size = as.integer, strides = as_nullable_integer),
        ignore = "object")
    create_layer(keras$layers$GlobalAveragePooling3D, object,
        args)
}


# <class 'keras.src.layers.pooling.global_max_pooling1d.GlobalMaxPooling1D'>
#' Global max pooling operation for 1D temporal data
#'
#' @details
#' Downsamples the input representation by taking the maximum value over
#' the time dimension.
#'
#' For example:
#'
#' ```python
#' >>> x = tf.constant([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]])
#' >>> x = tf.reshape(x, [3, 3, 1])
#' >>> x
#' <tf.Tensor: shape=(3, 3, 1), dtype=float32, numpy=
#' array([[[1.], [2.], [3.]],
#'        [[4.], [5.], [6.]],
#'        [[7.], [8.], [9.]]], dtype=float32)>
#' >>> max_pool_1d = tf.keras.layers.GlobalMaxPooling1D()
#' >>> max_pool_1d(x)
#' <tf.Tensor: shape=(3, 1), dtype=float32, numpy=
#' array([[3.],
#'        [6.],
#'        [9.], dtype=float32)>
#' ```
#'
#' Input shape:
#'   - If `data_format='channels_last'`:
#'     3D tensor with shape:
#'     `(batch_size, steps, features)`
#'   - If `data_format='channels_first'`:
#'     3D tensor with shape:
#'     `(batch_size, features, steps)`
#'
#' Output shape:
#'   - If `keepdims`=FALSE:
#'     2D tensor with shape `(batch_size, features)`.
#'   - If `keepdims`=TRUE:
#'     - If `data_format='channels_last'`:
#'       3D tensor with shape `(batch_size, 1, features)`
#'     - If `data_format='channels_first'`:
#'       3D tensor with shape `(batch_size, features, 1)`
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch, steps, features)` while `channels_first`
#' corresponds to inputs with shape
#' `(batch, features, steps)`.
#'
#' @param keepdims
#' A boolean, whether to keep the temporal dimension or not.
#' If `keepdims` is `FALSE` (default), the rank of the tensor is reduced
#' for spatial dimensions.
#' If `keepdims` is `TRUE`, the temporal dimension are retained with
#' length 1.
#' The behavior is the same as for `tf.reduce_max` or `np.max`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_global_max_pooling_1d <-
function(object, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape,
        pool_size = as.integer, strides = as_nullable_integer),
        ignore = "object")
    create_layer(keras$layers$GlobalMaxPooling1D, object, args)
}


# <class 'keras.src.layers.pooling.global_max_pooling2d.GlobalMaxPooling2D'>
#' Global max pooling operation for spatial data
#'
#' @details
#'
#' ```python
#' >>> input_shape = (2, 4, 5, 3)
#' >>> x = tf.random.normal(input_shape)
#' >>> y = tf.keras.layers.GlobalMaxPooling2D()(x)
#' >>> print(y.shape)
#' (2, 3)
#' ```
#'
#' Input shape:
#'   - If `data_format='channels_last'`:
#'     4D tensor with shape `(batch_size, rows, cols, channels)`.
#'   - If `data_format='channels_first'`:
#'     4D tensor with shape `(batch_size, channels, rows, cols)`.
#'
#' Output shape:
#'   - If `keepdims`=FALSE:
#'     2D tensor with shape `(batch_size, channels)`.
#'   - If `keepdims`=TRUE:
#'     - If `data_format='channels_last'`:
#'       4D tensor with shape `(batch_size, 1, 1, channels)`
#'     - If `data_format='channels_first'`:
#'       4D tensor with shape `(batch_size, channels, 1, 1)`
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch, height, width, channels)` while `channels_first`
#' corresponds to inputs with shape
#' `(batch, channels, height, width)`.
#' When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#'  `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param keepdims
#' A boolean, whether to keep the spatial dimensions or not.
#' If `keepdims` is `FALSE` (default), the rank of the tensor is reduced
#' for spatial dimensions.
#' If `keepdims` is `TRUE`, the spatial dimensions are retained with
#' length 1.
#' The behavior is the same as for `tf.reduce_max` or `np.max`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_global_max_pooling_2d <-
function(object, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape,
        pool_size = as.integer, strides = as_nullable_integer),
        ignore = "object")
    create_layer(keras$layers$GlobalMaxPooling2D, object, args)
}


# <class 'keras.src.layers.pooling.global_max_pooling3d.GlobalMaxPooling3D'>
#' Global Max pooling operation for 3D data
#'
#' @details
#'
#' Input shape:
#'   - If `data_format='channels_last'`:
#'     5D tensor with shape:
#'     `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`
#'   - If `data_format='channels_first'`:
#'     5D tensor with shape:
#'     `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`
#'
#' Output shape:
#'   - If `keepdims`=FALSE:
#'     2D tensor with shape `(batch_size, channels)`.
#'   - If `keepdims`=TRUE:
#'     - If `data_format='channels_last'`:
#'       5D tensor with shape `(batch_size, 1, 1, 1, channels)`
#'     - If `data_format='channels_first'`:
#'       5D tensor with shape `(batch_size, channels, 1, 1, 1)`
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`
#' while `channels_first` corresponds to inputs with shape
#' `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.
#' When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#'  `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param keepdims
#' A boolean, whether to keep the spatial dimensions or not.
#' If `keepdims` is `FALSE` (default), the rank of the tensor is reduced
#' for spatial dimensions.
#' If `keepdims` is `TRUE`, the spatial dimensions are retained with
#' length 1.
#' The behavior is the same as for `tf.reduce_max` or `np.max`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_global_max_pooling_3d <-
function(object, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape,
        pool_size = as.integer, strides = as_nullable_integer),
        ignore = "object")
    create_layer(keras$layers$GlobalMaxPooling3D, object, args)
}


# <class 'keras.src.layers.normalization.group_normalization.GroupNormalization'>
#' Group normalization layer
#'
#' @details
#' Group Normalization divides the channels into groups and computes
#' within each group the mean and variance for normalization.
#' Empirically, its accuracy is more stable than batch norm in a wide
#' range of small batch sizes, if learning rate is adjusted linearly
#' with batch sizes.
#'
#' Relation to Layer Normalization:
#' If the number of groups is set to 1, then this operation becomes nearly
#' identical to Layer Normalization (see Layer Normalization docs for details).
#'
#' Relation to Instance Normalization:
#' If the number of groups is set to the input dimension (number of groups is
#' equal to number of channels), then this operation becomes identical to
#' Instance Normalization.
#'
#' Call arguments:
#'   inputs: Input tensor (of any rank).
#'   mask: The mask parameter is a tensor that indicates the weight for each
#'     position in the input tensor when computing the mean and variance.
#'
#' Reference: - [Yuxin Wu & Kaiming He, 2018](https://arxiv.org/abs/1803.08494)
#'
#' @param groups
#' Integer, the number of groups for Group Normalization. Can be in
#' the range [1, N] where N is the input dimension. The input dimension
#' must be divisible by the number of groups. Defaults to `32`.
#'
#' @param axis
#' Integer or List/Tuple. The axis or axes to normalize across.
#' Typically, this is the features axis/axes. The left-out axes are
#' typically the batch axis/axes. `-1` is the last dimension in the
#' input. Defaults to `-1`.
#'
#' @param epsilon
#' Small float added to variance to avoid dividing by zero. Defaults
#' to 1e-3
#'
#' @param center
#' If TRUE, add offset of `beta` to normalized tensor. If FALSE,
#' `beta` is ignored. Defaults to `TRUE`.
#'
#' @param scale
#' If TRUE, multiply by `gamma`. If FALSE, `gamma` is not used.
#' When the next layer is linear (also e.g. `nn.relu`), this can be
#' disabled since the scaling will be done by the next layer.
#' Defaults to `TRUE`.
#'
#' @param beta_initializer
#' Initializer for the beta weight. Defaults to zeros.
#'
#' @param gamma_initializer
#' Initializer for the gamma weight. Defaults to ones.
#'
#' @param beta_regularizer
#' Optional regularizer for the beta weight. NULL by
#' default.
#'
#' @param gamma_regularizer
#' Optional regularizer for the gamma weight. NULL by
#' default.
#'
#' @param beta_constraint
#' Optional constraint for the beta weight. NULL by default.
#'
#' @param gamma_constraint
#' Optional constraint for the gamma weight. NULL by
#' default.  Input shape: Arbitrary. Use the keyword argument `input_shape`
#' (list of integers, does not include the samples axis) when using this
#' layer as the first layer in a model.  Output shape: Same shape as input.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_group_normalization <-
function(object, groups = 32L, axis = -1L, epsilon = 0.001,
    center = TRUE, scale = TRUE, beta_initializer = "zeros",
    gamma_initializer = "ones", beta_regularizer = NULL, gamma_regularizer = NULL,
    beta_constraint = NULL, gamma_constraint = NULL, ...)
{
    args <- capture_args(match.call(), list(groups = as.integer,
        axis = as_axis, input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$GroupNormalization, object, args)
}


# <class 'keras.src.layers.rnn.gru.GRU'>
#' Gated Recurrent Unit - Cho et al. 2014
#'
#' @details
#' See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)
#' for details about the usage of RNN API.
#'
#' Based on available runtime hardware and constraints, this layer
#' will choose different implementations (cuDNN-based or pure-TensorFlow)
#' to maximize the performance. If a GPU is available and all
#' the arguments to the layer meet the requirement of the cuDNN kernel
#' (see below for details), the layer will use a fast cuDNN implementation.
#'
#' The requirements to use the cuDNN implementation are:
#'
#' 1. `activation` == `tanh`
#' 2. `recurrent_activation` == `sigmoid`
#' 3. `recurrent_dropout` == 0
#' 4. `unroll` is `FALSE`
#' 5. `use_bias` is `TRUE`
#' 6. `reset_after` is `TRUE`
#' 7. Inputs, if use masking, are strictly right-padded.
#' 8. Eager execution is enabled in the outermost context.
#'
#' There are two variants of the GRU implementation. The default one is based
#' on [v3](https://arxiv.org/abs/1406.1078v3) and has reset gate applied to
#' hidden state before matrix multiplication. The other one is based on
#' [original](https://arxiv.org/abs/1406.1078v1) and has the order reversed.
#'
#' The second variant is compatible with CuDNNGRU (GPU-only) and allows
#' inference on CPU. Thus it has separate biases for `kernel` and
#' `recurrent_kernel`. To use this variant, set `reset_after=TRUE` and
#' `recurrent_activation='sigmoid'`.
#'
#' For example:
#'
#' ```python
#' >>> inputs = tf.random.normal([32, 10, 8])
#' >>> gru = tf.keras.layers.GRU(4)
#' >>> output = gru(inputs)
#' >>> print(output.shape)
#' (32, 4)
#' >>> gru = tf.keras.layers.GRU(4, return_sequences=TRUE, return_state=TRUE)
#' >>> whole_sequence_output, final_state = gru(inputs)
#' >>> print(whole_sequence_output.shape)
#' (32, 10, 4)
#' >>> print(final_state.shape)
#' (32, 4)
#' ```
#'
#' Call arguments:
#'   inputs: A 3D tensor, with shape `[batch, timesteps, feature]`.
#'   mask: Binary tensor of shape `[samples, timesteps]` indicating whether
#'     a given timestep should be masked  (optional).
#'     An individual `TRUE` entry indicates that the corresponding timestep
#'     should be utilized, while a `FALSE` entry indicates that the
#'     corresponding timestep should be ignored. Defaults to `NULL`.
#'   training: Python boolean indicating whether the layer should behave in
#'     training mode or in inference mode. This argument is passed to the cell
#'     when calling it. This is only relevant if `dropout` or
#'     `recurrent_dropout` is used  (optional). Defaults to `NULL`.
#'   initial_state: List of initial state tensors to be passed to the first
#'     call of the cell  (optional, `NULL` causes creation
#'     of zero-filled initial state tensors). Defaults to `NULL`.
#'
#' @param units
#' Positive integer, dimensionality of the output space.
#'
#' @param activation
#' Activation function to use.
#' Default: hyperbolic tangent (`tanh`).
#' If you pass `NULL`, no activation is applied
#' (ie. "linear" activation: `a(x) = x`).
#'
#' @param recurrent_activation
#' Activation function to use
#' for the recurrent step.
#' Default: sigmoid (`sigmoid`).
#' If you pass `NULL`, no activation is applied
#' (ie. "linear" activation: `a(x) = x`).
#'
#' @param use_bias
#' Boolean, (default `TRUE`), whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix,
#' used for the linear transformation of the inputs. Default:
#' `glorot_uniform`.
#'
#' @param recurrent_initializer
#' Initializer for the `recurrent_kernel`
#' weights matrix, used for the linear transformation of the recurrent
#' state. Default: `orthogonal`.
#'
#' @param bias_initializer
#' Initializer for the bias vector. Default: `zeros`.
#'
#' @param kernel_regularizer
#' Regularizer function applied to the `kernel` weights
#' matrix. Default: `NULL`.
#'
#' @param recurrent_regularizer
#' Regularizer function applied to the
#' `recurrent_kernel` weights matrix. Default: `NULL`.
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector.
#' Default: `NULL`.
#'
#' @param activity_regularizer
#' Regularizer function applied to the output of the
#' layer (its "activation"). Default: `NULL`.
#'
#' @param kernel_constraint
#' Constraint function applied to the `kernel` weights
#' matrix. Default: `NULL`.
#'
#' @param recurrent_constraint
#' Constraint function applied to the
#' `recurrent_kernel` weights matrix. Default: `NULL`.
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector. Default:
#' `NULL`.
#'
#' @param dropout
#' Float between 0 and 1. Fraction of the units to drop for the
#' linear transformation of the inputs. Default: 0.
#'
#' @param recurrent_dropout
#' Float between 0 and 1. Fraction of the units to drop
#' for the linear transformation of the recurrent state. Default: 0.
#'
#' @param return_sequences
#' Boolean. Whether to return the last output
#' in the output sequence, or the full sequence. Default: `FALSE`.
#'
#' @param return_state
#' Boolean. Whether to return the last state in addition to the
#' output. Default: `FALSE`.
#'
#' @param go_backwards
#' Boolean (default `FALSE`).
#' If TRUE, process the input sequence backwards and return the
#' reversed sequence.
#'
#' @param stateful
#' Boolean (default FALSE). If TRUE, the last state
#' for each sample at index i in a batch will be used as initial
#' state for the sample of index i in the following batch.
#'
#' @param unroll
#' Boolean (default FALSE).
#' If TRUE, the network will be unrolled,
#' else a symbolic loop will be used.
#' Unrolling can speed-up a RNN,
#' although it tends to be more memory-intensive.
#' Unrolling is only suitable for short sequences.
#'
#' @param time_major
#' The shape format of the `inputs` and `outputs` tensors.
#' If TRUE, the inputs and outputs will be in shape
#' `[timesteps, batch, feature]`, whereas in the FALSE case, it will be
#' `[batch, timesteps, feature]`. Using `time_major = TRUE` is a bit more
#' efficient because it avoids transposes at the beginning and end of the
#' RNN calculation. However, most TensorFlow data is batch-major, so by
#' default this function accepts input and emits output in batch-major
#' form.
#'
#' @param reset_after
#' GRU convention (whether to apply reset gate after or
#' before matrix multiplication). FALSE = "before",
#' TRUE = "after" (default and cuDNN compatible).
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_gru <-
function(object, units, activation = "tanh", recurrent_activation = "sigmoid",
    use_bias = TRUE, kernel_initializer = "glorot_uniform", recurrent_initializer = "orthogonal",
    bias_initializer = "zeros", kernel_regularizer = NULL, recurrent_regularizer = NULL,
    bias_regularizer = NULL, activity_regularizer = NULL, kernel_constraint = NULL,
    recurrent_constraint = NULL, bias_constraint = NULL, dropout = 0,
    recurrent_dropout = 0, return_sequences = FALSE, return_state = FALSE,
    go_backwards = FALSE, stateful = FALSE, unroll = FALSE, time_major = FALSE,
    reset_after = TRUE, ...)
{
    args <- capture_args(match.call(), list(units = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$GRU, object, args)
}


# <class 'keras.src.layers.rnn.gru.GRUCell'>
#' Cell class for the GRU layer
#'
#' @details
#' See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)
#' for details about the usage of RNN API.
#'
#' This class processes one step within the whole time sequence input, whereas
#' `tf.keras.layer.GRU` processes the whole sequence.
#'
#' For example:
#'
#' ```python
#' >>> inputs = tf.random.normal([32, 10, 8])
#' >>> rnn = tf.keras.layers.RNN(tf.keras.layers.GRUCell(4))
#' >>> output = rnn(inputs)
#' >>> print(output.shape)
#' (32, 4)
#' >>> rnn = tf.keras.layers.RNN(
#' ...    tf.keras.layers.GRUCell(4),
#' ...    return_sequences=TRUE,
#' ...    return_state=TRUE)
#' >>> whole_sequence_output, final_state = rnn(inputs)
#' >>> print(whole_sequence_output.shape)
#' (32, 10, 4)
#' >>> print(final_state.shape)
#' (32, 4)
#' ```
#'
#' Call arguments:
#'   inputs: A 2D tensor, with shape of `[batch, feature]`.
#'   states: A 2D tensor with shape of `[batch, units]`, which is the state
#'     from the previous time step. For timestep 0, the initial state provided
#'     by user will be feed to cell.
#'   training: Python boolean indicating whether the layer should behave in
#'     training mode or in inference mode. Only relevant when `dropout` or
#'     `recurrent_dropout` is used.
#'
#' @param units
#' Positive integer, dimensionality of the output space.
#'
#' @param activation
#' Activation function to use. Default: hyperbolic tangent
#' (`tanh`). If you pass NULL, no activation is applied
#' (ie. "linear" activation: `a(x) = x`).
#'
#' @param recurrent_activation
#' Activation function to use for the recurrent step.
#' Default: sigmoid (`sigmoid`). If you pass `NULL`, no activation is
#' applied (ie. "linear" activation: `a(x) = x`).
#'
#' @param use_bias
#' Boolean, (default `TRUE`), whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix,
#' used for the linear transformation of the inputs. Default:
#' `glorot_uniform`.
#'
#' @param recurrent_initializer
#' Initializer for the `recurrent_kernel`
#' weights matrix, used for the linear transformation of the recurrent
#' state.  Default: `orthogonal`.
#'
#' @param bias_initializer
#' Initializer for the bias vector. Default: `zeros`.
#'
#' @param kernel_regularizer
#' Regularizer function applied to the `kernel` weights
#' matrix. Default: `NULL`.
#'
#' @param recurrent_regularizer
#' Regularizer function applied to the
#' `recurrent_kernel` weights matrix. Default: `NULL`.
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector.
#' Default: `NULL`.
#'
#' @param kernel_constraint
#' Constraint function applied to the `kernel` weights
#' matrix. Default: `NULL`.
#'
#' @param recurrent_constraint
#' Constraint function applied to the
#' `recurrent_kernel` weights matrix. Default: `NULL`.
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector. Default:
#' `NULL`.
#'
#' @param dropout
#' Float between 0 and 1. Fraction of the units to drop for the
#' linear transformation of the inputs. Default: 0.
#'
#' @param recurrent_dropout
#' Float between 0 and 1. Fraction of the units to drop
#' for the linear transformation of the recurrent state. Default: 0.
#'
#' @param reset_after
#' GRU convention (whether to apply reset gate after or
#' before matrix multiplication). FALSE = "before",
#' TRUE = "after" (default and cuDNN compatible).
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_gru_cell <-
function(units, activation = "tanh", recurrent_activation = "sigmoid",
    use_bias = TRUE, kernel_initializer = "glorot_uniform", recurrent_initializer = "orthogonal",
    bias_initializer = "zeros", kernel_regularizer = NULL, recurrent_regularizer = NULL,
    bias_regularizer = NULL, kernel_constraint = NULL, recurrent_constraint = NULL,
    bias_constraint = NULL, dropout = 0, recurrent_dropout = 0,
    reset_after = TRUE, ...)
{
    args <- capture_args(match.call(), list(units = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape))
    do.call(keras$layers$GRUCell, args)
}


# <class 'keras.src.layers.preprocessing.hashed_crossing.HashedCrossing'>
#' A preprocessing layer which crosses features using the "hashing trick"
#'
#' @details
#' This layer performs crosses of categorical features using the "hashing
#' trick". Conceptually, the transformation can be thought of as:
#' `hash(concatenate(features)) % num_bins`.
#'
#' This layer currently only performs crosses of scalar inputs and batches of
#' scalar inputs. Valid input shapes are `(batch_size, 1)`, `(batch_size,)` and
#' `()`.
#'
#' For an overview and full list of preprocessing layers, see the preprocessing
#' [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).
#'
#' **Crossing two scalar features.**
#'
#' ```python
#' >>> layer = tf.keras.layers.HashedCrossing(
#' ...     num_bins=5)
#' >>> feat1 = tf.constant(['A', 'B', 'A', 'B', 'A'])
#' >>> feat2 = tf.constant([101, 101, 101, 102, 102])
#' >>> layer((feat1, feat2))
#' <tf.Tensor: shape=(5,), dtype=int64, numpy=array([1, 4, 1, 1, 3])>
#' ```
#'
#' **Crossing and one-hotting two scalar features.**
#'
#' ```python
#' >>> layer = tf.keras.layers.HashedCrossing(
#' ...     num_bins=5, output_mode='one_hot')
#' >>> feat1 = tf.constant(['A', 'B', 'A', 'B', 'A'])
#' >>> feat2 = tf.constant([101, 101, 101, 102, 102])
#' >>> layer((feat1, feat2))
#' <tf.Tensor: shape=(5, 5), dtype=float32, numpy=
#'   array([[0., 1., 0., 0., 0.],
#'          [0., 0., 0., 0., 1.],
#'          [0., 1., 0., 0., 0.],
#'          [0., 1., 0., 0., 0.],
#'          [0., 0., 0., 1., 0.]], dtype=float32)>
#' ```
#'
#' @param num_bins
#' Number of hash bins.
#'
#' @param output_mode
#' Specification for the output of the layer. Values can be
#' `"int"`, or `"one_hot"` configuring the layer as follows:
#' - `"int"`: Return the integer bin indices directly.
#' - `"one_hot"`: Encodes each individual element in the input into an
#'     array the same size as `num_bins`, containing a 1 at the input's
#'     bin index. Defaults to `"int"`.
#'
#' @param sparse
#' Boolean. Only applicable to `"one_hot"` mode. If `TRUE`,
#' returns a `SparseTensor` instead of a dense `Tensor`.
#' Defaults to `FALSE`.
#'
#' @param **kwargs
#' Keyword arguments to construct a layer.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_hashed_crossing <-
function(object, num_bins, output_mode = "int", sparse = FALSE,
    ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$HashedCrossing, object, args)
}


# <class 'keras.src.layers.preprocessing.hashing.Hashing'>
#' A preprocessing layer which hashes and bins categorical features
#'
#' @details
#' This layer transforms categorical inputs to hashed output. It element-wise
#' converts a ints or strings to ints in a fixed range. The stable hash
#' function uses `tensorflow::ops::Fingerprint` to produce the same output
#' consistently across all platforms.
#'
#' This layer uses [FarmHash64](https://github.com/google/farmhash) by default,
#' which provides a consistent hashed output across different platforms and is
#' stable across invocations, regardless of device and context, by mixing the
#' input bits thoroughly.
#'
#' If you want to obfuscate the hashed output, you can also pass a random
#' `salt` argument in the constructor. In that case, the layer will use the
#' [SipHash64](https://github.com/google/highwayhash) hash function, with
#' the `salt` value serving as additional input to the hash function.
#'
#' For an overview and full list of preprocessing layers, see the preprocessing
#' [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).
#'
#' **Example (FarmHash64)**
#'
#' ```python
#' >>> layer = tf.keras.layers.Hashing(num_bins=3)
#' >>> inp = [['A'], ['B'], ['C'], ['D'], ['E']]
#' >>> layer(inp)
#' <tf.Tensor: shape=(5, 1), dtype=int64, numpy=
#'   array([[1],
#'          [0],
#'          [1],
#'          [1],
#'          [2]])>
#' ```
#'
#' **Example (FarmHash64) with a mask value**
#'
#' ```python
#' >>> layer = tf.keras.layers.Hashing(num_bins=3, mask_value='')
#' >>> inp = [['A'], ['B'], [''], ['C'], ['D']]
#' >>> layer(inp)
#' <tf.Tensor: shape=(5, 1), dtype=int64, numpy=
#'   array([[1],
#'          [1],
#'          [0],
#'          [2],
#'          [2]])>
#' ```
#'
#' **Example (SipHash64)**
#'
#' ```python
#' >>> layer = tf.keras.layers.Hashing(num_bins=3, salt=[133, 137])
#' >>> inp = [['A'], ['B'], ['C'], ['D'], ['E']]
#' >>> layer(inp)
#' <tf.Tensor: shape=(5, 1), dtype=int64, numpy=
#'   array([[1],
#'          [2],
#'          [1],
#'          [0],
#'          [2]])>
#' ```
#'
#' **Example (Siphash64 with a single integer, same as `salt=[133, 133]`)**
#'
#' ```python
#' >>> layer = tf.keras.layers.Hashing(num_bins=3, salt=133)
#' >>> inp = [['A'], ['B'], ['C'], ['D'], ['E']]
#' >>> layer(inp)
#' <tf.Tensor: shape=(5, 1), dtype=int64, numpy=
#'   array([[0],
#'          [0],
#'          [2],
#'          [1],
#'          [0]])>
#' ```
#'
#' Input shape:
#'   A single or list of string, int32 or int64 `Tensor`,
#'   `SparseTensor` or `RaggedTensor` of shape `(batch_size, ...,)`
#'
#' Output shape:
#'   An int64 `Tensor`, `SparseTensor` or `RaggedTensor` of shape
#'   `(batch_size, ...)`. If any input is `RaggedTensor` then output is
#'   `RaggedTensor`, otherwise if any input is `SparseTensor` then output is
#'   `SparseTensor`, otherwise the output is `Tensor`.
#'
#' Reference:
#'   - [SipHash with salt](https://www.131002.net/siphash/siphash.pdf)
#'
#' @param num_bins
#' Number of hash bins. Note that this includes the `mask_value`
#' bin, so the effective number of bins is `(num_bins - 1)` if `mask_value`
#' is set.
#'
#' @param mask_value
#' A value that represents masked inputs, which are mapped to
#' index 0. `NULL` means no mask term will be added and the
#' hashing will start at index 0. Defaults to `NULL`.
#'
#' @param salt
#' A single unsigned integer or NULL.
#' If passed, the hash function used will be SipHash64, with these values
#' used as an additional input (known as a "salt" in cryptography).
#' These should be non-zero. If `NULL`, uses the FarmHash64 hash function.
#' It also supports list of 2 unsigned integer numbers, see
#' reference paper for details. Defaults to `NULL`.
#'
#' @param output_mode
#' Specification for the output of the layer. Values can bes
#' `"int"`, `"one_hot"`, `"multi_hot"`, or
#' `"count"` configuring the layer as follows:
#'   - `"int"`: Return the integer bin indices directly.
#'   - `"one_hot"`: Encodes each individual element in the input into an
#'     array the same size as `num_bins`, containing a 1 at the input's bin
#'     index. If the last dimension is size 1, will encode on that
#'     dimension.  If the last dimension is not size 1, will append a new
#'     dimension for the encoded output.
#'   - `"multi_hot"`: Encodes each sample in the input into a single array
#'     the same size as `num_bins`, containing a 1 for each bin index
#'     index present in the sample. Treats the last dimension as the sample
#'     dimension, if input shape is `(..., sample_length)`, output shape
#'     will be `(..., num_tokens)`.
#'   - `"count"`: As `"multi_hot"`, but the int array contains a count of
#'     the number of times the bin index appeared in the sample.
#' Defaults to `"int"`.
#'
#' @param sparse
#' Boolean. Only applicable to `"one_hot"`, `"multi_hot"`,
#' and `"count"` output modes. If TRUE, returns a `SparseTensor` instead of
#' a dense `Tensor`. Defaults to `FALSE`.
#'
#' @param **kwargs
#' Keyword arguments to construct a layer.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_hashing <-
function(object, num_bins, mask_value = NULL, salt = NULL, output_mode = "int",
    sparse = FALSE, ...)
{
    args <- capture_args(match.call(), list(num_bins = as.integer,
        salt = as_nullable_integer, input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$Hashing, object, args)
}


# <class 'keras.src.layers.core.identity.Identity'>
#' Identity layer
#'
#' @details
#' This layer should be used as a placeholder when no operation is to be
#' performed. The layer is argument insensitive, and returns its `inputs`
#' argument as output.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_identity <-
function(object, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$Identity, object, args)
}


# <function Input>
#' `Input()` is used to instantiate a Keras tensor
#'
#' @details
#' A Keras tensor is a symbolic tensor-like object, which we augment with
#' certain attributes that allow us to build a Keras model just by knowing the
#' inputs and outputs of the model.
#'
#' For instance, if `a`, `b` and `c` are Keras tensors,
#' it becomes possible to do:
#' `model = Model(input=[a, b], output=c)`
#'
#'   A `tensor`.
#'
#' Example:
#'
#' ```python
#' # this is a logistic regression in Keras
#' x = Input(shape=(32,))
#' y = Dense(16, activation='softmax')(x)
#' model = Model(x, y)
#' ```
#'
#' Note that even if eager execution is enabled,
#' `Input` produces a symbolic tensor-like object (i.e. a placeholder).
#' This symbolic tensor-like object can be used with lower-level
#' TensorFlow ops that take tensors as inputs, as such:
#'
#' ```python
#' x = Input(shape=(32,))
#' y = tf.square(x)  # This op will be treated like a layer
#' model = Model(x, y)
#' ```
#'
#' (This behavior does not work for higher-order TensorFlow APIs such as
#' control flow and being directly watched by a `tf.GradientTape`).
#'
#' However, the resulting model will not track any variables that were
#' used as inputs to TensorFlow ops. All variable usages must happen within
#' Keras layers to make sure they will be tracked by the model's weights.
#'
#' The Keras Input can also create a placeholder from an arbitrary
#' `tf.TypeSpec`, e.g:
#'
#' ```python
#' x = Input(type_spec=tf.RaggedTensorSpec(shape=[NULL, NULL],
#'                                         dtype=tf.float32, ragged_rank=1))
#' y = x.values
#' model = Model(x, y)
#' ```
#' When passing an arbitrary `tf.TypeSpec`, it must represent the signature of
#' an entire batch instead of just one example.
#'
#' @param shape
#' A shape list (integers), not including the batch size.
#' For instance, `shape=(32,)` indicates that the expected input
#' will be batches of 32-dimensional vectors. Elements of this list
#' can be NULL; 'NULL' elements represent dimensions where the shape is
#' not known.
#'
#' @param batch_size
#' optional static batch size (integer).
#'
#' @param sparse
#' A boolean specifying whether the placeholder to be created is
#' sparse. Only one of 'ragged' and 'sparse' can be TRUE. Note that,
#' if `sparse` is FALSE, sparse tensors can still be passed into the
#' input - they will be densified with a default value of 0.
#'
#' @param tensor
#' Optional existing tensor to wrap into the `Input` layer.
#' If set, the layer will use the `tf.TypeSpec` of this tensor rather
#' than creating a new placeholder tensor.
#'
#' @param ragged
#' A boolean specifying whether the placeholder to be created is
#' ragged. Only one of 'ragged' and 'sparse' can be TRUE. In this case,
#' values of 'NULL' in the 'shape' argument represent ragged
#' dimensions.  For more information about RaggedTensors, see
#' [this guide](https://www.tensorflow.org/guide/ragged_tensor).
#'
#' @param type_spec
#' A `tf.TypeSpec` object to create the input placeholder from.
#' When provided, all other args except name must be NULL.
#'
#' @param **kwargs
#' deprecated arguments support. Supports `batch_shape` and
#' `batch_input_shape`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_input <-
function(shape = NULL, batch_size = NULL, name = NULL, dtype = NULL,
    sparse = NULL, tensor = NULL, ragged = NULL, type_spec = NULL,
    ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape,
        shape = normalize_shape))
    create_layer(keras$layers$Input, NULL, args)
}


# <class 'keras.src.engine.input_layer.InputLayer'>
#' Layer to be used as an entry point into a Network (a graph of layers)
#'
#' @details
#' It can either wrap an existing tensor (pass an `input_tensor` argument)
#' or create a placeholder tensor (pass arguments `input_shape`, and
#' optionally, `dtype`).
#'
#' It is generally recommend to use the Keras Functional model via `Input`,
#' (which creates an `InputLayer`) without directly using `InputLayer`.
#'
#' When using `InputLayer` with the Keras Sequential model, it can be skipped
#' by moving the `input_shape` parameter to the first layer after the
#' `InputLayer`.
#'
#' This class can create placeholders for `tf.Tensors`, `tf.SparseTensors`, and
#' `tf.RaggedTensors` by choosing `sparse=TRUE` or `ragged=TRUE`. Note that
#' `sparse` and `ragged` can't be configured to `TRUE` at the same time.
#' Usage:
#'
#' ```python
#' # With explicit InputLayer.
#' model = tf.keras.Sequential([
#'   tf.keras.layers.InputLayer(input_shape=(4,)),
#'   tf.keras.layers.Dense(8)])
#' model.compile(tf.keras.optimizers.RMSprop(0.001), loss='mse')
#' model.fit(np.zeros((10, 4)),
#'           np.ones((10, 8)))
#'
#' # Without InputLayer and let the first layer to have the input_shape.
#' # Keras will add a input for the model behind the scene.
#' model = tf.keras.Sequential([
#'   tf.keras.layers.Dense(8, input_shape=(4,))])
#' model.compile(tf.keras.optimizers.RMSprop(0.001), loss='mse')
#' model.fit(np.zeros((10, 4)),
#'           np.ones((10, 8)))
#' ```
#'
#' @param input_shape
#' Shape list (not including the batch axis), or
#' `TensorShape` instance (not including the batch axis).
#'
#' @param batch_size
#' Optional input batch size (integer or `NULL`).
#'
#' @param input_tensor
#' Optional tensor to use as layer input. If set, the layer
#' will use the `tf.TypeSpec` of this tensor rather
#' than creating a new placeholder tensor.
#'
#' @param sparse
#' Boolean, whether the placeholder created is meant to be sparse.
#' Defaults to `FALSE`.
#'
#' @param ragged
#' Boolean, whether the placeholder created is meant to be ragged.
#' In this case, values of `NULL` in the `shape` argument represent
#' ragged dimensions. For more information about `tf.RaggedTensor`, see
#' [this guide](https://www.tensorflow.org/guide/ragged_tensor).
#' Defaults to `FALSE`.
#'
#' @param type_spec
#' A `tf.TypeSpec` object to create Input from. This
#' `tf.TypeSpec` represents the entire batch. When provided, all other
#' args except name must be `NULL`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
layer_input_layer <-
function(object, input_shape = NULL, batch_size = NULL, dtype = NULL,
    input_tensor = NULL, sparse = NULL, name = NULL, ragged = NULL,
    type_spec = NULL, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$InputLayer, object, args)
}


# <class 'keras.src.layers.preprocessing.integer_lookup.IntegerLookup'>
#' A preprocessing layer which maps integer features to contiguous ranges
#'
#' @details
#' This layer maps a set of arbitrary integer input tokens into indexed integer
#' output via a table-based vocabulary lookup. The layer's output indices will
#' be contiguously arranged up to the maximum vocab size, even if the input
#' tokens are non-continguous or unbounded. The layer supports multiple options
#' for encoding the output via `output_mode`, and has optional support for
#' out-of-vocabulary (OOV) tokens and masking.
#'
#' The vocabulary for the layer must be either supplied on construction or
#' learned via `adapt()`. During `adapt()`, the layer will analyze a data set,
#' determine the frequency of individual integer tokens, and create a
#' vocabulary from them. If the vocabulary is capped in size, the most frequent
#' tokens will be used to create the vocabulary and all others will be treated
#' as OOV.
#'
#' There are two possible output modes for the layer.  When `output_mode` is
#' `"int"`, input integers are converted to their index in the vocabulary (an
#' integer).  When `output_mode` is `"multi_hot"`, `"count"`, or `"tf_idf"`,
#' input integers are encoded into an array where each dimension corresponds to
#' an element in the vocabulary.
#'
#' The vocabulary can optionally contain a mask token as well as an OOV token
#' (which can optionally occupy multiple indices in the vocabulary, as set
#' by `num_oov_indices`).
#' The position of these tokens in the vocabulary is fixed. When `output_mode`
#' is `"int"`, the vocabulary will begin with the mask token at index 0,
#' followed by OOV indices, followed by the rest of the vocabulary. When
#' `output_mode` is `"multi_hot"`, `"count"`, or `"tf_idf"` the vocabulary will
#' begin with OOV indices and instances of the mask token will be dropped.
#'
#' For an overview and full list of preprocessing layers, see the preprocessing
#' [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).
#'
#' **Creating a lookup layer with a known vocabulary**
#'
#' This example creates a lookup layer with a pre-existing vocabulary.
#'
#' ```python
#' >>> vocab = [12, 36, 1138, 42]
#' >>> data = tf.constant([[12, 1138, 42], [42, 1000, 36]])  # Note OOV tokens
#' >>> layer = tf.keras.layers.IntegerLookup(vocabulary=vocab)
#' >>> layer(data)
#' <tf.Tensor: shape=(2, 3), dtype=int64, numpy=
#' array([[1, 3, 4],
#'        [4, 0, 2]])>
#' ```
#'
#' **Creating a lookup layer with an adapted vocabulary**
#'
#' This example creates a lookup layer and generates the vocabulary by
#' analyzing the dataset.
#'
#' ```python
#' >>> data = tf.constant([[12, 1138, 42], [42, 1000, 36]])
#' >>> layer = tf.keras.layers.IntegerLookup()
#' >>> layer.adapt(data)
#' >>> layer.get_vocabulary()
#' [-1, 42, 1138, 1000, 36, 12]
#' ```
#'
#' Note that the OOV token -1 have been added to the vocabulary. The remaining
#' tokens are sorted by frequency (42, which has 2 occurrences, is first) then
#' by inverse sort order.
#'
#' ```python
#' >>> data = tf.constant([[12, 1138, 42], [42, 1000, 36]])
#' >>> layer = tf.keras.layers.IntegerLookup()
#' >>> layer.adapt(data)
#' >>> layer(data)
#' <tf.Tensor: shape=(2, 3), dtype=int64, numpy=
#' array([[5, 2, 1],
#'        [1, 3, 4]])>
#' ```
#'
#' **Lookups with multiple OOV indices**
#'
#' This example demonstrates how to use a lookup layer with multiple OOV
#' indices.  When a layer is created with more than one OOV index, any OOV
#' tokens are hashed into the number of OOV buckets, distributing OOV tokens in
#' a deterministic fashion across the set.
#'
#' ```python
#' >>> vocab = [12, 36, 1138, 42]
#' >>> data = tf.constant([[12, 1138, 42], [37, 1000, 36]])
#' >>> layer = tf.keras.layers.IntegerLookup(
#' ...     vocabulary=vocab, num_oov_indices=2)
#' >>> layer(data)
#' <tf.Tensor: shape=(2, 3), dtype=int64, numpy=
#' array([[2, 4, 5],
#'        [1, 0, 3]])>
#' ```
#'
#' Note that the output for OOV token 37 is 1, while the output for OOV token
#' 1000 is 0. The in-vocab terms have their output index increased by 1 from
#' earlier examples (12 maps to 2, etc) in order to make space for the extra
#' OOV token.
#'
#' **One-hot output**
#'
#' Configure the layer with `output_mode='one_hot'`. Note that the first
#' `num_oov_indices` dimensions in the one_hot encoding represent OOV values.
#'
#' ```python
#' >>> vocab = [12, 36, 1138, 42]
#' >>> data = tf.constant([12, 36, 1138, 42, 7]) # Note OOV tokens
#' >>> layer = tf.keras.layers.IntegerLookup(
#' ...     vocabulary=vocab, output_mode='one_hot')
#' >>> layer(data)
#' <tf.Tensor: shape=(5, 5), dtype=float32, numpy=
#'   array([[0., 1., 0., 0., 0.],
#'          [0., 0., 1., 0., 0.],
#'          [0., 0., 0., 1., 0.],
#'          [0., 0., 0., 0., 1.],
#'          [1., 0., 0., 0., 0.]], dtype=float32)>
#' ```
#'
#' **Multi-hot output**
#'
#' Configure the layer with `output_mode='multi_hot'`. Note that the first
#' `num_oov_indices` dimensions in the multi_hot encoding represent OOV tokens
#'
#' ```python
#' >>> vocab = [12, 36, 1138, 42]
#' >>> data = tf.constant([[12, 1138, 42, 42],
#' ...                     [42, 7, 36, 7]]) # Note OOV tokens
#' >>> layer = tf.keras.layers.IntegerLookup(
#' ...     vocabulary=vocab, output_mode='multi_hot')
#' >>> layer(data)
#' <tf.Tensor: shape=(2, 5), dtype=float32, numpy=
#'   array([[0., 1., 0., 1., 1.],
#'          [1., 0., 1., 0., 1.]], dtype=float32)>
#' ```
#'
#' **Token count output**
#'
#' Configure the layer with `output_mode='count'`. As with multi_hot output,
#' the first `num_oov_indices` dimensions in the output represent OOV tokens.
#'
#' ```python
#' >>> vocab = [12, 36, 1138, 42]
#' >>> data = tf.constant([[12, 1138, 42, 42],
#' ...                     [42, 7, 36, 7]]) # Note OOV tokens
#' >>> layer = tf.keras.layers.IntegerLookup(
#' ...     vocabulary=vocab, output_mode='count')
#' >>> layer(data)
#' <tf.Tensor: shape=(2, 5), dtype=float32, numpy=
#'   array([[0., 1., 0., 1., 2.],
#'          [2., 0., 1., 0., 1.]], dtype=float32)>
#' ```
#'
#' **TF-IDF output**
#'
#' Configure the layer with `output_mode='tf_idf'`. As with multi_hot output,
#' the first `num_oov_indices` dimensions in the output represent OOV tokens.
#'
#' Each token bin will output `token_count * idf_weight`, where the idf weights
#' are the inverse document frequency weights per token. These should be
#' provided along with the vocabulary. Note that the `idf_weight` for OOV
#' tokens will default to the average of all idf weights passed in.
#'
#' ```python
#' >>> vocab = [12, 36, 1138, 42]
#' >>> idf_weights = [0.25, 0.75, 0.6, 0.4]
#' >>> data = tf.constant([[12, 1138, 42, 42],
#' ...                     [42, 7, 36, 7]]) # Note OOV tokens
#' >>> layer = tf.keras.layers.IntegerLookup(
#' ...     output_mode='tf_idf', vocabulary=vocab, idf_weights=idf_weights)
#' >>> layer(data)
#' <tf.Tensor: shape=(2, 5), dtype=float32, numpy=
#'   array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],
#'          [1.0 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)>
#' ```
#'
#' To specify the idf weights for oov tokens, you will need to pass the entire
#' vocabularly including the leading oov token.
#'
#' ```python
#' >>> vocab = [-1, 12, 36, 1138, 42]
#' >>> idf_weights = [0.9, 0.25, 0.75, 0.6, 0.4]
#' >>> data = tf.constant([[12, 1138, 42, 42],
#' ...                     [42, 7, 36, 7]]) # Note OOV tokens
#' >>> layer = tf.keras.layers.IntegerLookup(
#' ...     output_mode='tf_idf', vocabulary=vocab, idf_weights=idf_weights)
#' >>> layer(data)
#' <tf.Tensor: shape=(2, 5), dtype=float32, numpy=
#'   array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],
#'          [1.8 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)>
#' ```
#'
#' When adapting the layer in tf_idf mode, each input sample will be considered
#' a document, and idf weight per token will be calculated as
#' `log(1 + num_documents / (1 + token_document_count))`.
#'
#' **Inverse lookup**
#'
#' This example demonstrates how to map indices to tokens using this layer.
#' (You can also use `adapt()` with `inverse=TRUE`, but for simplicity we'll
#' pass the vocab in this example.)
#'
#' ```python
#' >>> vocab = [12, 36, 1138, 42]
#' >>> data = tf.constant([[1, 3, 4], [4, 0, 2]])
#' >>> layer = tf.keras.layers.IntegerLookup(vocabulary=vocab, invert=TRUE)
#' >>> layer(data)
#' <tf.Tensor: shape=(2, 3), dtype=int64, numpy=
#' array([[  12, 1138,   42],
#'        [  42,   -1,   36]])>
#' ```
#'
#' Note that the first index correspond to the oov token by default.
#'
#' **Forward and inverse lookup pairs**
#'
#' This example demonstrates how to use the vocabulary of a standard lookup
#' layer to create an inverse lookup layer.
#'
#' ```python
#' >>> vocab = [12, 36, 1138, 42]
#' >>> data = tf.constant([[12, 1138, 42], [42, 1000, 36]])
#' >>> layer = tf.keras.layers.IntegerLookup(vocabulary=vocab)
#' >>> i_layer = tf.keras.layers.IntegerLookup(
#' ...     vocabulary=layer.get_vocabulary(), invert=TRUE)
#' >>> int_data = layer(data)
#' >>> i_layer(int_data)
#' <tf.Tensor: shape=(2, 3), dtype=int64, numpy=
#' array([[  12, 1138,   42],
#'        [  42,   -1,   36]])>
#' ```
#'
#' In this example, the input token 1000 resulted in an output of -1, since
#' 1000 was not in the vocabulary - it got represented as an OOV, and all OOV
#' tokens are returned as -1 in the inverse layer. Also, note that for the
#' inverse to work, you must have already set the forward layer vocabulary
#' either directly or via `adapt()` before calling `get_vocabulary()`.
#'
#' @param max_tokens
#' Maximum size of the vocabulary for this layer. This should
#' only be specified when adapting the vocabulary or when setting
#' `pad_to_max_tokens=TRUE`. If NULL, there is no cap on the size of the
#' vocabulary. Note that this size includes the OOV and mask tokens.
#' Defaults to `NULL`.
#'
#' @param num_oov_indices
#' The number of out-of-vocabulary tokens to use. If this
#' value is more than 1, OOV inputs are modulated to determine their OOV
#' value. If this value is 0, OOV inputs will cause an error when calling
#' the layer. Defaults to `1`.
#'
#' @param mask_token
#' An integer token that represents masked inputs. When
#' `output_mode` is `"int"`, the token is included in vocabulary and mapped
#' to index 0. In other output modes, the token will not appear in the
#' vocabulary and instances of the mask token in the input will be dropped.
#' If set to NULL, no mask term will be added. Defaults to `NULL`.
#'
#' @param oov_token
#' Only used when `invert` is TRUE. The token to return for OOV
#' indices. Defaults to `-1`.
#'
#' @param vocabulary
#' Optional. Either an array of integers or a string path to a
#' text file. If passing an array, can pass a list, list, 1D numpy array,
#' or 1D tensor containing the integer vocbulary terms. If passing a file
#' path, the file should contain one line per term in the vocabulary. If
#' this argument is set, there is no need to `adapt()` the layer.
#'
#' @param vocabulary_dtype
#' The dtype of the vocabulary terms, for example
#' `"int64"` or `"int32"`. Defaults to `"int64"`.
#'
#' @param idf_weights
#' Only valid when `output_mode` is `"tf_idf"`. A list, list,
#' 1D numpy array, or 1D tensor or the same length as the vocabulary,
#' containing the floating point inverse document frequency weights, which
#' will be multiplied by per sample term counts for the final `tf_idf`
#' weight. If the `vocabulary` argument is set, and `output_mode` is
#' `"tf_idf"`, this argument must be supplied.
#'
#' @param invert
#' Only valid when `output_mode` is `"int"`. If TRUE, this layer will
#' map indices to vocabulary items instead of mapping vocabulary items to
#' indices. Defaults to `FALSE`.
#'
#' @param output_mode
#' Specification for the output of the layer. Values can be
#' `"int"`, `"one_hot"`, `"multi_hot"`, `"count"`, or `"tf_idf"`
#' configuring the layer as follows:
#'   - `"int"`: Return the vocabulary indices of the input tokens.
#'   - `"one_hot"`: Encodes each individual element in the input into an
#'     array the same size as the vocabulary, containing a 1 at the element
#'     index. If the last dimension is size 1, will encode on that
#'     dimension.  If the last dimension is not size 1, will append a new
#'     dimension for the encoded output.
#'   - `"multi_hot"`: Encodes each sample in the input into a single array
#'     the same size as the vocabulary, containing a 1 for each vocabulary
#'     term present in the sample. Treats the last dimension as the sample
#'     dimension, if input shape is (..., sample_length), output shape will
#'     be (..., num_tokens).
#'   - `"count"`: As `"multi_hot"`, but the int array contains a count of
#'     the number of times the token at that index appeared in the sample.
#'   - `"tf_idf"`: As `"multi_hot"`, but the TF-IDF algorithm is applied to
#'     find the value in each token slot.
#' For `"int"` output, any shape of input and output is supported. For all
#' other output modes, currently only output up to rank 2 is supported.
#' Defaults to `"int"`.
#'
#' @param pad_to_max_tokens
#' Only applicable when `output_mode` is `"multi_hot"`,
#' `"count"`, or `"tf_idf"`. If TRUE, the output will have its feature axis
#' padded to `max_tokens` even if the number of unique tokens in the
#' vocabulary is less than max_tokens, resulting in a tensor of shape
#' [batch_size, max_tokens] regardless of vocabulary size. Defaults to
#' FALSE.
#'
#' @param sparse
#' Boolean. Only applicable when `output_mode` is `"multi_hot"`,
#' `"count"`, or `"tf_idf"`. If TRUE, returns a `SparseTensor` instead of a
#' dense `Tensor`. Defaults to `FALSE`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_integer_lookup <-
function(object, max_tokens = NULL, num_oov_indices = 1L, mask_token = NULL,
    oov_token = -1L, vocabulary = NULL, vocabulary_dtype = "int64",
    idf_weights = NULL, invert = FALSE, output_mode = "int",
    sparse = FALSE, pad_to_max_tokens = FALSE, ...)
{
    args <- capture_args(match.call(), list(num_oov_indices = as.integer,
        oov_token = as.integer, input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$IntegerLookup, object, args)
}


# <class 'keras.src.layers.core.lambda_layer.Lambda'>
#' Wraps arbitrary expressions as a `Layer` object
#'
#' @details
#' The `Lambda` layer exists so that arbitrary expressions can be used
#' as a `Layer` when constructing Sequential
#' and Functional API models. `Lambda` layers are best suited for simple
#' operations or quick experimentation. For more advanced use cases, follow
#' [this guide](
#' https://www.tensorflow.org/guide/keras/custom_layers_and_models)
#' for subclassing `tf.keras.layers.Layer`.
#'
#' WARNING: `tf.keras.layers.Lambda` layers have (de)serialization limitations!
#'
#' The main reason to subclass `tf.keras.layers.Layer` instead of using a
#' `Lambda` layer is saving and inspecting a Model. `Lambda` layers
#' are saved by serializing the Python bytecode, which is fundamentally
#' non-portable. They should only be loaded in the same environment where
#' they were saved. Subclassed layers can be saved in a more portable way
#' by overriding their `get_config()` method. Models that rely on
#' subclassed Layers are also often easier to visualize and reason about.
#'
#' ```python
#' # add a x -> x^2 layer
#' model.add(Lambda(lambda x: x ** 2))
#' ```
#'
#' ```python
#' # add a layer that returns the concatenation
#' # of the positive part of the input and
#' # the opposite of the negative part
#'
#' def antirectifier(x):
#'     x -= K.mean(x, axis=1, keepdims=TRUE)
#'     x = K.l2_normalize(x, axis=1)
#'     pos = K.relu(x)
#'     neg = K.relu(-x)
#'     return K.concatenate([pos, neg], axis=1)
#'
#' model.add(Lambda(antirectifier))
#' ```
#'
#' **Note on Variables:**
#'
#' While it is possible to use Variables with Lambda layers,
#' this practice is discouraged as it can easily lead to bugs.
#' For instance, consider the following layer:
#'
#' ```python
#' scale = tf.Variable(1.)
#' scale_layer = tf.keras.layers.Lambda(lambda x: x * scale)
#' ```
#'
#' Because `scale_layer` does not directly track the `scale` variable, it will
#' not appear in `scale_layer.trainable_weights` and will therefore not be
#' trained if `scale_layer` is used in a Model.
#'
#' A better pattern is to write a subclassed Layer:
#'
#' ```python
#' class ScaleLayer(tf.keras.layers.Layer):
#'     def __init__(self, **kwargs):
#'         super().__init__(**kwargs)
#'         self.scale = tf.Variable(1.)
#'
#'     def call(self, inputs):
#'         return inputs * self.scale
#' ```
#'
#' In general, `Lambda` layers can be convenient for simple stateless
#' computation, but anything more complex should use a subclass Layer instead.
#'
#' Input shape: Arbitrary. Use the keyword argument input_shape (list of
#'   integers, does not include the samples axis) when using this layer as the
#'   first layer in a model.
#'
#' Output shape: Specified by `output_shape` argument
#'
#' @param function
#' The function to be evaluated. Takes input tensor as first
#' argument.
#'
#' @param output_shape
#' Expected output shape from function. This argument can be
#' inferred if not explicitly provided. Can be a list or function. If a
#' list, it only specifies the first dimension onward;
#' sample dimension is assumed either the same as the input:
#' `output_shape = (input_shape[0], ) + output_shape` or, the input is
#' `NULL` and the sample dimension is also `NULL`:
#' `output_shape = (NULL, ) + output_shape` If a function, it specifies the
#' entire shape as a function of the input shape:
#' `output_shape = f(input_shape)`
#'
#' @param mask
#' Either NULL (indicating no masking) or a callable with the same
#' signature as the `compute_mask` layer method, or a tensor that will be
#' returned as output mask regardless of what the input is.
#'
#' @param arguments
#' Optional dictionary of keyword arguments to be passed to the
#' function.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_lambda <-
function(object, `function`, output_shape = NULL, mask = NULL,
    arguments = NULL, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$Lambda, object, args)
}


# <class 'keras.src.engine.base_layer.Layer'>
#' This is the class from which all layers inherit
#'
#' @details
#' A layer is a callable object that takes as input one or more tensors and
#' that outputs one or more tensors. It involves *computation*, defined
#' in the `call()` method, and a *state* (weight variables). State can be
#' created in various places, at the convenience of the subclass implementer:
#'
#' * in `__init__()`;
#' * in the optional `build()` method, which is invoked by the first
#'   `__call__()` to the layer, and supplies the shape(s) of the input(s),
#'   which may not have been known at initialization time;
#' * in the first invocation of `call()`, with some caveats discussed
#'   below.
#'
#' Layers are recursively composable: If you assign a Layer instance as an
#' attribute of another Layer, the outer layer will start tracking the weights
#' created by the inner layer. Nested layers should be instantiated in the
#' `__init__()` method.
#'
#' Users will just instantiate a layer and then treat it as a callable.
#'
#' We recommend that descendants of `Layer` implement the following methods:
#'
#' * `__init__()`: Defines custom layer attributes, and creates layer weights
#'   that do not depend on input shapes, using `add_weight()`, or other state.
#' * `build(self, input_shape)`: This method can be used to create weights that
#'   depend on the shape(s) of the input(s), using `add_weight()`, or other
#'   state. `__call__()` will automatically build the layer (if it has not been
#'   built yet) by calling `build()`.
#' * `call(self, inputs, *args, **kwargs)`: Called in `__call__` after making
#'   sure `build()` has been called. `call()` performs the logic of applying
#'   the layer to the `inputs`. The first invocation may additionally create
#'   state that could not be conveniently created in `build()`; see its
#'   docstring for details.
#'   Two reserved keyword arguments you can optionally use in `call()` are:
#'     - `training` (boolean, whether the call is in inference mode or training
#'       mode). See more details in [the layer/model subclassing guide](
#'       https://www.tensorflow.org/guide/keras/custom_layers_and_models#privileged_training_argument_in_the_call_method)
#'     - `mask` (boolean tensor encoding masked timesteps in the input, used
#'       in RNN layers). See more details in
#'       [the layer/model subclassing guide](
#'       https://www.tensorflow.org/guide/keras/custom_layers_and_models#privileged_mask_argument_in_the_call_method)
#'   A typical signature for this method is `call(self, inputs)`, and user
#'   could optionally add `training` and `mask` if the layer need them. `*args`
#'   and `**kwargs` is only useful for future extension when more input
#'   parameters are planned to be added.
#' * `get_config(self)`: Returns a dictionary containing the configuration used
#'   to initialize this layer. If the keys differ from the arguments
#'   in `__init__`, then override `from_config(self)` as well.
#'   This method is used when saving
#'   the layer or a model that contains this layer.
#'
#' Here's a basic example: a layer with two variables, `w` and `b`,
#' that returns `y = w . x + b`.
#' It shows how to implement `build()` and `call()`.
#' Variables set as attributes of a layer are tracked as weights
#' of the layers (in `layer.weights`).
#'
#' ```python
#' class SimpleDense(Layer):
#'
#'   def __init__(self, units=32):
#'       super(SimpleDense, self).__init__()
#'       self.units = units
#'
#'   def build(self, input_shape):  # Create the state of the layer (weights)
#'     w_init = tf.random_normal_initializer()
#'     self.w = tf.Variable(
#'         initial_value=w_init(shape=(input_shape[-1], self.units),
#'                              dtype='float32'),
#'         trainable=TRUE)
#'     b_init = tf.zeros_initializer()
#'     self.b = tf.Variable(
#'         initial_value=b_init(shape=(self.units,), dtype='float32'),
#'         trainable=TRUE)
#'
#'   def call(self, inputs):  # Defines the computation from inputs to outputs
#'       return tf.matmul(inputs, self.w) + self.b
#'
#' # Instantiates the layer.
#' linear_layer = SimpleDense(4)
#'
#' # This will also call `build(input_shape)` and create the weights.
#' y = linear_layer(tf.ones((2, 2)))
#' assert len(linear_layer.weights) == 2
#'
#' # These weights are trainable, so they're listed in `trainable_weights`:
#' assert len(linear_layer.trainable_weights) == 2
#' ```
#'
#' Note that the method `add_weight()` offers a shortcut to create weights:
#'
#' ```python
#' class SimpleDense(Layer):
#'
#'   def __init__(self, units=32):
#'       super(SimpleDense, self).__init__()
#'       self.units = units
#'
#'   def build(self, input_shape):
#'       self.w = self.add_weight(shape=(input_shape[-1], self.units),
#'                                initializer='random_normal',
#'                                trainable=TRUE)
#'       self.b = self.add_weight(shape=(self.units,),
#'                                initializer='random_normal',
#'                                trainable=TRUE)
#'
#'   def call(self, inputs):
#'       return tf.matmul(inputs, self.w) + self.b
#' ```
#'
#' Besides trainable weights, updated via backpropagation during training,
#' layers can also have non-trainable weights. These weights are meant to
#' be updated manually during `call()`. Here's a example layer that computes
#' the running sum of its inputs:
#'
#' ```python
#' class ComputeSum(Layer):
#'
#'   def __init__(self, input_dim):
#'       super(ComputeSum, self).__init__()
#'       # Create a non-trainable weight.
#'       self.total = tf.Variable(initial_value=tf.zeros((input_dim,)),
#'                                trainable=FALSE)
#'
#'   def call(self, inputs):
#'       self.total.assign_add(tf.reduce_sum(inputs, axis=0))
#'       return self.total
#'
#' my_sum = ComputeSum(2)
#' x = tf.ones((2, 2))
#'
#' y = my_sum(x)
#' print(y.numpy())  # [2. 2.]
#'
#' y = my_sum(x)
#' print(y.numpy())  # [4. 4.]
#'
#' assert my_sum.weights == [my_sum.total]
#' assert my_sum.non_trainable_weights == [my_sum.total]
#' assert my_sum.trainable_weights == []
#' ```
#'
#' For more information about creating layers, see the guide
#' [Making new Layers and Models via subclassing](
#'   https://www.tensorflow.org/guide/keras/custom_layers_and_models)
#'
#' @param trainable
#' Boolean, whether the layer's variables should be trainable.
#'
#' @param dynamic
#' Set this to `TRUE` if your layer should only be run eagerly, and
#' should not be used to generate a static computation graph.
#' This would be the case for a Tree-RNN or a recursive network,
#' for example, or generally for any layer that manipulates tensors
#' using Python control flow. If `FALSE`, we assume that the layer can
#' safely be used to generate a static computation graph.
#'
#' @param variable_dtype
#' Alias of `dtype`.
#'
#' @param compute_dtype
#' The dtype of the layer's computations. Layers automatically
#' cast inputs to this dtype which causes the computations and output to
#' also be in this dtype. When mixed precision is used with a
#' `tf.keras.mixed_precision.Policy`, this will be different than
#' `variable_dtype`.
#'
#' @param dtype_policy
#' The layer's dtype policy. See the
#' `tf.keras.mixed_precision.Policy` documentation for details.
#'
#' @param trainable_weights
#' List of variables to be included in backprop.
#'
#' @param non_trainable_weights
#' List of variables that should not be
#' included in backprop.
#'
#' @param weights
#' The concatenation of the lists trainable_weights and
#' non_trainable_weights (in this order).
#'
#' @param trainable
#' Whether the layer should be trained (boolean), i.e. whether
#' its potentially-trainable weights should be returned as part of
#' `layer.trainable_weights`.
#'
#' @param input_spec
#' Optional (list of) `InputSpec` object(s) specifying the
#' constraints on inputs that can be accepted by the layer.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
layer_layer <-
function(object, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$Layer, object, args)
}


# <class 'keras.src.layers.normalization.layer_normalization.LayerNormalization'>
#' Layer normalization layer (Ba et al., 2016)
#'
#' @details
#' Normalize the activations of the previous layer for each given example in a
#' batch independently, rather than across a batch like Batch Normalization.
#' i.e. applies a transformation that maintains the mean activation within each
#' example close to 0 and the activation standard deviation close to 1.
#'
#' Given a tensor `inputs`, moments are calculated and normalization
#' is performed across the axes specified in `axis`.
#'
#' Example:
#'
#' ```python
#' >>> data = tf.constant(np.arange(10).reshape(5, 2) * 10, dtype=tf.float32)
#' >>> print(data)
#' tf.Tensor(
#' [[ 0. 10.]
#'  [20. 30.]
#'  [40. 50.]
#'  [60. 70.]
#'  [80. 90.]], shape=(5, 2), dtype=float32)
#' ```
#'
#' ```python
#' >>> layer = tf.keras.layers.LayerNormalization(axis=1)
#' >>> output = layer(data)
#' >>> print(output)
#' tf.Tensor(
#' [[-1. 1.]
#'  [-1. 1.]
#'  [-1. 1.]
#'  [-1. 1.]
#'  [-1. 1.]], shape=(5, 2), dtype=float32)
#' ```
#'
#' Notice that with Layer Normalization the normalization happens across the
#' axes *within* each example, rather than across different examples in the
#' batch.
#'
#' If `scale` or `center` are enabled, the layer will scale the normalized
#' outputs by broadcasting them with a trainable variable `gamma`, and center
#' the outputs by broadcasting with a trainable variable `beta`. `gamma` will
#' default to a ones tensor and `beta` will default to a zeros tensor, so that
#' centering and scaling are no-ops before training has begun.
#'
#' So, with scaling and centering enabled the normalization equations
#' are as follows:
#'
#' Let the intermediate activations for a mini-batch to be the `inputs`.
#'
#' For each sample `x_i` in `inputs` with `k` features, we compute the mean and
#' variance of the sample:
#'
#' ```python
#' mean_i = sum(x_i[j] for j in range(k)) / k
#' var_i = sum((x_i[j] - mean_i) ** 2 for j in range(k)) / k
#' ```
#'
#' and then compute a normalized `x_i_normalized`, including a small factor
#' `epsilon` for numerical stability.
#'
#' ```python
#' x_i_normalized = (x_i - mean_i) / sqrt(var_i + epsilon)
#' ```
#'
#' And finally `x_i_normalized ` is linearly transformed by `gamma` and `beta`,
#' which are learned parameters:
#'
#' ```python
#' output_i = x_i_normalized * gamma + beta
#' ```
#'
#' `gamma` and `beta` will span the axes of `inputs` specified in `axis`, and
#' this part of the inputs' shape must be fully defined.
#'
#' For example:
#'
#' ```python
#' >>> layer = tf.keras.layers.LayerNormalization(axis=[1, 2, 3])
#' >>> layer.build([5, 20, 30, 40])
#' >>> print(layer.beta.shape)
#' (20, 30, 40)
#' >>> print(layer.gamma.shape)
#' (20, 30, 40)
#' ```
#'
#' Note that other implementations of layer normalization may choose to define
#' `gamma` and `beta` over a separate set of axes from the axes being
#' normalized across. For example, Group Normalization
#' ([Wu et al. 2018](https://arxiv.org/abs/1803.08494)) with group size of 1
#' corresponds to a Layer Normalization that normalizes across height, width,
#' and channel and has `gamma` and `beta` span only the channel dimension.
#' So, this Layer Normalization implementation will not match a Group
#' Normalization layer with group size set to 1.
#'
#' Input shape:
#'   Arbitrary. Use the keyword argument `input_shape` (list of
#'   integers, does not include the samples axis) when using this layer as the
#'   first layer in a model.
#'
#' Output shape:
#'   Same shape as input.
#'
#' Reference:
#'   - [Lei Ba et al., 2016](https://arxiv.org/abs/1607.06450).
#'
#' @param axis
#' Integer or List/Tuple. The axis or axes to normalize across.
#' Typically, this is the features axis/axes. The left-out axes are
#' typically the batch axis/axes. `-1` is the last dimension in the
#' input. Defaults to `-1`.
#'
#' @param epsilon
#' Small float added to variance to avoid dividing by zero. Defaults
#' to 1e-3
#'
#' @param center
#' If TRUE, add offset of `beta` to normalized tensor. If FALSE,
#' `beta` is ignored. Defaults to `TRUE`.
#'
#' @param scale
#' If TRUE, multiply by `gamma`. If FALSE, `gamma` is not used.
#' When the next layer is linear (also e.g. `nn.relu`), this can be
#' disabled since the scaling will be done by the next layer.
#' Defaults to `TRUE`.
#'
#' @param beta_initializer
#' Initializer for the beta weight. Defaults to zeros.
#'
#' @param gamma_initializer
#' Initializer for the gamma weight. Defaults to ones.
#'
#' @param beta_regularizer
#' Optional regularizer for the beta weight. NULL by
#' default.
#'
#' @param gamma_regularizer
#' Optional regularizer for the gamma weight. NULL by
#' default.
#'
#' @param beta_constraint
#' Optional constraint for the beta weight. NULL by default.
#'
#' @param gamma_constraint
#' Optional constraint for the gamma weight. NULL by
#' default.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_layer_normalization <-
function(object, axis = -1L, epsilon = 0.001, center = TRUE,
    scale = TRUE, beta_initializer = "zeros", gamma_initializer = "ones",
    beta_regularizer = NULL, gamma_regularizer = NULL, beta_constraint = NULL,
    gamma_constraint = NULL, ...)
{
    args <- capture_args(match.call(), list(axis = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$LayerNormalization, object, args)
}


# <class 'keras.src.layers.activation.leaky_relu.LeakyReLU'>
#' Leaky version of a Rectified Linear Unit
#'
#' @details
#' It allows a small gradient when the unit is not active:
#'
#' ```
#'     f(x) = alpha * x if x < 0
#'     f(x) = x if x >= 0
#' ```
#'
#' Usage:
#'
#' ```python
#' >>> layer = tf.keras.layers.LeakyReLU()
#' >>> output = layer([-3.0, -1.0, 0.0, 2.0])
#' >>> list(output.numpy())
#' [-0.9, -0.3, 0.0, 2.0]
#' >>> layer = tf.keras.layers.LeakyReLU(alpha=0.1)
#' >>> output = layer([-3.0, -1.0, 0.0, 2.0])
#' >>> list(output.numpy())
#' [-0.3, -0.1, 0.0, 2.0]
#' ```
#'
#' Input shape:
#'     Arbitrary. Use the keyword argument `input_shape`
#'     (list of integers, does not include the batch axis)
#'     when using this layer as the first layer in a model.
#'
#' Output shape:
#'     Same shape as the input.
#'
#' @param alpha
#' Float >= `0.`. Negative slope coefficient. Defaults to `0.3`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_activation_leaky_relu <-
function(object, alpha = 0.3, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$LeakyReLU, object, args)
}


# <class 'keras.src.layers.locally_connected.locally_connected1d.LocallyConnected1D'>
#' Locally-connected layer for 1D inputs
#'
#' @details
#' The `LocallyConnected1D` layer works similarly to
#' the `Conv1D` layer, except that weights are unshared,
#' that is, a different set of filters is applied at each different patch
#' of the input.
#'
#' Note: layer attributes cannot be modified after the layer has been called
#' once (except the `trainable` attribute).
#'
#' Example:
#' ```python
#'     # apply a unshared weight convolution 1d of length 3 to a sequence with
#'     # 10 timesteps, with 64 output filters
#'     model = Sequential()
#'     model.add(LocallyConnected1D(64, 3, input_shape=(10, 32)))
#'     # now model.output_shape == (NULL, 8, 64)
#'     # add a new conv1d on top
#'     model.add(LocallyConnected1D(32, 3))
#'     # now model.output_shape == (NULL, 6, 32)
#' ```
#'
#' Input shape:
#'     3D tensor with shape: `(batch_size, steps, input_dim)`
#' Output shape:
#'     3D tensor with shape: `(batch_size, new_steps, filters)` `steps` value
#'       might have changed due to padding or strides.
#'
#' @param filters
#' Integer, the dimensionality of the output space (i.e. the
#' number of output filters in the convolution).
#'
#' @param kernel_size
#' An integer or list of a single integer, specifying
#' the length of the 1D convolution window.
#'
#' @param strides
#' An integer or list of a single integer, specifying the
#' stride length of the convolution.
#'
#' @param padding
#' Currently only supports `"valid"` (case-insensitive). `"same"`
#' may be supported in the future. `"valid"` means no padding.
#'
#' @param data_format
#' A string, one of `channels_last` (default) or
#' `channels_first`. The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape `(batch, length,
#' channels)` while `channels_first` corresponds to inputs with shape
#' `(batch, channels, length)`. When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#' `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param activation
#' Activation function to use. If you don't specify anything,
#' no activation is applied (ie. "linear" activation: `a(x) = x`).
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix.
#'
#' @param bias_initializer
#' Initializer for the bias vector.
#'
#' @param kernel_regularizer
#' Regularizer function applied to the `kernel` weights
#' matrix.
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector.
#'
#' @param activity_regularizer
#' Regularizer function applied to the output of the
#' layer (its "activation")..
#'
#' @param kernel_constraint
#' Constraint function applied to the kernel matrix.
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector.
#'
#' @param implementation
#' implementation mode, either `1`, `2`, or `3`. `1` loops
#' over input spatial locations to perform the forward pass. It is
#' memory-efficient but performs a lot of (small) ops.  `2` stores layer
#' weights in a dense but sparsely-populated 2D matrix and implements the
#' forward pass as a single matrix-multiply. It uses a lot of RAM but
#' performs few (large) ops.  `3` stores layer weights in a sparse tensor
#' and implements the forward pass as a single sparse matrix-multiply.
#'   How to choose:
#'   `1`: large, dense models,
#'   `2`: small models,
#'   `3`: large, sparse models,  where "large" stands for large
#'     input/output activations (i.e. many `filters`, `input_filters`,
#'     large `input_size`, `output_size`), and "sparse" stands for few
#'     connections between inputs and outputs, i.e. small ratio
#'     `filters * input_filters * kernel_size / (input_size * strides)`,
#'     where inputs to and outputs of the layer are assumed to have
#'     shapes `(input_size, input_filters)`, `(output_size, filters)`
#'     respectively.  It is recommended to benchmark each in the setting
#'     of interest to pick the most efficient one (in terms of speed and
#'     memory usage). Correct choice of implementation can lead to
#'     dramatic speed improvements (e.g. 50X), potentially at the expense
#'     of RAM.  Also, only `padding="valid"` is supported by
#'     `implementation=1`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_locally_connected_1d <-
function(object, filters, kernel_size, strides = 1L, padding = "valid",
    data_format = NULL, activation = NULL, use_bias = TRUE, kernel_initializer = "glorot_uniform",
    bias_initializer = "zeros", kernel_regularizer = NULL, bias_regularizer = NULL,
    activity_regularizer = NULL, kernel_constraint = NULL, bias_constraint = NULL,
    implementation = 1L, ...)
{
    args <- capture_args(match.call(), list(filters = as.integer,
        kernel_size = as.integer, strides = as.integer, implementation = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$LocallyConnected1D, object, args)
}


# <class 'keras.src.layers.locally_connected.locally_connected2d.LocallyConnected2D'>
#' Locally-connected layer for 2D inputs
#'
#' @details
#' The `LocallyConnected2D` layer works similarly
#' to the `Conv2D` layer, except that weights are unshared,
#' that is, a different set of filters is applied at each
#' different patch of the input.
#'
#' Note: layer attributes cannot be modified after the layer has been called
#' once (except the `trainable` attribute).
#'
#' ```python
#'     # apply a 3x3 unshared weights convolution with 64 output filters on a
#'     32x32 image
#'     # with `data_format="channels_last"`:
#'     model = Sequential()
#'     model.add(LocallyConnected2D(64, (3, 3), input_shape=(32, 32, 3)))
#'     # now model.output_shape == (NULL, 30, 30, 64)
#'     # notice that this layer will consume (30*30)*(3*3*3*64) + (30*30)*64
#'     parameters
#'
#'     # add a 3x3 unshared weights convolution on top, with 32 output filters:
#'     model.add(LocallyConnected2D(32, (3, 3)))
#'     # now model.output_shape == (NULL, 28, 28, 32)
#' ```
#'
#' Input shape:
#'     4D tensor with shape: `(samples, channels, rows, cols)` if
#'       data_format='channels_first'
#'     or 4D tensor with shape: `(samples, rows, cols, channels)` if
#'       data_format='channels_last'.
#' Output shape:
#'     4D tensor with shape: `(samples, filters, new_rows, new_cols)` if
#'       data_format='channels_first'
#'     or 4D tensor with shape: `(samples, new_rows, new_cols, filters)` if
#'       data_format='channels_last'. `rows` and `cols` values might have
#'       changed due to padding.
#'
#' @param filters
#' Integer, the dimensionality of the output space (i.e. the
#' number of output filters in the convolution).
#'
#' @param kernel_size
#' An integer or list of 2 integers, specifying the
#' width and height of the 2D convolution window. Can be a single integer
#' to specify the same value for all spatial dimensions.
#'
#' @param strides
#' An integer or list of 2 integers, specifying the strides
#' of the convolution along the width and height. Can be a single integer
#' to specify the same value for all spatial dimensions.
#'
#' @param padding
#' Currently only support `"valid"` (case-insensitive). `"same"`
#' will be supported in future. `"valid"` means no padding.
#'
#' @param data_format
#' A string, one of `channels_last` (default) or
#' `channels_first`. The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape `(batch, height,
#'   width, channels)` while `channels_first` corresponds to inputs with
#'   shape
#' `(batch, channels, height, width)`. When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#' `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param activation
#' Activation function to use. If you don't specify anything,
#' no activation is applied (ie. "linear" activation: `a(x) = x`).
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix.
#'
#' @param bias_initializer
#' Initializer for the bias vector.
#'
#' @param kernel_regularizer
#' Regularizer function applied to the `kernel` weights
#' matrix.
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector.
#'
#' @param activity_regularizer
#' Regularizer function applied to the output of the
#' layer (its "activation").
#'
#' @param kernel_constraint
#' Constraint function applied to the kernel matrix.
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector.
#'
#' @param implementation
#' implementation mode, either `1`, `2`, or `3`. `1` loops
#' over input spatial locations to perform the forward pass. It is
#' memory-efficient but performs a lot of (small) ops.  `2` stores layer
#' weights in a dense but sparsely-populated 2D matrix and implements the
#' forward pass as a single matrix-multiply. It uses a lot of RAM but
#' performs few (large) ops.  `3` stores layer weights in a sparse tensor
#' and implements the forward pass as a single sparse matrix-multiply.
#'   How to choose:
#'   `1`: large, dense models,
#'   `2`: small models,
#'   `3`: large, sparse models,  where "large" stands for large
#'     input/output activations (i.e. many `filters`, `input_filters`,
#'     large `np.prod(input_size)`, `np.prod(output_size)`), and "sparse"
#'     stands for few connections between inputs and outputs, i.e. small
#'     ratio `filters * input_filters * np.prod(kernel_size) /
#'     (np.prod(input_size) * np.prod(strides))`, where inputs to and
#'     outputs of the layer are assumed to have shapes `input_size +
#'     (input_filters,)`, `output_size + (filters,)` respectively. It is
#'     recommended to benchmark each in the setting of interest to pick
#'     the most efficient one (in terms of speed and memory usage).
#'     Correct choice of implementation can lead to dramatic speed
#'     improvements (e.g. 50X), potentially at the expense of RAM. Also,
#'     only `padding="valid"` is supported by `implementation=1`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_locally_connected_2d <-
function(object, filters, kernel_size, strides = list(1L, 1L),
    padding = "valid", data_format = NULL, activation = NULL,
    use_bias = TRUE, kernel_initializer = "glorot_uniform", bias_initializer = "zeros",
    kernel_regularizer = NULL, bias_regularizer = NULL, activity_regularizer = NULL,
    kernel_constraint = NULL, bias_constraint = NULL, implementation = 1L,
    ...)
{
    args <- capture_args(match.call(), list(filters = as.integer,
        kernel_size = as.integer, implementation = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$LocallyConnected2D, object, args)
}


# <class 'keras.src.layers.rnn.lstm.LSTM'>
#' Long Short-Term Memory layer - Hochreiter 1997
#'
#' @details
#' See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)
#' for details about the usage of RNN API.
#'
#' Based on available runtime hardware and constraints, this layer
#' will choose different implementations (cuDNN-based or pure-TensorFlow)
#' to maximize the performance. If a GPU is available and all
#' the arguments to the layer meet the requirement of the cuDNN kernel
#' (see below for details), the layer will use a fast cuDNN implementation.
#'
#' The requirements to use the cuDNN implementation are:
#'
#' 1. `activation` == `tanh`
#' 2. `recurrent_activation` == `sigmoid`
#' 3. `recurrent_dropout` == 0
#' 4. `unroll` is `FALSE`
#' 5. `use_bias` is `TRUE`
#' 6. Inputs, if use masking, are strictly right-padded.
#' 7. Eager execution is enabled in the outermost context.
#'
#' For example:
#'
#' ```python
#' >>> inputs = tf.random.normal([32, 10, 8])
#' >>> lstm = tf.keras.layers.LSTM(4)
#' >>> output = lstm(inputs)
#' >>> print(output.shape)
#' (32, 4)
#' >>> lstm = tf.keras.layers.LSTM(4, return_sequences=TRUE, return_state=TRUE)
#' >>> whole_seq_output, final_memory_state, final_carry_state = lstm(inputs)
#' >>> print(whole_seq_output.shape)
#' (32, 10, 4)
#' >>> print(final_memory_state.shape)
#' (32, 4)
#' >>> print(final_carry_state.shape)
#' (32, 4)
#' ```
#'
#' Call arguments:
#'   inputs: A 3D tensor with shape `[batch, timesteps, feature]`.
#'   mask: Binary tensor of shape `[batch, timesteps]` indicating whether
#'     a given timestep should be masked (optional).
#'     An individual `TRUE` entry indicates that the corresponding timestep
#'     should be utilized, while a `FALSE` entry indicates that the
#'     corresponding timestep should be ignored. Defaults to `NULL`.
#'   training: Python boolean indicating whether the layer should behave in
#'     training mode or in inference mode. This argument is passed to the cell
#'     when calling it. This is only relevant if `dropout` or
#'     `recurrent_dropout` is used (optional). Defaults to `NULL`.
#'   initial_state: List of initial state tensors to be passed to the first
#'     call of the cell (optional, `NULL` causes creation
#'     of zero-filled initial state tensors). Defaults to `NULL`.
#'
#' @param units
#' Positive integer, dimensionality of the output space.
#'
#' @param activation
#' Activation function to use.
#' Default: hyperbolic tangent (`tanh`). If you pass `NULL`, no activation
#' is applied (ie. "linear" activation: `a(x) = x`).
#'
#' @param recurrent_activation
#' Activation function to use for the recurrent step.
#' Default: sigmoid (`sigmoid`). If you pass `NULL`, no activation is
#' applied (ie. "linear" activation: `a(x) = x`).
#'
#' @param use_bias
#' Boolean (default `TRUE`), whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix, used for
#' the linear transformation of the inputs. Default: `glorot_uniform`.
#'
#' @param recurrent_initializer
#' Initializer for the `recurrent_kernel` weights
#' matrix, used for the linear transformation of the recurrent state.
#' Default: `orthogonal`.
#'
#' @param bias_initializer
#' Initializer for the bias vector. Default: `zeros`.
#'
#' @param unit_forget_bias
#' Boolean (default `TRUE`). If TRUE, add 1 to the bias of
#' the forget gate at initialization. Setting it to true will also force
#' `bias_initializer="zeros"`. This is recommended in [Jozefowicz et
#'     al.](http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).
#'
#' @param kernel_regularizer
#' Regularizer function applied to the `kernel` weights
#' matrix. Default: `NULL`.
#'
#' @param recurrent_regularizer
#' Regularizer function applied to the
#' `recurrent_kernel` weights matrix. Default: `NULL`.
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector.
#' Default: `NULL`.
#'
#' @param activity_regularizer
#' Regularizer function applied to the output of the
#' layer (its "activation"). Default: `NULL`.
#'
#' @param kernel_constraint
#' Constraint function applied to the `kernel` weights
#' matrix. Default: `NULL`.
#'
#' @param recurrent_constraint
#' Constraint function applied to the
#' `recurrent_kernel` weights matrix. Default: `NULL`.
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector. Default:
#' `NULL`.
#'
#' @param dropout
#' Float between 0 and 1. Fraction of the units to drop for the
#' linear transformation of the inputs. Default: 0.
#'
#' @param recurrent_dropout
#' Float between 0 and 1. Fraction of the units to drop
#' for the linear transformation of the recurrent state. Default: 0.
#'
#' @param return_sequences
#' Boolean. Whether to return the last output in the output
#' sequence, or the full sequence. Default: `FALSE`.
#'
#' @param return_state
#' Boolean. Whether to return the last state in addition to the
#' output. Default: `FALSE`.
#'
#' @param go_backwards
#' Boolean (default `FALSE`). If TRUE, process the input
#' sequence backwards and return the reversed sequence.
#'
#' @param stateful
#' Boolean (default `FALSE`). If TRUE, the last state for each
#' sample at index i in a batch will be used as initial state for the sample
#' of index i in the following batch.
#'
#' @param time_major
#' The shape format of the `inputs` and `outputs` tensors.
#' If TRUE, the inputs and outputs will be in shape
#' `[timesteps, batch, feature]`, whereas in the FALSE case, it will be
#' `[batch, timesteps, feature]`. Using `time_major = TRUE` is a bit more
#' efficient because it avoids transposes at the beginning and end of the
#' RNN calculation. However, most TensorFlow data is batch-major, so by
#' default this function accepts input and emits output in batch-major
#' form.
#'
#' @param unroll
#' Boolean (default `FALSE`). If TRUE, the network will be unrolled,
#' else a symbolic loop will be used. Unrolling can speed-up a RNN,
#' although it tends to be more memory-intensive. Unrolling is only
#' suitable for short sequences.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_lstm <-
function(object, units, activation = "tanh", recurrent_activation = "sigmoid",
    use_bias = TRUE, kernel_initializer = "glorot_uniform", recurrent_initializer = "orthogonal",
    bias_initializer = "zeros", unit_forget_bias = TRUE, kernel_regularizer = NULL,
    recurrent_regularizer = NULL, bias_regularizer = NULL, activity_regularizer = NULL,
    kernel_constraint = NULL, recurrent_constraint = NULL, bias_constraint = NULL,
    dropout = 0, recurrent_dropout = 0, return_sequences = FALSE,
    return_state = FALSE, go_backwards = FALSE, stateful = FALSE,
    time_major = FALSE, unroll = FALSE, ...)
{
    args <- capture_args(match.call(), list(units = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$LSTM, object, args)
}


# <class 'keras.src.layers.rnn.lstm.LSTMCell'>
#' Cell class for the LSTM layer
#'
#' @details
#' See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)
#' for details about the usage of RNN API.
#'
#' This class processes one step within the whole time sequence input, whereas
#' `tf.keras.layer.LSTM` processes the whole sequence.
#'
#' For example:
#'
#' ```python
#' >>> inputs = tf.random.normal([32, 10, 8])
#' >>> rnn = tf.keras.layers.RNN(tf.keras.layers.LSTMCell(4))
#' >>> output = rnn(inputs)
#' >>> print(output.shape)
#' (32, 4)
#' >>> rnn = tf.keras.layers.RNN(
#' ...    tf.keras.layers.LSTMCell(4),
#' ...    return_sequences=TRUE,
#' ...    return_state=TRUE)
#' >>> whole_seq_output, final_memory_state, final_carry_state = rnn(inputs)
#' >>> print(whole_seq_output.shape)
#' (32, 10, 4)
#' >>> print(final_memory_state.shape)
#' (32, 4)
#' >>> print(final_carry_state.shape)
#' (32, 4)
#' ```
#'
#' Call arguments:
#'   inputs: A 2D tensor, with shape of `[batch, feature]`.
#'   states: List of 2 tensors that corresponding to the cell's units. Both of
#'     them have shape `[batch, units]`, the first tensor is the memory state
#'     from previous time step, the second tensor is the carry state from
#'     previous time step. For timestep 0, the initial state provided by user
#'     will be feed to cell.
#'   training: Python boolean indicating whether the layer should behave in
#'     training mode or in inference mode. Only relevant when `dropout` or
#'     `recurrent_dropout` is used.
#'
#' @param units
#' Positive integer, dimensionality of the output space.
#'
#' @param activation
#' Activation function to use. Default: hyperbolic tangent
#' (`tanh`). If you pass `NULL`, no activation is applied (ie. "linear"
#' activation: `a(x) = x`).
#'
#' @param recurrent_activation
#' Activation function to use for the recurrent step.
#' Default: sigmoid (`sigmoid`). If you pass `NULL`, no activation is
#' applied (ie. "linear" activation: `a(x) = x`).
#'
#' @param use_bias
#' Boolean, (default `TRUE`), whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix, used for
#' the linear transformation of the inputs. Default: `glorot_uniform`.
#'
#' @param recurrent_initializer
#' Initializer for the `recurrent_kernel` weights
#' matrix, used for the linear transformation of the recurrent state.
#' Default: `orthogonal`.
#'
#' @param bias_initializer
#' Initializer for the bias vector. Default: `zeros`.
#'
#' @param unit_forget_bias
#' Boolean (default `TRUE`). If TRUE, add 1 to the bias of
#' the forget gate at initialization. Setting it to true will also force
#' `bias_initializer="zeros"`. This is recommended in [Jozefowicz et
#'   al.](https://github.com/mlresearch/v37/blob/gh-pages/jozefowicz15.pdf)
#'
#' @param kernel_regularizer
#' Regularizer function applied to the `kernel` weights
#' matrix. Default: `NULL`.
#'
#' @param recurrent_regularizer
#' Regularizer function applied to
#' the `recurrent_kernel` weights matrix. Default: `NULL`.
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector.
#' Default: `NULL`.
#'
#' @param kernel_constraint
#' Constraint function applied to the `kernel` weights
#' matrix. Default: `NULL`.
#'
#' @param recurrent_constraint
#' Constraint function applied to the
#' `recurrent_kernel` weights matrix. Default: `NULL`.
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector. Default:
#' `NULL`.
#'
#' @param dropout
#' Float between 0 and 1. Fraction of the units to drop for the
#' linear transformation of the inputs. Default: 0.
#'
#' @param recurrent_dropout
#' Float between 0 and 1. Fraction of the units to drop
#' for the linear transformation of the recurrent state. Default: 0.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_lstm_cell <-
function(units, activation = "tanh", recurrent_activation = "sigmoid",
    use_bias = TRUE, kernel_initializer = "glorot_uniform", recurrent_initializer = "orthogonal",
    bias_initializer = "zeros", unit_forget_bias = TRUE, kernel_regularizer = NULL,
    recurrent_regularizer = NULL, bias_regularizer = NULL, kernel_constraint = NULL,
    recurrent_constraint = NULL, bias_constraint = NULL, dropout = 0,
    recurrent_dropout = 0, ...)
{
    args <- capture_args(match.call(), list(units = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape))
    do.call(keras$layers$LSTMCell, args)
}


# <class 'keras.src.layers.core.masking.Masking'>
#' Masks a sequence by using a mask value to skip timesteps
#'
#' @details
#' For each timestep in the input tensor (dimension #1 in the tensor),
#' if all values in the input tensor at that timestep
#' are equal to `mask_value`, then the timestep will be masked (skipped)
#' in all downstream layers (as long as they support masking).
#'
#' If any downstream layer does not support masking yet receives such
#' an input mask, an exception will be raised.
#'
#' Example:
#'
#' Consider a Numpy data array `x` of shape `(samples, timesteps, features)`,
#' to be fed to an LSTM layer. You want to mask timestep #3 and #5 because you
#' lack data for these timesteps. You can:
#'
#' - Set `x[:, 3, :] = 0.` and `x[:, 5, :] = 0.`
#' - Insert a `Masking` layer with `mask_value=0.` before the LSTM layer:
#'
#' ```python
#' samples, timesteps, features = 32, 10, 8
#' inputs = np.random.random([samples, timesteps, features]).astype(np.float32)
#' inputs[:, 3, :] = 0.
#' inputs[:, 5, :] = 0.
#'
#' model = tf.keras.models.Sequential()
#' model.add(tf.keras.layers.Masking(mask_value=0.,
#'                                   input_shape=(timesteps, features)))
#' model.add(tf.keras.layers.LSTM(32))
#'
#' output = model(inputs)
#' # The time step 3 and 5 will be skipped from LSTM calculation.
#' ```
#'
#' See [the masking and padding guide](
#'   https://www.tensorflow.org/guide/keras/masking_and_padding)
#' for more details.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_masking <-
function(object, mask_value = 0, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$Masking, object, args)
}


# <class 'keras.src.layers.merging.maximum.Maximum'>
#' Layer that computes the maximum (element-wise) a list of inputs
#'
#' @details
#' It takes as input a list of tensors, all of the same shape, and returns
#' a single tensor (also of the same shape).
#'
#' ```python
#' >>> tf.keras.layers.Maximum()([np.arange(5).reshape(5, 1),
#' ...                            np.arange(5, 10).reshape(5, 1)])
#' <tf.Tensor: shape=(5, 1), dtype=int64, numpy=
#' array([[5],
#'      [6],
#'      [7],
#'      [8],
#'      [9]])>
#' ```
#'
#' ```python
#' >>> x1 = tf.keras.layers.Dense(8)(np.arange(10).reshape(5, 2))
#' >>> x2 = tf.keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))
#' >>> maxed = tf.keras.layers.Maximum()([x1, x2])
#' >>> maxed.shape
#' TensorShape([5, 8])
#' ```
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_maximum <-
function(inputs, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = c("...", "inputs"))
    dots <- split_dots_named_unnamed(list(...))
    if (missing(inputs))
        inputs <- NULL
    else if (!is.null(inputs) && !is.list(inputs))
        inputs <- list(inputs)
    inputs <- c(inputs, dots$unnamed)
    args <- c(args, dots$named)
    layer <- do.call(keras$layers$Maximum, args)
    if (length(inputs))
        layer(inputs)
    else layer
}


# <class 'keras.src.layers.pooling.max_pooling1d.MaxPooling1D'>
#' Max pooling operation for 1D temporal data
#'
#' @details
#' Downsamples the input representation by taking the maximum value over a
#' spatial window of size `pool_size`. The window is shifted by `strides`.  The
#' resulting output, when using the `"valid"` padding option, has a shape of:
#' `output_shape = (input_shape - pool_size + 1) / strides)`
#'
#' The resulting output shape when using the `"same"` padding option is:
#' `output_shape = input_shape / strides`
#'
#' For example, for `strides=1` and `padding="valid"`:
#'
#' ```python
#' >>> x = tf.constant([1., 2., 3., 4., 5.])
#' >>> x = tf.reshape(x, [1, 5, 1])
#' >>> max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=2,
#' ...    strides=1, padding='valid')
#' >>> max_pool_1d(x)
#' <tf.Tensor: shape=(1, 4, 1), dtype=float32, numpy=
#' array([[[2.],
#'         [3.],
#'         [4.],
#'         [5.]]], dtype=float32)>
#' ```
#'
#' For example, for `strides=2` and `padding="valid"`:
#'
#' ```python
#' >>> x = tf.constant([1., 2., 3., 4., 5.])
#' >>> x = tf.reshape(x, [1, 5, 1])
#' >>> max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=2,
#' ...    strides=2, padding='valid')
#' >>> max_pool_1d(x)
#' <tf.Tensor: shape=(1, 2, 1), dtype=float32, numpy=
#' array([[[2.],
#'         [4.]]], dtype=float32)>
#' ```
#'
#' For example, for `strides=1` and `padding="same"`:
#'
#' ```python
#' >>> x = tf.constant([1., 2., 3., 4., 5.])
#' >>> x = tf.reshape(x, [1, 5, 1])
#' >>> max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=2,
#' ...    strides=1, padding='same')
#' >>> max_pool_1d(x)
#' <tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=
#' array([[[2.],
#'         [3.],
#'         [4.],
#'         [5.],
#'         [5.]]], dtype=float32)>
#' ```
#'
#' Input shape:
#'   - If `data_format='channels_last'`:
#'     3D tensor with shape `(batch_size, steps, features)`.
#'   - If `data_format='channels_first'`:
#'     3D tensor with shape `(batch_size, features, steps)`.
#'
#' Output shape:
#'   - If `data_format='channels_last'`:
#'     3D tensor with shape `(batch_size, downsampled_steps, features)`.
#'   - If `data_format='channels_first'`:
#'     3D tensor with shape `(batch_size, features, downsampled_steps)`.
#'
#' @param pool_size
#' Integer, size of the max pooling window.
#'
#' @param strides
#' Integer, or NULL. Specifies how much the pooling window moves
#' for each pooling step.
#' If NULL, it will default to `pool_size`.
#'
#' @param padding
#' One of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding evenly to
#' the left/right or up/down of the input such that output has the same
#' height/width dimension as the input.
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch, steps, features)` while `channels_first`
#' corresponds to inputs with shape
#' `(batch, features, steps)`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_max_pooling_1d <-
function(object, pool_size = 2L, strides = NULL, padding = "valid",
    data_format = "channels_last", ...)
{
    args <- capture_args(match.call(), list(pool_size = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape, strides = as_nullable_integer),
        ignore = "object")
    create_layer(keras$layers$MaxPooling1D, object, args)
}


# <class 'keras.src.layers.pooling.max_pooling2d.MaxPooling2D'>
#' Max pooling operation for 2D spatial data
#'
#' @details
#' Downsamples the input along its spatial dimensions (height and width)
#' by taking the maximum value over an input window
#' (of size defined by `pool_size`) for each channel of the input.
#' The window is shifted by `strides` along each dimension.
#'
#' The resulting output,
#' when using the `"valid"` padding option, has a spatial shape
#' (number of rows or columns) of:
#' `output_shape = math.floor((input_shape - pool_size) / strides) + 1`
#' (when `input_shape >= pool_size`)
#'
#' The resulting output shape when using the `"same"` padding option is:
#' `output_shape = math.floor((input_shape - 1) / strides) + 1`
#'
#' For example, for `strides=(1, 1)` and `padding="valid"`:
#'
#' ```python
#' >>> x = tf.constant([[1., 2., 3.],
#' ...                  [4., 5., 6.],
#' ...                  [7., 8., 9.]])
#' >>> x = tf.reshape(x, [1, 3, 3, 1])
#' >>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),
#' ...    strides=(1, 1), padding='valid')
#' >>> max_pool_2d(x)
#' <tf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy=
#'   array([[[[5.],
#'            [6.]],
#'           [[8.],
#'            [9.]]]], dtype=float32)>
#' ```
#'
#' For example, for `strides=(2, 2)` and `padding="valid"`:
#'
#' ```python
#' >>> x = tf.constant([[1., 2., 3., 4.],
#' ...                  [5., 6., 7., 8.],
#' ...                  [9., 10., 11., 12.]])
#' >>> x = tf.reshape(x, [1, 3, 4, 1])
#' >>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),
#' ...    strides=(2, 2), padding='valid')
#' >>> max_pool_2d(x)
#' <tf.Tensor: shape=(1, 1, 2, 1), dtype=float32, numpy=
#'   array([[[[6.],
#'            [8.]]]], dtype=float32)>
#' ```
#'
#' Usage Example:
#'
#' ```python
#' >>> input_image = tf.constant([[[[1.], [1.], [2.], [4.]],
#' ...                            [[2.], [2.], [3.], [2.]],
#' ...                            [[4.], [1.], [1.], [1.]],
#' ...                            [[2.], [2.], [1.], [4.]]]])
#' >>> output = tf.constant([[[[1], [0]],
#' ...                       [[0], [1]]]])
#' >>> model = tf.keras.models.Sequential()
#' >>> model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2),
#' ...    input_shape=(4, 4, 1)))
#' >>> model.compile('adam', 'mean_squared_error')
#' >>> model.predict(input_image, steps=1)
#' array([[[[2.],
#'          [4.]],
#'         [[4.],
#'          [4.]]]], dtype=float32)
#' ```
#'
#' For example, for stride=(1, 1) and padding="same":
#'
#' ```python
#' >>> x = tf.constant([[1., 2., 3.],
#' ...                  [4., 5., 6.],
#' ...                  [7., 8., 9.]])
#' >>> x = tf.reshape(x, [1, 3, 3, 1])
#' >>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),
#' ...    strides=(1, 1), padding='same')
#' >>> max_pool_2d(x)
#' <tf.Tensor: shape=(1, 3, 3, 1), dtype=float32, numpy=
#'   array([[[[5.],
#'            [6.],
#'            [6.]],
#'           [[8.],
#'            [9.],
#'            [9.]],
#'           [[8.],
#'            [9.],
#'            [9.]]]], dtype=float32)>
#' ```
#'
#' Input shape:
#'   - If `data_format='channels_last'`:
#'     4D tensor with shape `(batch_size, rows, cols, channels)`.
#'   - If `data_format='channels_first'`:
#'     4D tensor with shape `(batch_size, channels, rows, cols)`.
#'
#' Output shape:
#'   - If `data_format='channels_last'`:
#'     4D tensor with shape `(batch_size, pooled_rows, pooled_cols, channels)`.
#'   - If `data_format='channels_first'`:
#'     4D tensor with shape `(batch_size, channels, pooled_rows, pooled_cols)`.
#'
#'   A tensor of rank 4 representing the maximum pooled values.  See above for
#'
#' @param pool_size
#' integer or list of 2 integers,
#' window size over which to take the maximum.
#' `(2, 2)` will take the max value over a 2x2 pooling window.
#' If only one integer is specified, the same window length
#' will be used for both dimensions.
#'
#' @param strides
#' Integer, list of 2 integers, or NULL.
#' Strides values.  Specifies how far the pooling window moves
#' for each pooling step. If NULL, it will default to `pool_size`.
#'
#' @param padding
#' One of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding evenly to
#' the left/right or up/down of the input such that output has the same
#' height/width dimension as the input.
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch, height, width, channels)` while `channels_first`
#' corresponds to inputs with shape
#' `(batch, channels, height, width)`.
#' When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#'  `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_max_pooling_2d <-
function(object, pool_size = list(2L, 2L), strides = NULL, padding = "valid",
    data_format = NULL, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape,
        pool_size = as.integer, strides = as_nullable_integer),
        ignore = "object")
    create_layer(keras$layers$MaxPooling2D, object, args)
}


# <class 'keras.src.layers.pooling.max_pooling3d.MaxPooling3D'>
#' Max pooling operation for 3D data (spatial or spatio-temporal)
#'
#' @details
#' Downsamples the input along its spatial dimensions (depth, height, and
#' width) by taking the maximum value over an input window (of size defined by
#' `pool_size`) for each channel of the input.  The window is shifted by
#' `strides` along each dimension.
#'
#' Input shape:
#'   - If `data_format='channels_last'`:
#'     5D tensor with shape:
#'     `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`
#'   - If `data_format='channels_first'`:
#'     5D tensor with shape:
#'     `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`
#'
#' Output shape:
#'   - If `data_format='channels_last'`:
#'     5D tensor with shape:
#'     `(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)`
#'   - If `data_format='channels_first'`:
#'     5D tensor with shape:
#'     `(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)`
#'
#' Example:
#'
#' ```python
#' depth = 30
#' height = 30
#' width = 30
#' input_channels = 3
#'
#' inputs = tf.keras.Input(shape=(depth, height, width, input_channels))
#' layer = tf.keras.layers.MaxPooling3D(pool_size=3)
#' outputs = layer(inputs)  # Shape: (batch_size, 10, 10, 10, 3)
#' ```
#'
#' @param pool_size
#' Tuple of 3 integers,
#' factors by which to downscale (dim1, dim2, dim3).
#' `(2, 2, 2)` will halve the size of the 3D input in each dimension.
#'
#' @param strides
#' list of 3 integers, or NULL. Strides values.
#'
#' @param padding
#' One of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding evenly to
#' the left/right or up/down of the input such that output has the same
#' height/width dimension as the input.
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`
#' while `channels_first` corresponds to inputs with shape
#' `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.
#' When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#'  `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_max_pooling_3d <-
function(object, pool_size = list(2L, 2L, 2L), strides = NULL,
    padding = "valid", data_format = NULL, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape,
        pool_size = as.integer, strides = as_nullable_integer),
        ignore = "object")
    create_layer(keras$layers$MaxPooling3D, object, args)
}


# <class 'keras.src.layers.pooling.max_pooling1d.MaxPooling1D'>
#' Max pooling operation for 1D temporal data
#'
#' @details
#' Downsamples the input representation by taking the maximum value over a
#' spatial window of size `pool_size`. The window is shifted by `strides`.  The
#' resulting output, when using the `"valid"` padding option, has a shape of:
#' `output_shape = (input_shape - pool_size + 1) / strides)`
#'
#' The resulting output shape when using the `"same"` padding option is:
#' `output_shape = input_shape / strides`
#'
#' For example, for `strides=1` and `padding="valid"`:
#'
#' ```python
#' >>> x = tf.constant([1., 2., 3., 4., 5.])
#' >>> x = tf.reshape(x, [1, 5, 1])
#' >>> max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=2,
#' ...    strides=1, padding='valid')
#' >>> max_pool_1d(x)
#' <tf.Tensor: shape=(1, 4, 1), dtype=float32, numpy=
#' array([[[2.],
#'         [3.],
#'         [4.],
#'         [5.]]], dtype=float32)>
#' ```
#'
#' For example, for `strides=2` and `padding="valid"`:
#'
#' ```python
#' >>> x = tf.constant([1., 2., 3., 4., 5.])
#' >>> x = tf.reshape(x, [1, 5, 1])
#' >>> max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=2,
#' ...    strides=2, padding='valid')
#' >>> max_pool_1d(x)
#' <tf.Tensor: shape=(1, 2, 1), dtype=float32, numpy=
#' array([[[2.],
#'         [4.]]], dtype=float32)>
#' ```
#'
#' For example, for `strides=1` and `padding="same"`:
#'
#' ```python
#' >>> x = tf.constant([1., 2., 3., 4., 5.])
#' >>> x = tf.reshape(x, [1, 5, 1])
#' >>> max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=2,
#' ...    strides=1, padding='same')
#' >>> max_pool_1d(x)
#' <tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=
#' array([[[2.],
#'         [3.],
#'         [4.],
#'         [5.],
#'         [5.]]], dtype=float32)>
#' ```
#'
#' Input shape:
#'   - If `data_format='channels_last'`:
#'     3D tensor with shape `(batch_size, steps, features)`.
#'   - If `data_format='channels_first'`:
#'     3D tensor with shape `(batch_size, features, steps)`.
#'
#' Output shape:
#'   - If `data_format='channels_last'`:
#'     3D tensor with shape `(batch_size, downsampled_steps, features)`.
#'   - If `data_format='channels_first'`:
#'     3D tensor with shape `(batch_size, features, downsampled_steps)`.
#'
#' @param pool_size
#' Integer, size of the max pooling window.
#'
#' @param strides
#' Integer, or NULL. Specifies how much the pooling window moves
#' for each pooling step.
#' If NULL, it will default to `pool_size`.
#'
#' @param padding
#' One of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding evenly to
#' the left/right or up/down of the input such that output has the same
#' height/width dimension as the input.
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch, steps, features)` while `channels_first`
#' corresponds to inputs with shape
#' `(batch, features, steps)`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_max_pooling_1d <-
function(object, pool_size = 2L, strides = NULL, padding = "valid",
    data_format = "channels_last", ...)
{
    args <- capture_args(match.call(), list(pool_size = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape, strides = as_nullable_integer),
        ignore = "object")
    create_layer(keras$layers$MaxPooling1D, object, args)
}


# <class 'keras.src.layers.pooling.max_pooling2d.MaxPooling2D'>
#' Max pooling operation for 2D spatial data
#'
#' @details
#' Downsamples the input along its spatial dimensions (height and width)
#' by taking the maximum value over an input window
#' (of size defined by `pool_size`) for each channel of the input.
#' The window is shifted by `strides` along each dimension.
#'
#' The resulting output,
#' when using the `"valid"` padding option, has a spatial shape
#' (number of rows or columns) of:
#' `output_shape = math.floor((input_shape - pool_size) / strides) + 1`
#' (when `input_shape >= pool_size`)
#'
#' The resulting output shape when using the `"same"` padding option is:
#' `output_shape = math.floor((input_shape - 1) / strides) + 1`
#'
#' For example, for `strides=(1, 1)` and `padding="valid"`:
#'
#' ```python
#' >>> x = tf.constant([[1., 2., 3.],
#' ...                  [4., 5., 6.],
#' ...                  [7., 8., 9.]])
#' >>> x = tf.reshape(x, [1, 3, 3, 1])
#' >>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),
#' ...    strides=(1, 1), padding='valid')
#' >>> max_pool_2d(x)
#' <tf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy=
#'   array([[[[5.],
#'            [6.]],
#'           [[8.],
#'            [9.]]]], dtype=float32)>
#' ```
#'
#' For example, for `strides=(2, 2)` and `padding="valid"`:
#'
#' ```python
#' >>> x = tf.constant([[1., 2., 3., 4.],
#' ...                  [5., 6., 7., 8.],
#' ...                  [9., 10., 11., 12.]])
#' >>> x = tf.reshape(x, [1, 3, 4, 1])
#' >>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),
#' ...    strides=(2, 2), padding='valid')
#' >>> max_pool_2d(x)
#' <tf.Tensor: shape=(1, 1, 2, 1), dtype=float32, numpy=
#'   array([[[[6.],
#'            [8.]]]], dtype=float32)>
#' ```
#'
#' Usage Example:
#'
#' ```python
#' >>> input_image = tf.constant([[[[1.], [1.], [2.], [4.]],
#' ...                            [[2.], [2.], [3.], [2.]],
#' ...                            [[4.], [1.], [1.], [1.]],
#' ...                            [[2.], [2.], [1.], [4.]]]])
#' >>> output = tf.constant([[[[1], [0]],
#' ...                       [[0], [1]]]])
#' >>> model = tf.keras.models.Sequential()
#' >>> model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2),
#' ...    input_shape=(4, 4, 1)))
#' >>> model.compile('adam', 'mean_squared_error')
#' >>> model.predict(input_image, steps=1)
#' array([[[[2.],
#'          [4.]],
#'         [[4.],
#'          [4.]]]], dtype=float32)
#' ```
#'
#' For example, for stride=(1, 1) and padding="same":
#'
#' ```python
#' >>> x = tf.constant([[1., 2., 3.],
#' ...                  [4., 5., 6.],
#' ...                  [7., 8., 9.]])
#' >>> x = tf.reshape(x, [1, 3, 3, 1])
#' >>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),
#' ...    strides=(1, 1), padding='same')
#' >>> max_pool_2d(x)
#' <tf.Tensor: shape=(1, 3, 3, 1), dtype=float32, numpy=
#'   array([[[[5.],
#'            [6.],
#'            [6.]],
#'           [[8.],
#'            [9.],
#'            [9.]],
#'           [[8.],
#'            [9.],
#'            [9.]]]], dtype=float32)>
#' ```
#'
#' Input shape:
#'   - If `data_format='channels_last'`:
#'     4D tensor with shape `(batch_size, rows, cols, channels)`.
#'   - If `data_format='channels_first'`:
#'     4D tensor with shape `(batch_size, channels, rows, cols)`.
#'
#' Output shape:
#'   - If `data_format='channels_last'`:
#'     4D tensor with shape `(batch_size, pooled_rows, pooled_cols, channels)`.
#'   - If `data_format='channels_first'`:
#'     4D tensor with shape `(batch_size, channels, pooled_rows, pooled_cols)`.
#'
#'   A tensor of rank 4 representing the maximum pooled values.  See above for
#'
#' @param pool_size
#' integer or list of 2 integers,
#' window size over which to take the maximum.
#' `(2, 2)` will take the max value over a 2x2 pooling window.
#' If only one integer is specified, the same window length
#' will be used for both dimensions.
#'
#' @param strides
#' Integer, list of 2 integers, or NULL.
#' Strides values.  Specifies how far the pooling window moves
#' for each pooling step. If NULL, it will default to `pool_size`.
#'
#' @param padding
#' One of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding evenly to
#' the left/right or up/down of the input such that output has the same
#' height/width dimension as the input.
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch, height, width, channels)` while `channels_first`
#' corresponds to inputs with shape
#' `(batch, channels, height, width)`.
#' When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#'  `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_max_pooling_2d <-
function(object, pool_size = list(2L, 2L), strides = NULL, padding = "valid",
    data_format = NULL, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape,
        pool_size = as.integer, strides = as_nullable_integer),
        ignore = "object")
    create_layer(keras$layers$MaxPooling2D, object, args)
}


# <class 'keras.src.layers.pooling.max_pooling3d.MaxPooling3D'>
#' Max pooling operation for 3D data (spatial or spatio-temporal)
#'
#' @details
#' Downsamples the input along its spatial dimensions (depth, height, and
#' width) by taking the maximum value over an input window (of size defined by
#' `pool_size`) for each channel of the input.  The window is shifted by
#' `strides` along each dimension.
#'
#' Input shape:
#'   - If `data_format='channels_last'`:
#'     5D tensor with shape:
#'     `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`
#'   - If `data_format='channels_first'`:
#'     5D tensor with shape:
#'     `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`
#'
#' Output shape:
#'   - If `data_format='channels_last'`:
#'     5D tensor with shape:
#'     `(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)`
#'   - If `data_format='channels_first'`:
#'     5D tensor with shape:
#'     `(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)`
#'
#' Example:
#'
#' ```python
#' depth = 30
#' height = 30
#' width = 30
#' input_channels = 3
#'
#' inputs = tf.keras.Input(shape=(depth, height, width, input_channels))
#' layer = tf.keras.layers.MaxPooling3D(pool_size=3)
#' outputs = layer(inputs)  # Shape: (batch_size, 10, 10, 10, 3)
#' ```
#'
#' @param pool_size
#' Tuple of 3 integers,
#' factors by which to downscale (dim1, dim2, dim3).
#' `(2, 2, 2)` will halve the size of the 3D input in each dimension.
#'
#' @param strides
#' list of 3 integers, or NULL. Strides values.
#'
#' @param padding
#' One of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding evenly to
#' the left/right or up/down of the input such that output has the same
#' height/width dimension as the input.
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`
#' while `channels_first` corresponds to inputs with shape
#' `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.
#' When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#'  `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_max_pooling_3d <-
function(object, pool_size = list(2L, 2L, 2L), strides = NULL,
    padding = "valid", data_format = NULL, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape,
        pool_size = as.integer, strides = as_nullable_integer),
        ignore = "object")
    create_layer(keras$layers$MaxPooling3D, object, args)
}


# <class 'keras.src.layers.merging.minimum.Minimum'>
#' Layer that computes the minimum (element-wise) a list of inputs
#'
#' @details
#' It takes as input a list of tensors, all of the same shape, and returns
#' a single tensor (also of the same shape).
#'
#' ```python
#' >>> tf.keras.layers.Minimum()([np.arange(5).reshape(5, 1),
#' ...                            np.arange(5, 10).reshape(5, 1)])
#' <tf.Tensor: shape=(5, 1), dtype=int64, numpy=
#' array([[0],
#'      [1],
#'      [2],
#'      [3],
#'      [4]])>
#' ```
#'
#' ```python
#' >>> x1 = tf.keras.layers.Dense(8)(np.arange(10).reshape(5, 2))
#' >>> x2 = tf.keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))
#' >>> minned = tf.keras.layers.Minimum()([x1, x2])
#' >>> minned.shape
#' TensorShape([5, 8])
#' ```
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_minimum <-
function(inputs, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = c("...", "inputs"))
    dots <- split_dots_named_unnamed(list(...))
    if (missing(inputs))
        inputs <- NULL
    else if (!is.null(inputs) && !is.list(inputs))
        inputs <- list(inputs)
    inputs <- c(inputs, dots$unnamed)
    args <- c(args, dots$named)
    layer <- do.call(keras$layers$Minimum, args)
    if (length(inputs))
        layer(inputs)
    else layer
}


# <class 'keras.src.layers.attention.multi_head_attention.MultiHeadAttention'>
#' MultiHeadAttention layer
#'
#' @details
#' This is an implementation of multi-headed attention as described in the
#' paper "Attention is all you Need" (Vaswani et al., 2017).
#' If `query`, `key,` `value` are the same, then
#' this is self-attention. Each timestep in `query` attends to the
#' corresponding sequence in `key`, and returns a fixed-width vector.
#'
#' This layer first projects `query`, `key` and `value`. These are
#' (effectively) a list of tensors of length `num_attention_heads`, where the
#' corresponding shapes are `(batch_size, <query dimensions>, key_dim)`,
#' `(batch_size, <key/value dimensions>, key_dim)`,
#' `(batch_size, <key/value dimensions>, value_dim)`.
#'
#' Then, the query and key tensors are dot-producted and scaled. These are
#' softmaxed to obtain attention probabilities. The value tensors are then
#' interpolated by these probabilities, then concatenated back to a single
#' tensor.
#'
#' Finally, the result tensor with the last dimension as value_dim can take an
#' linear projection and return.
#'
#' When using `MultiHeadAttention` inside a custom layer, the custom layer must
#' implement its own `build()` method and call `MultiHeadAttention`'s
#' `_build_from_signature()` there.
#' This enables weights to be restored correctly when the model is loaded.
#'
#' Performs 1D cross-attention over two sequence inputs with an attention mask.
#' Returns the additional attention weights over heads.
#'
#' ```python
#' >>> layer = MultiHeadAttention(num_heads=2, key_dim=2)
#' >>> target = tf.keras.Input(shape=[8, 16])
#' >>> source = tf.keras.Input(shape=[4, 16])
#' >>> output_tensor, weights = layer(target, source,
#' ...                                return_attention_scores=TRUE)
#' >>> print(output_tensor.shape)
#' (NULL, 8, 16)
#' >>> print(weights.shape)
#' (NULL, 2, 8, 4)
#' ```
#'
#' Performs 2D self-attention over a 5D input tensor on axes 2 and 3.
#'
#' ```python
#' >>> layer = MultiHeadAttention(
#' ...     num_heads=2, key_dim=2, attention_axes=(2, 3))
#' >>> input_tensor = tf.keras.Input(shape=[5, 3, 4, 16])
#' >>> output_tensor = layer(input_tensor, input_tensor)
#' >>> print(output_tensor.shape)
#' (NULL, 5, 3, 4, 16)
#' ```
#'
#' Call arguments:
#'     query: Query `Tensor` of shape `(B, T, dim)`.
#'     value: Value `Tensor` of shape `(B, S, dim)`.
#'     key: Optional key `Tensor` of shape `(B, S, dim)`. If not given, will
#'         use `value` for both `key` and `value`, which is the most common
#'         case.
#'     attention_mask: a boolean mask of shape `(B, T, S)`, that prevents
#'         attention to certain positions. The boolean mask specifies which
#'         query elements can attend to which key elements, 1 indicates
#'         attention and 0 indicates no attention. Broadcasting can happen for
#'         the missing batch dimensions and the head dimension.
#'     return_attention_scores: A boolean to indicate whether the output should
#'         be `(attention_output, attention_scores)` if `TRUE`, or
#'         `attention_output` if `FALSE`. Defaults to `FALSE`.
#'     training: Python boolean indicating whether the layer should behave in
#'         training mode (adding dropout) or in inference mode (no dropout).
#'         Will go with either using the training mode of the parent
#'         layer/model, or FALSE (inference) if there is no parent layer.
#'     use_causal_mask: A boolean to indicate whether to apply a causal mask to
#'         prevent tokens from attending to future tokens (e.g., used in a
#'         decoder Transformer).
#'
#' @param num_heads
#' Number of attention heads.
#'
#' @param key_dim
#' Size of each attention head for query and key.
#'
#' @param value_dim
#' Size of each attention head for value.
#'
#' @param dropout
#' Dropout probability.
#'
#' @param use_bias
#' Boolean, whether the dense layers use bias vectors/matrices.
#'
#' @param output_shape
#' The expected shape of an output tensor, besides the batch
#' and sequence dims. If not specified, projects back to the query
#' feature dim (the query input's last dimension).
#'
#' @param attention_axes
#' axes over which the attention is applied. `NULL` means
#' attention over all axes, but batch, heads, and features.
#'
#' @param kernel_initializer
#' Initializer for dense layer kernels.
#'
#' @param bias_initializer
#' Initializer for dense layer biases.
#'
#' @param kernel_regularizer
#' Regularizer for dense layer kernels.
#'
#' @param bias_regularizer
#' Regularizer for dense layer biases.
#'
#' @param activity_regularizer
#' Regularizer for dense layer activity.
#'
#' @param kernel_constraint
#' Constraint for dense layer kernels.
#'
#' @param bias_constraint
#' Constraint for dense layer kernels.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_multi_head_attention <-
function(inputs, num_heads, key_dim, value_dim = NULL, dropout = 0,
    use_bias = TRUE, output_shape = NULL, attention_axes = NULL,
    kernel_initializer = "glorot_uniform", bias_initializer = "zeros",
    kernel_regularizer = NULL, bias_regularizer = NULL, activity_regularizer = NULL,
    kernel_constraint = NULL, bias_constraint = NULL, ...)
{
    args <- capture_args(match.call(), list(num_heads = as.integer,
        key_dim = as.integer, value_dim = as.integer, attention_axes = as_nullable_integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "inputs")
    layer <- do.call(keras$layers$MultiHeadAttention, args)
    if (missing(inputs) || is.null(inputs))
        return(layer)
    if (!is.list(inputs))
        inputs <- list(inputs)
    do.call(layer, inputs)
}


# <class 'keras.src.layers.merging.multiply.Multiply'>
#' Layer that multiplies (element-wise) a list of inputs
#'
#' @details
#' It takes as input a list of tensors, all of the same shape, and returns
#' a single tensor (also of the same shape).
#'
#' ```python
#' >>> tf.keras.layers.Multiply()([np.arange(5).reshape(5, 1),
#' ...                             np.arange(5, 10).reshape(5, 1)])
#' <tf.Tensor: shape=(5, 1), dtype=int64, numpy=
#' array([[ 0],
#'      [ 6],
#'      [14],
#'      [24],
#'      [36]])>
#' ```
#'
#' ```python
#' >>> x1 = tf.keras.layers.Dense(8)(np.arange(10).reshape(5, 2))
#' >>> x2 = tf.keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))
#' >>> multiplied = tf.keras.layers.Multiply()([x1, x2])
#' >>> multiplied.shape
#' TensorShape([5, 8])
#' ```
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_multiply <-
function(inputs, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = c("...", "inputs"))
    dots <- split_dots_named_unnamed(list(...))
    if (missing(inputs))
        inputs <- NULL
    else if (!is.null(inputs) && !is.list(inputs))
        inputs <- list(inputs)
    inputs <- c(inputs, dots$unnamed)
    args <- c(args, dots$named)
    layer <- do.call(keras$layers$Multiply, args)
    if (length(inputs))
        layer(inputs)
    else layer
}


# <class 'keras.src.layers.preprocessing.normalization.Normalization'>
#' A preprocessing layer which normalizes continuous features
#'
#' @details
#' This layer will shift and scale inputs into a distribution centered around
#' 0 with standard deviation 1. It accomplishes this by precomputing the mean
#' and variance of the data, and calling `(input - mean) / sqrt(var)` at
#' runtime.
#'
#' The mean and variance values for the layer must be either supplied on
#' construction or learned via `adapt()`. `adapt()` will compute the mean and
#' variance of the data and store them as the layer's weights. `adapt()` should
#' be called before `fit()`, `evaluate()`, or `predict()`.
#'
#' For an overview and full list of preprocessing layers, see the preprocessing
#' [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).
#'
#' Calculate a global mean and variance by analyzing the dataset in `adapt()`.
#'
#' ```python
#' >>> adapt_data = np.array([1., 2., 3., 4., 5.], dtype='float32')
#' >>> input_data = np.array([1., 2., 3.], dtype='float32')
#' >>> layer = tf.keras.layers.Normalization(axis=NULL)
#' >>> layer.adapt(adapt_data)
#' >>> layer(input_data)
#' <tf.Tensor: shape=(3,), dtype=float32, numpy=
#' array([-1.4142135, -0.70710677, 0.], dtype=float32)>
#' ```
#'
#' Calculate a mean and variance for each index on the last axis.
#'
#' ```python
#' >>> adapt_data = np.array([[0., 7., 4.],
#' ...                        [2., 9., 6.],
#' ...                        [0., 7., 4.],
#' ...                        [2., 9., 6.]], dtype='float32')
#' >>> input_data = np.array([[0., 7., 4.]], dtype='float32')
#' >>> layer = tf.keras.layers.Normalization(axis=-1)
#' >>> layer.adapt(adapt_data)
#' >>> layer(input_data)
#' <tf.Tensor: shape=(1, 3), dtype=float32, numpy=
#' array([-1., -1., -1.], dtype=float32)>
#' ```
#'
#' Pass the mean and variance directly.
#'
#' ```python
#' >>> input_data = np.array([[1.], [2.], [3.]], dtype='float32')
#' >>> layer = tf.keras.layers.Normalization(mean=3., variance=2.)
#' >>> layer(input_data)
#' <tf.Tensor: shape=(3, 1), dtype=float32, numpy=
#' array([[-1.4142135 ],
#'        [-0.70710677],
#'        [ 0.        ]], dtype=float32)>
#' ```
#'
#' Use the layer to de-normalize inputs (after adapting the layer).
#'
#' ```python
#' >>> adapt_data = np.array([[0., 7., 4.],
#' ...                        [2., 9., 6.],
#' ...                        [0., 7., 4.],
#' ...                        [2., 9., 6.]], dtype='float32')
#' >>> input_data = np.array([[1., 2., 3.]], dtype='float32')
#' >>> layer = tf.keras.layers.Normalization(axis=-1, invert=TRUE)
#' >>> layer.adapt(adapt_data)
#' >>> layer(input_data)
#' <tf.Tensor: shape=(1, 3), dtype=float32, numpy=
#' array([2., 10., 8.], dtype=float32)>
#' ```
#'
#' @param axis
#' Integer, list of integers, or NULL. The axis or axes that should
#' have a separate mean and variance for each index in the shape. For
#' example, if shape is `(NULL, 5)` and `axis=1`, the layer will track 5
#' separate mean and variance values for the last axis. If `axis` is set
#' to `NULL`, the layer will normalize all elements in the input by a
#' scalar mean and variance. When `-1` the last axis of the
#' input is assumed to be a feature dimension and is normalized per
#' index. Note that in the specific case of batched scalar inputs where
#' the only axis is the batch axis, the default will normalize each index
#' in the batch separately. In this case, consider passing `axis=NULL`.
#' Defaults to `-1`.
#'
#' @param mean
#' The mean value(s) to use during normalization. The passed value(s)
#' will be broadcast to the shape of the kept axes above; if the value(s)
#' cannot be broadcast, an error will be raised when this layer's
#' `build()` method is called.
#'
#' @param variance
#' The variance value(s) to use during normalization. The passed
#' value(s) will be broadcast to the shape of the kept axes above; if the
#' value(s) cannot be broadcast, an error will be raised when this
#' layer's `build()` method is called.
#'
#' @param invert
#' If TRUE, this layer will apply the inverse transformation
#' to its inputs: it would turn a normalized input back into its
#' original form.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_normalization <-
function(object, axis = -1L, mean = NULL, variance = NULL, invert = FALSE,
    ...)
{
    args <- capture_args(match.call(), list(axis = as_axis, input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$Normalization, object, args)
}


# <class 'keras.src.layers.reshaping.permute.Permute'>
#' Permutes the dimensions of the input according to a given pattern
#'
#' @details
#' Useful e.g. connecting RNNs and convnets.
#'
#' Example:
#'
#' ```python
#' model = Sequential()
#' model.add(Permute((2, 1), input_shape=(10, 64)))
#' # now: model.output_shape == (NULL, 64, 10)
#' # note: `NULL` is the batch dimension
#' ```
#'
#' Input shape:
#'   Arbitrary. Use the keyword argument `input_shape`
#'   (list of integers, does not include the samples axis)
#'   when using this layer as the first layer in a model.
#'
#' Output shape:
#'   Same as the input shape, but with the dimensions re-ordered according
#'   to the specified pattern.
#'
#' @param dims
#' Tuple of integers. Permutation pattern does not include the
#' samples dimension. Indexing starts at 1.
#' For instance, `(2, 1)` permutes the first and second dimensions
#' of the input.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_permute <-
function(object, dims, ...)
{
    args <- capture_args(match.call(), list(dims = function(x)
    tuple(as.list(as.integer(x))), input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$Permute, object, args)
}


# <class 'keras.src.layers.activation.prelu.PReLU'>
#' Parametric Rectified Linear Unit
#'
#' @details
#' It follows:
#'
#' ```
#'     f(x) = alpha * x for x < 0
#'     f(x) = x for x >= 0
#' ```
#'
#' where `alpha` is a learned array with the same shape as x.
#'
#' Input shape:
#'     Arbitrary. Use the keyword argument `input_shape`
#'     (list of integers, does not include the samples axis)
#'     when using this layer as the first layer in a model.
#'
#' Output shape:
#'     Same shape as the input.
#'
#' @param alpha_initializer
#' Initializer function for the weights.
#'
#' @param alpha_regularizer
#' Regularizer for the weights.
#'
#' @param alpha_constraint
#' Constraint for the weights.
#'
#' @param shared_axes
#' The axes along which to share learnable
#' parameters for the activation function.
#' For example, if the incoming feature maps
#' are from a 2D convolution
#' with output shape `(batch, height, width, channels)`,
#' and you wish to share parameters across space
#' so that each filter only has one set of parameters,
#' set `shared_axes=[1, 2]`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_activation_parametric_relu <-
function(object, alpha_initializer = "zeros", alpha_regularizer = NULL,
    alpha_constraint = NULL, shared_axes = NULL, ...)
{
    args <- capture_args(match.call(), list(shared_axes = function(x)
    as.list(as.integer(x)), input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$PReLU, object, args)
}


# <class 'keras.src.layers.preprocessing.image_preprocessing.RandomBrightness'>
#' A preprocessing layer which randomly adjusts brightness during training
#'
#' @details
#' This layer will randomly increase/reduce the brightness for the input RGB
#' images. At inference time, the output will be identical to the input.
#' Call the layer with `training=TRUE` to adjust the brightness of the input.
#'
#' Note that different brightness adjustment factors
#' will be apply to each the images in the batch.
#'
#' For an overview and full list of preprocessing layers, see the preprocessing
#' [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).
#'
#' Inputs: 3D (HWC) or 4D (NHWC) tensor, with float or int dtype. Input pixel
#'     values can be of any range (e.g. `[0., 1.)` or `[0, 255]`)
#'
#' Output: 3D (HWC) or 4D (NHWC) tensor with brightness adjusted based on the
#'     `factor`. By default, the layer will output floats.
#'     The output value will be clipped to the range `[0, 255]`,
#'     the valid range of RGB colors, and
#'     rescaled based on the `value_range` if needed.
#'
#' Sample usage:
#'
#' ```python
#' random_bright = tf.keras.layers.RandomBrightness(factor=0.2)
#'
#' # An image with shape [2, 2, 3]
#' image = [[[1, 2, 3], [4 ,5 ,6]], [[7, 8, 9], [10, 11, 12]]]
#'
#' # Assume we randomly select the factor to be 0.1, then it will apply
#' # 0.1 * 255 to all the channel
#' output = random_bright(image, training=TRUE)
#'
#' # output will be int64 with 25.5 added to each channel and round down.
#' tf.Tensor([[[26.5, 27.5, 28.5]
#'             [29.5, 30.5, 31.5]]
#'            [[32.5, 33.5, 34.5]
#'             [35.5, 36.5, 37.5]]],
#'           shape=(2, 2, 3), dtype=int64)
#' ```
#'
#' @param factor
#' Float or a list of 2 floats between -1.0 and 1.0. The
#' factor is used to determine the lower bound and upper bound of the
#' brightness adjustment. A float value will be chosen randomly between
#' the limits. When -1.0 is chosen, the output image will be black, and
#' when 1.0 is chosen, the image will be fully white.
#' When only one float is provided, eg, 0.2,
#' then -0.2 will be used for lower bound and 0.2
#' will be used for upper bound.
#'
#' @param value_range
#' Optional list of 2 floats
#' for the lower and upper limit
#' of the values of the input data.
#' To make no change, use [0.0, 1.0], e.g., if the image input
#' has been scaled before this layer. Defaults to [0.0, 255.0].
#' The brightness adjustment will be scaled to this range, and the
#' output values will be clipped to this range.
#'
#' @param seed
#' optional integer, for fixed RNG behavior.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_random_brightness <-
function(object, factor, value_range = list(0L, 255L), seed = NULL,
    ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$RandomBrightness, object, args)
}


# <class 'keras.src.layers.preprocessing.image_preprocessing.RandomContrast'>
#' A preprocessing layer which randomly adjusts contrast during training
#'
#' @details
#' This layer will randomly adjust the contrast of an image or images
#' by a random factor. Contrast is adjusted independently
#' for each channel of each image during training.
#'
#' For each channel, this layer computes the mean of the image pixels in the
#' channel and then adjusts each component `x` of each pixel to
#' `(x - mean) * contrast_factor + mean`.
#'
#' Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and
#' in integer or floating point dtype.
#' By default, the layer will output floats.
#' The output value will be clipped to the range `[0, 255]`, the valid
#' range of RGB colors.
#'
#' For an overview and full list of preprocessing layers, see the preprocessing
#' [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).
#'
#' Input shape:
#'     3D (unbatched) or 4D (batched) tensor with shape:
#'     `(..., height, width, channels)`, in `"channels_last"` format.
#'
#' Output shape:
#'     3D (unbatched) or 4D (batched) tensor with shape:
#'     `(..., height, width, channels)`, in `"channels_last"` format.
#'
#' @param factor
#' a positive float represented as fraction of value, or a list of
#' size 2 representing lower and upper bound.
#' When represented as a single float, lower = upper.
#' The contrast factor will be randomly picked between
#' `[1.0 - lower, 1.0 + upper]`. For any pixel x in the channel,
#' the output will be `(x - mean) * factor + mean`
#' where `mean` is the mean value of the channel.
#'
#' @param seed
#' Integer. Used to create a random seed.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_random_contrast <-
function(object, factor, seed = NULL, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$RandomContrast, object, args)
}


# <class 'keras.src.layers.preprocessing.image_preprocessing.RandomCrop'>
#' A preprocessing layer which randomly crops images during training
#'
#' @details
#' During training, this layer will randomly choose a location to crop images
#' down to a target size. The layer will crop all the images in the same batch
#' to the same cropping location.
#'
#' At inference time, and during training if an input image is smaller than the
#' target size, the input will be resized and cropped so as to return the
#' largest possible window in the image that matches the target aspect ratio.
#' If you need to apply random cropping at inference time, set `training` to
#' TRUE when calling the layer.
#'
#' Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and
#' of integer or floating point dtype. By default, the layer will output
#' floats.
#'
#' For an overview and full list of preprocessing layers, see the preprocessing
#' [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).
#'
#' Input shape:
#'     3D (unbatched) or 4D (batched) tensor with shape:
#'     `(..., height, width, channels)`, in `"channels_last"` format.
#'
#' Output shape:
#'     3D (unbatched) or 4D (batched) tensor with shape:
#'     `(..., target_height, target_width, channels)`.
#'
#' @param height
#' Integer, the height of the output shape.
#'
#' @param width
#' Integer, the width of the output shape.
#'
#' @param seed
#' Integer. Used to create a random seed.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_random_crop <-
function(object, height, width, seed = NULL, ...)
{
    args <- capture_args(match.call(), list(height = as.integer,
        width = as.integer, input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$RandomCrop, object, args)
}


# <class 'keras.src.layers.preprocessing.image_preprocessing.RandomFlip'>
#' A preprocessing layer which randomly flips images during training
#'
#' @details
#' This layer will flip the images horizontally and or vertically based on the
#' `mode` attribute. During inference time, the output will be identical to
#' input. Call the layer with `training=TRUE` to flip the input.
#'
#' Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and
#' of integer or floating point dtype.
#' By default, the layer will output floats.
#'
#' For an overview and full list of preprocessing layers, see the preprocessing
#' [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).
#'
#' Input shape:
#'     3D (unbatched) or 4D (batched) tensor with shape:
#'     `(..., height, width, channels)`, in `"channels_last"` format.
#'
#' Output shape:
#'     3D (unbatched) or 4D (batched) tensor with shape:
#'     `(..., height, width, channels)`, in `"channels_last"` format.
#'
#' @param mode
#' String indicating which flip mode to use. Can be `"horizontal"`,
#' `"vertical"`, or `"horizontal_and_vertical"`. `"horizontal"` is a
#' left-right flip and `"vertical"` is a top-bottom flip. Defaults to
#' `"horizontal_and_vertical"`
#'
#' @param seed
#' Integer. Used to create a random seed.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_random_flip <-
function(object, mode = "horizontal_and_vertical", seed = NULL,
    ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$RandomFlip, object, args)
}


# <class 'keras.src.layers.preprocessing.image_preprocessing.RandomHeight'>
#' A preprocessing layer which randomly varies image height during training
#'
#' @details
#' This layer adjusts the height of a batch of images by a random factor.
#' The input should be a 3D (unbatched) or 4D (batched) tensor in the
#' `"channels_last"` image data format. Input pixel values can be of any range
#' (e.g. `[0., 1.)` or `[0, 255]`) and of integer or floating point dtype. By
#' default, the layer will output floats.
#'
#' By default, this layer is inactive during inference.
#'
#' For an overview and full list of preprocessing layers, see the preprocessing
#' [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).
#'
#' Input shape:
#'     3D (unbatched) or 4D (batched) tensor with shape:
#'     `(..., height, width, channels)`, in `"channels_last"` format.
#'
#' Output shape:
#'     3D (unbatched) or 4D (batched) tensor with shape:
#'     `(..., random_height, width, channels)`.
#'
#' @param factor
#' A positive float (fraction of original height),
#' or a list of size 2 representing lower and upper bound
#' for resizing vertically. When represented as a single float,
#' this value is used for both the upper and
#' lower bound. For instance, `factor=(0.2, 0.3)` results
#' in an output with
#' height changed by a random amount in the range `[20%, 30%]`.
#' `factor=(-0.2, 0.3)` results in an output with height
#' changed by a random amount in the range `[-20%, +30%]`.
#' `factor=0.2` results in an output with
#' height changed by a random amount in the range `[-20%, +20%]`.
#'
#' @param interpolation
#' String, the interpolation method.
#' Supports `"bilinear"`, `"nearest"`, `"bicubic"`, `"area"`,
#' `"lanczos3"`, `"lanczos5"`, `"gaussian"`, `"mitchellcubic"`.
#' Defaults to `"bilinear"`.
#'
#' @param seed
#' Integer. Used to create a random seed.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_random_height <-
function(object, factor, interpolation = "bilinear", seed = NULL,
    ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$RandomHeight, object, args)
}


# <class 'keras.src.layers.preprocessing.image_preprocessing.RandomRotation'>
#' A preprocessing layer which randomly rotates images during training
#'
#' @details
#' This layer will apply random rotations to each image, filling empty space
#' according to `fill_mode`.
#'
#' By default, random rotations are only applied during training.
#' At inference time, the layer does nothing. If you need to apply random
#' rotations at inference time, set `training` to TRUE when calling the layer.
#'
#' Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and
#' of integer or floating point dtype.
#' By default, the layer will output floats.
#'
#' For an overview and full list of preprocessing layers, see the preprocessing
#' [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).
#'
#' Input shape:
#'     3D (unbatched) or 4D (batched) tensor with shape:
#'     `(..., height, width, channels)`, in `"channels_last"` format
#'
#' Output shape:
#'     3D (unbatched) or 4D (batched) tensor with shape:
#'     `(..., height, width, channels)`, in `"channels_last"` format
#'
#' @param factor
#' a float represented as fraction of 2 Pi, or a list of size 2
#' representing lower and upper bound for rotating clockwise and
#' counter-clockwise. A positive values means rotating
#' counter clock-wise,
#' while a negative value means clock-wise.
#' When represented as a single
#' float, this value is used for both the upper and lower bound.
#' For instance, `factor=(-0.2, 0.3)`
#' results in an output rotation by a random
#' amount in the range `[-20% * 2pi, 30% * 2pi]`.
#' `factor=0.2` results in an
#' output rotating by a random amount
#' in the range `[-20% * 2pi, 20% * 2pi]`.
#'
#' @param fill_mode
#' Points outside the boundaries of the input are filled
#' according to the given mode
#' (one of `{"constant", "reflect", "wrap", "nearest"}`).
#' - *reflect*: `(d c b a | a b c d | d c b a)`
#'     The input is extended by reflecting about
#'     the edge of the last pixel.
#' - *constant*: `(k k k k | a b c d | k k k k)`
#'     The input is extended by
#'     filling all values beyond the edge with
#'     the same constant value k = 0.
#' - *wrap*: `(a b c d | a b c d | a b c d)` The input is extended by
#'     wrapping around to the opposite edge.
#' - *nearest*: `(a a a a | a b c d | d d d d)`
#'     The input is extended by the nearest pixel.
#'
#' @param interpolation
#' Interpolation mode. Supported values: `"nearest"`,
#' `"bilinear"`.
#'
#' @param seed
#' Integer. Used to create a random seed.
#'
#' @param fill_value
#' a float represents the value to be filled outside
#' the boundaries when `fill_mode="constant"`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_random_rotation <-
function(object, factor, fill_mode = "reflect", interpolation = "bilinear",
    seed = NULL, fill_value = 0, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$RandomRotation, object, args)
}


# <class 'keras.src.layers.preprocessing.image_preprocessing.RandomTranslation'>
#' A preprocessing layer which randomly translates images during training
#'
#' @details
#' This layer will apply random translations to each image during training,
#' filling empty space according to `fill_mode`.
#'
#' Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and
#' of integer or floating point dtype. By default, the layer will output
#' floats.
#'
#' For an overview and full list of preprocessing layers, see the preprocessing
#' [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).
#'
#' Input shape:
#'     3D (unbatched) or 4D (batched) tensor with shape:
#'     `(..., height, width, channels)`,  in `"channels_last"` format.
#'
#' Output shape:
#'     3D (unbatched) or 4D (batched) tensor with shape:
#'     `(..., height, width, channels)`,  in `"channels_last"` format.
#'
#' @param height_factor
#' a float represented as fraction of value, or a list of
#' size 2 representing lower and upper bound for shifting vertically. A
#' negative value means shifting image up, while a positive value means
#' shifting image down. When represented as a single positive float, this
#' value is used for both the upper and lower bound. For instance,
#' `height_factor=(-0.2, 0.3)` results in an output shifted by a random
#' amount in the range `[-20%, +30%]`.  `height_factor=0.2` results in an
#' output height shifted by a random amount in the range `[-20%, +20%]`.
#'
#' @param width_factor
#' a float represented as fraction of value, or a list of size
#' 2 representing lower and upper bound for shifting horizontally. A
#' negative value means shifting image left, while a positive value means
#' shifting image right. When represented as a single positive float,
#' this value is used for both the upper and lower bound. For instance,
#' `width_factor=(-0.2, 0.3)` results in an output shifted left by 20%,
#' and shifted right by 30%. `width_factor=0.2` results
#' in an output height shifted left or right by 20%.
#'
#' @param fill_mode
#' Points outside the boundaries of the input are filled according
#' to the given mode
#' (one of `{"constant", "reflect", "wrap", "nearest"}`).
#' - *reflect*: `(d c b a | a b c d | d c b a)` The input is extended by
#'     reflecting about the edge of the last pixel.
#' - *constant*: `(k k k k | a b c d | k k k k)` The input is extended by
#'     filling all values beyond the edge with the same constant value
#'     k = 0.
#' - *wrap*: `(a b c d | a b c d | a b c d)` The input is extended by
#'     wrapping around to the opposite edge.
#' - *nearest*: `(a a a a | a b c d | d d d d)` The input is extended by
#'     the nearest pixel.
#'
#' @param interpolation
#' Interpolation mode. Supported values: `"nearest"`,
#' `"bilinear"`.
#'
#' @param seed
#' Integer. Used to create a random seed.
#'
#' @param fill_value
#' a float represents the value to be filled outside the
#' boundaries when `fill_mode="constant"`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_random_translation <-
function(object, height_factor, width_factor, fill_mode = "reflect",
    interpolation = "bilinear", seed = NULL, fill_value = 0,
    ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$RandomTranslation, object, args)
}


# <class 'keras.src.layers.preprocessing.image_preprocessing.RandomWidth'>
#' A preprocessing layer which randomly varies image width during training
#'
#' @details
#' This layer will randomly adjusts the width of a batch of images of a
#' batch of images by a random factor. The input should be a 3D (unbatched) or
#' 4D (batched) tensor in the `"channels_last"` image data format. Input pixel
#' values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and of integer or
#' floating point dtype. By default, the layer will output floats.
#'
#' By default, this layer is inactive during inference.
#'
#' For an overview and full list of preprocessing layers, see the preprocessing
#' [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).
#'
#' Input shape:
#'     3D (unbatched) or 4D (batched) tensor with shape:
#'     `(..., height, width, channels)`, in `"channels_last"` format.
#'
#' Output shape:
#'     3D (unbatched) or 4D (batched) tensor with shape:
#'     `(..., height, random_width, channels)`.
#'
#' @param factor
#' A positive float (fraction of original width),
#' or a list of size 2 representing lower and upper bound
#' for resizing horizontally. When represented as a single float,
#' this value is used for both the upper and
#' lower bound. For instance, `factor=(0.2, 0.3)`
#' results in an output with
#' width changed by a random amount in the range `[20%, 30%]`.
#' `factor=(-0.2, 0.3)` results in an output with width changed
#' by a random amount in the range `[-20%, +30%]`.
#' `factor=0.2` results in an output with width changed
#' by a random amount in the range `[-20%, +20%]`.
#'
#' @param interpolation
#' String, the interpolation method.
#' Supports `"bilinear"`, `"nearest"`, `"bicubic"`, `"area"`,
#' `"lanczos3"`, `"lanczos5"`, `"gaussian"`, `"mitchellcubic"`.
#' Defaults to `bilinear`.
#'
#' @param seed
#' Integer. Used to create a random seed.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_random_width <-
function(object, factor, interpolation = "bilinear", seed = NULL,
    ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$RandomWidth, object, args)
}


# <class 'keras.src.layers.preprocessing.image_preprocessing.RandomZoom'>
#' A preprocessing layer which randomly zooms images during training
#'
#' @details
#' This layer will randomly zoom in or out on each axis of an image
#' independently, filling empty space according to `fill_mode`.
#'
#' Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and
#' of integer or floating point dtype.
#' By default, the layer will output floats.
#'
#' For an overview and full list of preprocessing layers, see the preprocessing
#' [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).
#'
#' Example:
#'
#' ```python
#' >>> input_img = np.random.random((32, 224, 224, 3))
#' >>> layer = tf.keras.layers.RandomZoom(.5, .2)
#' >>> out_img = layer(input_img)
#' >>> out_img.shape
#' TensorShape([32, 224, 224, 3])
#' ```
#'
#' Input shape:
#'     3D (unbatched) or 4D (batched) tensor with shape:
#'     `(..., height, width, channels)`, in `"channels_last"` format.
#'
#' Output shape:
#'     3D (unbatched) or 4D (batched) tensor with shape:
#'     `(..., height, width, channels)`, in `"channels_last"` format.
#'
#' @param height_factor
#' a float represented as fraction of value,
#' or a list of size 2 representing lower and upper bound
#' for zooming vertically. When represented as a single float,
#' this value is used for both the upper and
#' lower bound. A positive value means zooming out,
#' while a negative value
#' means zooming in. For instance, `height_factor=(0.2, 0.3)`
#' result in an output zoomed out by a random amount
#' in the range `[+20%, +30%]`.
#' `height_factor=(-0.3, -0.2)` result in an output zoomed
#' in by a random amount in the range `[+20%, +30%]`.
#'
#' @param width_factor
#' a float represented as fraction of value,
#' or a list of size 2 representing lower and upper bound
#' for zooming horizontally. When
#' represented as a single float, this value is used
#' for both the upper and
#' lower bound. For instance, `width_factor=(0.2, 0.3)`
#' result in an output
#' zooming out between 20% to 30%.
#' `width_factor=(-0.3, -0.2)` result in an
#' output zooming in between 20% to 30%. `NULL` means
#' i.e., zooming vertical and horizontal directions
#' by preserving the aspect ratio. Defaults to `NULL`.
#'
#' @param fill_mode
#' Points outside the boundaries of the input are
#' filled according to the given mode
#' (one of `{"constant", "reflect", "wrap", "nearest"}`).
#' - *reflect*: `(d c b a | a b c d | d c b a)`
#'     The input is extended by reflecting about
#'     the edge of the last pixel.
#' - *constant*: `(k k k k | a b c d | k k k k)`
#'     The input is extended by filling all values beyond
#'     the edge with the same constant value k = 0.
#' - *wrap*: `(a b c d | a b c d | a b c d)` The input is extended by
#'     wrapping around to the opposite edge.
#' - *nearest*: `(a a a a | a b c d | d d d d)`
#'     The input is extended by the nearest pixel.
#'
#' @param interpolation
#' Interpolation mode. Supported values: `"nearest"`,
#' `"bilinear"`.
#'
#' @param seed
#' Integer. Used to create a random seed.
#'
#' @param fill_value
#' a float represents the value to be filled outside
#' the boundaries when `fill_mode="constant"`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_random_zoom <-
function(object, height_factor, width_factor = NULL, fill_mode = "reflect",
    interpolation = "bilinear", seed = NULL, fill_value = 0,
    ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$RandomZoom, object, args)
}


# <class 'keras.src.layers.activation.relu.ReLU'>
#' Rectified Linear Unit activation function
#'
#' @details
#' With default values, it returns element-wise `max(x, 0)`.
#'
#' Otherwise, it follows:
#'
#' ```
#'     f(x) = max_value if x >= max_value
#'     f(x) = x if threshold <= x < max_value
#'     f(x) = negative_slope * (x - threshold) otherwise
#' ```
#'
#' Usage:
#'
#' ```python
#' >>> layer = tf.keras.layers.ReLU()
#' >>> output = layer([-3.0, -1.0, 0.0, 2.0])
#' >>> list(output.numpy())
#' [0.0, 0.0, 0.0, 2.0]
#' >>> layer = tf.keras.layers.ReLU(max_value=1.0)
#' >>> output = layer([-3.0, -1.0, 0.0, 2.0])
#' >>> list(output.numpy())
#' [0.0, 0.0, 0.0, 1.0]
#' >>> layer = tf.keras.layers.ReLU(negative_slope=1.0)
#' >>> output = layer([-3.0, -1.0, 0.0, 2.0])
#' >>> list(output.numpy())
#' [-3.0, -1.0, 0.0, 2.0]
#' >>> layer = tf.keras.layers.ReLU(threshold=1.5)
#' >>> output = layer([-3.0, -1.0, 1.0, 2.0])
#' >>> list(output.numpy())
#' [0.0, 0.0, 0.0, 2.0]
#' ```
#'
#' Input shape:
#'     Arbitrary. Use the keyword argument `input_shape`
#'     (list of integers, does not include the batch axis)
#'     when using this layer as the first layer in a model.
#'
#' Output shape:
#'     Same shape as the input.
#'
#' @param max_value
#' Float >= 0. Maximum activation value. NULL means unlimited.
#' Defaults to `NULL`.
#'
#' @param negative_slope
#' Float >= 0. Negative slope coefficient.
#' Defaults to `0.`.
#'
#' @param threshold
#' Float >= 0. Threshold value for thresholded activation.
#' Defaults to `0.`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_activation_relu <-
function(object, max_value = NULL, negative_slope = 0, threshold = 0,
    ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$ReLU, object, args)
}


# <class 'keras.src.layers.reshaping.repeat_vector.RepeatVector'>
#' Repeats the input n times
#'
#' @details
#'
#' Example:
#'
#' ```python
#' model = Sequential()
#' model.add(Dense(32, input_dim=32))
#' # now: model.output_shape == (NULL, 32)
#' # note: `NULL` is the batch dimension
#'
#' model.add(RepeatVector(3))
#' # now: model.output_shape == (NULL, 3, 32)
#' ```
#'
#' Input shape: 2D tensor of shape `(num_samples, features)`.
#' Output shape: 3D tensor of shape `(num_samples, n, features)`.
#'
#' @param n
#' Integer, repetition factor.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_repeat_vector <-
function(object, n, ...)
{
    args <- capture_args(match.call(), list(n = as.integer, input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$RepeatVector, object, args)
}


# <class 'keras.src.layers.preprocessing.image_preprocessing.Rescaling'>
#' A preprocessing layer which rescales input values to a new range
#'
#' @details
#' This layer rescales every value of an input (often an image) by multiplying
#' by `scale` and adding `offset`.
#'
#' For instance:
#'
#' 1. To rescale an input in the `[0, 255]` range
#' to be in the `[0, 1]` range, you would pass `scale=1./255`.
#'
#' 2. To rescale an input in the `[0, 255]` range to be in the `[-1, 1]` range,
#' you would pass `scale=1./127.5, offset=-1`.
#'
#' The rescaling is applied both during training and inference. Inputs can be
#' of integer or floating point dtype, and by default the layer will output
#' floats.
#'
#' For an overview and full list of preprocessing layers, see the preprocessing
#' [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).
#'
#' Input shape:
#'     Arbitrary.
#'
#' Output shape:
#'     Same as input.
#'
#' @param scale
#' Float, the scale to apply to the inputs.
#'
#' @param offset
#' Float, the offset to apply to the inputs.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_rescaling <-
function(object, scale, offset = 0, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$Rescaling, object, args)
}


# <class 'keras.src.layers.reshaping.reshape.Reshape'>
#' Layer that reshapes inputs into the given shape
#'
#' @details
#' Input shape:
#'   Arbitrary, although all dimensions in the input shape must be known/fixed.
#'   Use the keyword argument `input_shape` (list of integers, does not
#'   include the samples/batch size axis) when using this layer as the first
#'   layer in a model.
#'
#' Output shape:
#'   `(batch_size,) + target_shape`
#'
#' Example:
#'
#' ```python
#' >>> # as first layer in a Sequential model
#' >>> model = tf.keras.Sequential()
#' >>> model.add(tf.keras.layers.Reshape((3, 4), input_shape=(12,)))
#' >>> # model.output_shape == (NULL, 3, 4), `NULL` is the batch size.
#' >>> model.output_shape
#' (NULL, 3, 4)
#' ```
#'
#' ```python
#' >>> # as intermediate layer in a Sequential model
#' >>> model.add(tf.keras.layers.Reshape((6, 2)))
#' >>> model.output_shape
#' (NULL, 6, 2)
#' ```
#'
#' ```python
#' >>> # also supports shape inference using `-1` as dimension
#' >>> model.add(tf.keras.layers.Reshape((-1, 2, 2)))
#' >>> model.output_shape
#' (NULL, 3, 2, 2)
#' ```
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_reshape <-
function(object, target_shape, ...)
{
    args <- capture_args(match.call(), list(target_shape = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$Reshape, object, args)
}


# <class 'keras.src.layers.preprocessing.image_preprocessing.Resizing'>
#' A preprocessing layer which resizes images
#'
#' @details
#' This layer resizes an image input to a target height and width. The input
#' should be a 4D (batched) or 3D (unbatched) tensor in `"channels_last"`
#' format. Input pixel values can be of any range
#' (e.g. `[0., 1.)` or `[0, 255]`) and of integer or floating point dtype.
#' By default, the layer will output floats.
#'
#' This layer can be called on tf.RaggedTensor batches of input images of
#' distinct sizes, and will resize the outputs to dense tensors of uniform
#' size.
#'
#' For an overview and full list of preprocessing layers, see the preprocessing
#' [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).
#'
#' @param height
#' Integer, the height of the output shape.
#'
#' @param width
#' Integer, the width of the output shape.
#'
#' @param interpolation
#' String, the interpolation method.
#' Supports `"bilinear"`, `"nearest"`, `"bicubic"`, `"area"`,
#' `"lanczos3"`, `"lanczos5"`, `"gaussian"`, `"mitchellcubic"`.
#' Defaults to `"bilinear"`.
#'
#' @param crop_to_aspect_ratio
#' If TRUE, resize the images without aspect
#' ratio distortion. When the original aspect ratio differs
#' from the target aspect ratio, the output image will be
#' cropped so as to return the
#' largest possible window in the image (of size `(height, width)`)
#' that matches the target aspect ratio. By default
#' (`crop_to_aspect_ratio=FALSE`), aspect ratio may not be preserved.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_resizing <-
function(object, height, width, interpolation = "bilinear",
    crop_to_aspect_ratio = FALSE, ...)
{
    args <- capture_args(match.call(), list(height = as.integer,
        width = as.integer, input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$Resizing, object, args)
}


# <class 'keras.src.layers.rnn.base_rnn.RNN'>
#' Base class for recurrent layers
#'
#' @details
#' See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)
#' for details about the usage of RNN API.
#'
#' Call arguments:
#'   inputs: Input tensor.
#'   mask: Binary tensor of shape `[batch_size, timesteps]` indicating whether
#'     a given timestep should be masked. An individual `TRUE` entry indicates
#'     that the corresponding timestep should be utilized, while a `FALSE`
#'     entry indicates that the corresponding timestep should be ignored.
#'   training: Python boolean indicating whether the layer should behave in
#'     training mode or in inference mode. This argument is passed to the cell
#'     when calling it. This is for use with cells that use dropout.
#'   initial_state: List of initial state tensors to be passed to the first
#'     call of the cell.
#'   constants: List of constant tensors to be passed to the cell at each
#'     timestep.
#'
#' Input shape:
#'   N-D tensor with shape `[batch_size, timesteps, ...]` or
#'   `[timesteps, batch_size, ...]` when time_major is TRUE.
#'
#' Output shape:
#'   - If `return_state`: a list of tensors. The first tensor is
#'     the output. The remaining tensors are the last states,
#'     each with shape `[batch_size, state_size]`, where `state_size` could
#'     be a high dimension tensor shape.
#'   - If `return_sequences`: N-D tensor with shape
#'     `[batch_size, timesteps, output_size]`, where `output_size` could
#'     be a high dimension tensor shape, or
#'     `[timesteps, batch_size, output_size]` when `time_major` is TRUE.
#'   - Else, N-D tensor with shape `[batch_size, output_size]`, where
#'     `output_size` could be a high dimension tensor shape.
#'
#' Masking:
#'   This layer supports masking for input data with a variable number
#'   of timesteps. To introduce masks to your data,
#'   use an [tf.keras.layers.Embedding] layer with the `mask_zero` parameter
#'   set to `TRUE`.
#'
#' Note on using statefulness in RNNs:
#'   You can set RNN layers to be 'stateful', which means that the states
#'   computed for the samples in one batch will be reused as initial states
#'   for the samples in the next batch. This assumes a one-to-one mapping
#'   between samples in different successive batches.
#'
#'   To enable statefulness:
#'     - Specify `stateful=TRUE` in the layer constructor.
#'     - Specify a fixed batch size for your model, by passing
#'       If sequential model:
#'         `batch_input_shape=(...)` to the first layer in your model.
#'       Else for functional model with 1 or more Input layers:
#'         `batch_shape=(...)` to all the first layers in your model.
#'       This is the expected shape of your inputs
#'       *including the batch size*.
#'       It should be a list of integers, e.g. `(32, 10, 100)`.
#'     - Specify `shuffle=FALSE` when calling `fit()`.
#'
#'   To reset the states of your model, call `.reset_states()` on either
#'   a specific layer, or on your entire model.
#'
#' Note on specifying the initial state of RNNs:
#'   You can specify the initial state of RNN layers symbolically by
#'   calling them with the keyword argument `initial_state`. The value of
#'   `initial_state` should be a tensor or list of tensors representing
#'   the initial state of the RNN layer.
#'
#'   You can specify the initial state of RNN layers numerically by
#'   calling `reset_states` with the keyword argument `states`. The value of
#'   `states` should be a numpy array or list of numpy arrays representing
#'   the initial state of the RNN layer.
#'
#' Note on passing external constants to RNNs:
#'   You can pass "external" constants to the cell using the `constants`
#'   keyword argument of `RNN.__call__` (as well as `RNN.call`) method. This
#'   requires that the `cell.call` method accepts the same keyword argument
#'   `constants`. Such constants can be used to condition the cell
#'   transformation on additional static inputs (not changing over time),
#'   a.k.a. an attention mechanism.
#'
#' ```python
#' from keras.src.layers import RNN
#' from keras.src import backend
#'
#' # First, let's define a RNN Cell, as a layer subclass.
#' class MinimalRNNCell(keras.layers.Layer):
#'
#'     def __init__(self, units, **kwargs):
#'         self.units = units
#'         self.state_size = units
#'         super(MinimalRNNCell, self).__init__(**kwargs)
#'
#'     def build(self, input_shape):
#'         self.kernel = self.add_weight(shape=(input_shape[-1], self.units),
#'                                       initializer='uniform',
#'                                       name='kernel')
#'         self.recurrent_kernel = self.add_weight(
#'             shape=(self.units, self.units),
#'             initializer='uniform',
#'             name='recurrent_kernel')
#'         self.built = TRUE
#'
#'     def call(self, inputs, states):
#'         prev_output = states[0]
#'         h = backend.dot(inputs, self.kernel)
#'         output = h + backend.dot(prev_output, self.recurrent_kernel)
#'         return output, [output]
#'
#' # Let's use this cell in a RNN layer:
#'
#' cell = MinimalRNNCell(32)
#' x = keras.Input((NULL, 5))
#' layer = RNN(cell)
#' y = layer(x)
#'
#' # Here's how to use the cell to build a stacked RNN:
#'
#' cells = [MinimalRNNCell(32), MinimalRNNCell(64)]
#' x = keras.Input((NULL, 5))
#' layer = RNN(cells)
#' y = layer(x)
#' ```
#'
#' @param cell
#' A RNN cell instance or a list of RNN cell instances.
#' A RNN cell is a class that has:
#' - A `call(input_at_t, states_at_t)` method, returning
#'   `(output_at_t, states_at_t_plus_1)`. The call method of the
#'   cell can also take the optional argument `constants`, see
#'   section "Note on passing external constants" below.
#' - A `state_size` attribute. This can be a single integer
#'   (single state) in which case it is the size of the recurrent
#'   state. This can also be a list of integers (one size per state).
#'   The `state_size` can also be TensorShape or list of
#'   TensorShape, to represent high dimension state.
#' - A `output_size` attribute. This can be a single integer or a
#'   TensorShape, which represent the shape of the output. For backward
#'   compatible reason, if this attribute is not available for the
#'   cell, the value will be inferred by the first element of the
#'   `state_size`.
#' - A `get_initial_state(inputs=NULL, batch_size=NULL, dtype=NULL)`
#'   method that creates a tensor meant to be fed to `call()` as the
#'   initial state, if the user didn't specify any initial state via other
#'   means. The returned initial state should have a shape of
#'   [batch_size, cell.state_size]. The cell might choose to create a
#'   tensor full of zeros, or full of other values based on the cell's
#'   implementation.
#'   `inputs` is the input tensor to the RNN layer, which should
#'   contain the batch size as its shape[0], and also dtype. Note that
#'   the shape[0] might be `NULL` during the graph construction. Either
#'   the `inputs` or the pair of `batch_size` and `dtype` are provided.
#'   `batch_size` is a scalar tensor that represents the batch size
#'   of the inputs. `dtype` is `tf.DType` that represents the dtype of
#'   the inputs.
#'   For backward compatibility, if this method is not implemented
#'   by the cell, the RNN layer will create a zero filled tensor with the
#'   size of [batch_size, cell.state_size].
#' In the case that `cell` is a list of RNN cell instances, the cells
#' will be stacked on top of each other in the RNN, resulting in an
#' efficient stacked RNN.
#'
#' @param return_sequences
#' Boolean (default `FALSE`). Whether to return the last
#' output in the output sequence, or the full sequence.
#'
#' @param return_state
#' Boolean (default `FALSE`). Whether to return the last state
#' in addition to the output.
#'
#' @param go_backwards
#' Boolean (default `FALSE`).
#' If TRUE, process the input sequence backwards and return the
#' reversed sequence.
#'
#' @param stateful
#' Boolean (default `FALSE`). If TRUE, the last state
#' for each sample at index i in a batch will be used as initial
#' state for the sample of index i in the following batch.
#'
#' @param unroll
#' Boolean (default `FALSE`).
#' If TRUE, the network will be unrolled, else a symbolic loop will be
#' used. Unrolling can speed-up a RNN, although it tends to be more
#' memory-intensive. Unrolling is only suitable for short sequences.
#'
#' @param time_major
#' The shape format of the `inputs` and `outputs` tensors.
#' If TRUE, the inputs and outputs will be in shape
#' `(timesteps, batch, ...)`, whereas in the FALSE case, it will be
#' `(batch, timesteps, ...)`. Using `time_major = TRUE` is a bit more
#' efficient because it avoids transposes at the beginning and end of the
#' RNN calculation. However, most TensorFlow data is batch-major, so by
#' default this function accepts input and emits output in batch-major
#' form.
#'
#' @param zero_output_for_mask
#' Boolean (default `FALSE`).
#' Whether the output should use zeros for the masked timesteps. Note that
#' this field is only used when `return_sequences` is TRUE and mask is
#' provided. It can useful if you want to reuse the raw output sequence of
#' the RNN without interference from the masked timesteps, eg, merging
#' bidirectional RNNs.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_rnn <-
function(object, cell, return_sequences = FALSE, return_state = FALSE,
    go_backwards = FALSE, stateful = FALSE, unroll = FALSE, time_major = FALSE,
    ...)
{
    args <- capture_args(match.call(), list(cell = as_nullable_integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$RNN, object, args)
}


# <class 'keras.src.layers.convolutional.separable_conv1d.SeparableConv1D'>
#' Depthwise separable 1D convolution
#'
#' @details
#' This layer performs a depthwise convolution that acts separately on
#' channels, followed by a pointwise convolution that mixes channels.
#' If `use_bias` is TRUE and a bias initializer is provided,
#' it adds a bias vector to the output.
#' It then optionally applies an activation function to produce the final
#' output.
#'
#' Input shape:
#'   3D tensor with shape:
#'   `(batch_size, channels, steps)` if data_format='channels_first'
#'   or 3D tensor with shape:
#'   `(batch_size, steps, channels)` if data_format='channels_last'.
#'
#' Output shape:
#'   3D tensor with shape:
#'   `(batch_size, filters, new_steps)` if data_format='channels_first'
#'   or 3D tensor with shape:
#'   `(batch_size,  new_steps, filters)` if data_format='channels_last'.
#'   `new_steps` value might have changed due to padding or strides.
#'
#'   A tensor of rank 3 representing
#'
#' @param filters
#' Integer, the dimensionality of the output space (i.e. the number
#' of filters in the convolution).
#'
#' @param kernel_size
#' A single integer specifying the spatial
#' dimensions of the filters.
#'
#' @param strides
#' A single integer specifying the strides
#' of the convolution.
#' Specifying any `stride` value != 1 is incompatible with specifying
#' any `dilation_rate` value != 1.
#'
#' @param padding
#' One of `"valid"`, `"same"`, or `"causal"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding with zeros
#' evenly to the left/right or up/down of the input such that output has
#' the same height/width dimension as the input. `"causal"` results in
#' causal (dilated) convolutions, e.g. `output[t]` does not depend on
#' `input[t+1:]`.
#'
#' @param data_format
#' A string, one of `channels_last` (default) or
#' `channels_first`.  The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch_size, length, channels)` while `channels_first` corresponds to
#' inputs with shape `(batch_size, channels, length)`.
#'
#' @param dilation_rate
#' A single integer, specifying
#' the dilation rate to use for dilated convolution.
#'
#' @param depth_multiplier
#' The number of depthwise convolution output channels for
#' each input channel. The total number of depthwise convolution output
#' channels will be equal to `num_filters_in * depth_multiplier`.
#'
#' @param activation
#' Activation function to use.
#' If you don't specify anything, no activation is applied
#' (see `keras.activations`).
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias.
#'
#' @param depthwise_initializer
#' An initializer for the depthwise convolution kernel
#' (see `keras.initializers`). If NULL, then the default initializer
#' ('glorot_uniform') will be used.
#'
#' @param pointwise_initializer
#' An initializer for the pointwise convolution kernel
#' (see `keras.initializers`). If NULL, then the default initializer
#' ('glorot_uniform') will be used.
#'
#' @param bias_initializer
#' An initializer for the bias vector. If NULL, the default
#' initializer ('zeros') will be used (see `keras.initializers`).
#'
#' @param depthwise_regularizer
#' Optional regularizer for the depthwise
#' convolution kernel (see `keras.regularizers`).
#'
#' @param pointwise_regularizer
#' Optional regularizer for the pointwise
#' convolution kernel (see `keras.regularizers`).
#'
#' @param bias_regularizer
#' Optional regularizer for the bias vector
#' (see `keras.regularizers`).
#'
#' @param activity_regularizer
#' Optional regularizer function for the output
#' (see `keras.regularizers`).
#'
#' @param depthwise_constraint
#' Optional projection function to be applied to the
#' depthwise kernel after being updated by an `Optimizer` (e.g. used for
#' norm constraints or value constraints for layer weights). The function
#' must take as input the unprojected variable and must return the
#' projected variable (which must have the same shape). Constraints are
#' not safe to use when doing asynchronous distributed training
#' (see `keras.constraints`).
#'
#' @param pointwise_constraint
#' Optional projection function to be applied to the
#' pointwise kernel after being updated by an `Optimizer`
#' (see `keras.constraints`).
#'
#' @param bias_constraint
#' Optional projection function to be applied to the
#' bias after being updated by an `Optimizer`
#' (see `keras.constraints`).
#'
#' @param trainable
#' Boolean, if `TRUE` the weights of this layer will be marked as
#' trainable (and listed in `layer.trainable_weights`).
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_separable_conv_1d <-
function(object, filters, kernel_size, strides = 1L, padding = "valid",
    data_format = NULL, dilation_rate = 1L, depth_multiplier = 1L,
    activation = NULL, use_bias = TRUE, depthwise_initializer = "glorot_uniform",
    pointwise_initializer = "glorot_uniform", bias_initializer = "zeros",
    depthwise_regularizer = NULL, pointwise_regularizer = NULL,
    bias_regularizer = NULL, activity_regularizer = NULL, depthwise_constraint = NULL,
    pointwise_constraint = NULL, bias_constraint = NULL, ...)
{
    args <- capture_args(match.call(), list(filters = as.integer,
        kernel_size = as.integer, strides = as.integer, dilation_rate = as.integer,
        depth_multiplier = as.integer, input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$SeparableConv1D, object, args)
}


# <class 'keras.src.layers.convolutional.separable_conv2d.SeparableConv2D'>
#' Depthwise separable 2D convolution
#'
#' @details
#' Separable convolutions consist of first performing
#' a depthwise spatial convolution
#' (which acts on each input channel separately)
#' followed by a pointwise convolution which mixes the resulting
#' output channels. The `depth_multiplier` argument controls how many
#' output channels are generated per input channel in the depthwise step.
#'
#' Intuitively, separable convolutions can be understood as
#' a way to factorize a convolution kernel into two smaller kernels,
#' or as an extreme version of an Inception block.
#'
#' Input shape:
#'   4D tensor with shape:
#'   `(batch_size, channels, rows, cols)` if data_format='channels_first'
#'   or 4D tensor with shape:
#'   `(batch_size, rows, cols, channels)` if data_format='channels_last'.
#'
#' Output shape:
#'   4D tensor with shape:
#'   `(batch_size, filters, new_rows, new_cols)` if
#'   data_format='channels_first'
#'   or 4D tensor with shape:
#'   `(batch_size, new_rows, new_cols, filters)` if
#'   data_format='channels_last'.  `rows` and `cols` values might have changed
#'   due to padding.
#'
#'   A tensor of rank 4 representing
#'
#' @param filters
#' Integer, the dimensionality of the output space
#' (i.e. the number of output filters in the convolution).
#'
#' @param kernel_size
#' An integer or list of 2 integers, specifying the
#' height and width of the 2D convolution window.
#' Can be a single integer to specify the same value for
#' all spatial dimensions.
#'
#' @param strides
#' An integer or list of 2 integers,
#' specifying the strides of the convolution along the height and width.
#' Can be a single integer to specify the same value for
#' all spatial dimensions. Current implementation only supports equal
#' length strides in the row and column dimensions.
#' Specifying any stride value != 1 is incompatible with specifying
#' any `dilation_rate` value != 1.
#'
#' @param padding
#' one of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding with zeros
#' evenly to the left/right or up/down of the input such that output has
#' the same height/width dimension as the input.
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch_size, height, width, channels)` while `channels_first`
#' corresponds to inputs with shape
#' `(batch_size, channels, height, width)`.
#' When unspecified, uses `image_data_format` value found in your Keras
#' config file at `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param dilation_rate
#' An integer or list of 2 integers, specifying
#' the dilation rate to use for dilated convolution.
#'
#' @param depth_multiplier
#' The number of depthwise convolution output channels
#' for each input channel.
#' The total number of depthwise convolution output
#' channels will be equal to `filters_in * depth_multiplier`.
#'
#' @param activation
#' Activation function to use.
#' If you don't specify anything, no activation is applied
#' (see `keras.activations`).
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias vector.
#'
#' @param depthwise_initializer
#' An initializer for the depthwise convolution kernel
#' (see `keras.initializers`). If NULL, then the default initializer
#' ('glorot_uniform') will be used.
#'
#' @param pointwise_initializer
#' An initializer for the pointwise convolution kernel
#' (see `keras.initializers`). If NULL, then the default initializer
#' ('glorot_uniform') will be used.
#'
#' @param bias_initializer
#' An initializer for the bias vector. If NULL, the default
#' initializer ('zeros') will be used (see `keras.initializers`).
#'
#' @param depthwise_regularizer
#' Regularizer function applied to
#' the depthwise kernel matrix (see `keras.regularizers`).
#'
#' @param pointwise_regularizer
#' Regularizer function applied to
#' the pointwise kernel matrix (see `keras.regularizers`).
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector
#' (see `keras.regularizers`).
#'
#' @param activity_regularizer
#' Regularizer function applied to
#' the output of the layer (its "activation")
#' (see `keras.regularizers`).
#'
#' @param depthwise_constraint
#' Constraint function applied to
#' the depthwise kernel matrix
#' (see `keras.constraints`).
#'
#' @param pointwise_constraint
#' Constraint function applied to
#' the pointwise kernel matrix
#' (see `keras.constraints`).
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector
#' (see `keras.constraints`).
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_separable_conv_2d <-
function(object, filters, kernel_size, strides = list(1L, 1L),
    padding = "valid", data_format = NULL, dilation_rate = list(
        1L, 1L), depth_multiplier = 1L, activation = NULL, use_bias = TRUE,
    depthwise_initializer = "glorot_uniform", pointwise_initializer = "glorot_uniform",
    bias_initializer = "zeros", depthwise_regularizer = NULL,
    pointwise_regularizer = NULL, bias_regularizer = NULL, activity_regularizer = NULL,
    depthwise_constraint = NULL, pointwise_constraint = NULL,
    bias_constraint = NULL, ...)
{
    args <- capture_args(match.call(), list(filters = as.integer,
        kernel_size = as.integer, depth_multiplier = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$SeparableConv2D, object, args)
}


# <class 'keras.src.layers.convolutional.separable_conv1d.SeparableConv1D'>
#' Depthwise separable 1D convolution
#'
#' @details
#' This layer performs a depthwise convolution that acts separately on
#' channels, followed by a pointwise convolution that mixes channels.
#' If `use_bias` is TRUE and a bias initializer is provided,
#' it adds a bias vector to the output.
#' It then optionally applies an activation function to produce the final
#' output.
#'
#' Input shape:
#'   3D tensor with shape:
#'   `(batch_size, channels, steps)` if data_format='channels_first'
#'   or 3D tensor with shape:
#'   `(batch_size, steps, channels)` if data_format='channels_last'.
#'
#' Output shape:
#'   3D tensor with shape:
#'   `(batch_size, filters, new_steps)` if data_format='channels_first'
#'   or 3D tensor with shape:
#'   `(batch_size,  new_steps, filters)` if data_format='channels_last'.
#'   `new_steps` value might have changed due to padding or strides.
#'
#'   A tensor of rank 3 representing
#'
#' @param filters
#' Integer, the dimensionality of the output space (i.e. the number
#' of filters in the convolution).
#'
#' @param kernel_size
#' A single integer specifying the spatial
#' dimensions of the filters.
#'
#' @param strides
#' A single integer specifying the strides
#' of the convolution.
#' Specifying any `stride` value != 1 is incompatible with specifying
#' any `dilation_rate` value != 1.
#'
#' @param padding
#' One of `"valid"`, `"same"`, or `"causal"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding with zeros
#' evenly to the left/right or up/down of the input such that output has
#' the same height/width dimension as the input. `"causal"` results in
#' causal (dilated) convolutions, e.g. `output[t]` does not depend on
#' `input[t+1:]`.
#'
#' @param data_format
#' A string, one of `channels_last` (default) or
#' `channels_first`.  The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch_size, length, channels)` while `channels_first` corresponds to
#' inputs with shape `(batch_size, channels, length)`.
#'
#' @param dilation_rate
#' A single integer, specifying
#' the dilation rate to use for dilated convolution.
#'
#' @param depth_multiplier
#' The number of depthwise convolution output channels for
#' each input channel. The total number of depthwise convolution output
#' channels will be equal to `num_filters_in * depth_multiplier`.
#'
#' @param activation
#' Activation function to use.
#' If you don't specify anything, no activation is applied
#' (see `keras.activations`).
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias.
#'
#' @param depthwise_initializer
#' An initializer for the depthwise convolution kernel
#' (see `keras.initializers`). If NULL, then the default initializer
#' ('glorot_uniform') will be used.
#'
#' @param pointwise_initializer
#' An initializer for the pointwise convolution kernel
#' (see `keras.initializers`). If NULL, then the default initializer
#' ('glorot_uniform') will be used.
#'
#' @param bias_initializer
#' An initializer for the bias vector. If NULL, the default
#' initializer ('zeros') will be used (see `keras.initializers`).
#'
#' @param depthwise_regularizer
#' Optional regularizer for the depthwise
#' convolution kernel (see `keras.regularizers`).
#'
#' @param pointwise_regularizer
#' Optional regularizer for the pointwise
#' convolution kernel (see `keras.regularizers`).
#'
#' @param bias_regularizer
#' Optional regularizer for the bias vector
#' (see `keras.regularizers`).
#'
#' @param activity_regularizer
#' Optional regularizer function for the output
#' (see `keras.regularizers`).
#'
#' @param depthwise_constraint
#' Optional projection function to be applied to the
#' depthwise kernel after being updated by an `Optimizer` (e.g. used for
#' norm constraints or value constraints for layer weights). The function
#' must take as input the unprojected variable and must return the
#' projected variable (which must have the same shape). Constraints are
#' not safe to use when doing asynchronous distributed training
#' (see `keras.constraints`).
#'
#' @param pointwise_constraint
#' Optional projection function to be applied to the
#' pointwise kernel after being updated by an `Optimizer`
#' (see `keras.constraints`).
#'
#' @param bias_constraint
#' Optional projection function to be applied to the
#' bias after being updated by an `Optimizer`
#' (see `keras.constraints`).
#'
#' @param trainable
#' Boolean, if `TRUE` the weights of this layer will be marked as
#' trainable (and listed in `layer.trainable_weights`).
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_separable_conv_1d <-
function(object, filters, kernel_size, strides = 1L, padding = "valid",
    data_format = NULL, dilation_rate = 1L, depth_multiplier = 1L,
    activation = NULL, use_bias = TRUE, depthwise_initializer = "glorot_uniform",
    pointwise_initializer = "glorot_uniform", bias_initializer = "zeros",
    depthwise_regularizer = NULL, pointwise_regularizer = NULL,
    bias_regularizer = NULL, activity_regularizer = NULL, depthwise_constraint = NULL,
    pointwise_constraint = NULL, bias_constraint = NULL, ...)
{
    args <- capture_args(match.call(), list(filters = as.integer,
        kernel_size = as.integer, strides = as.integer, dilation_rate = as.integer,
        depth_multiplier = as.integer, input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$SeparableConv1D, object, args)
}


# <class 'keras.src.layers.convolutional.separable_conv2d.SeparableConv2D'>
#' Depthwise separable 2D convolution
#'
#' @details
#' Separable convolutions consist of first performing
#' a depthwise spatial convolution
#' (which acts on each input channel separately)
#' followed by a pointwise convolution which mixes the resulting
#' output channels. The `depth_multiplier` argument controls how many
#' output channels are generated per input channel in the depthwise step.
#'
#' Intuitively, separable convolutions can be understood as
#' a way to factorize a convolution kernel into two smaller kernels,
#' or as an extreme version of an Inception block.
#'
#' Input shape:
#'   4D tensor with shape:
#'   `(batch_size, channels, rows, cols)` if data_format='channels_first'
#'   or 4D tensor with shape:
#'   `(batch_size, rows, cols, channels)` if data_format='channels_last'.
#'
#' Output shape:
#'   4D tensor with shape:
#'   `(batch_size, filters, new_rows, new_cols)` if
#'   data_format='channels_first'
#'   or 4D tensor with shape:
#'   `(batch_size, new_rows, new_cols, filters)` if
#'   data_format='channels_last'.  `rows` and `cols` values might have changed
#'   due to padding.
#'
#'   A tensor of rank 4 representing
#'
#' @param filters
#' Integer, the dimensionality of the output space
#' (i.e. the number of output filters in the convolution).
#'
#' @param kernel_size
#' An integer or list of 2 integers, specifying the
#' height and width of the 2D convolution window.
#' Can be a single integer to specify the same value for
#' all spatial dimensions.
#'
#' @param strides
#' An integer or list of 2 integers,
#' specifying the strides of the convolution along the height and width.
#' Can be a single integer to specify the same value for
#' all spatial dimensions. Current implementation only supports equal
#' length strides in the row and column dimensions.
#' Specifying any stride value != 1 is incompatible with specifying
#' any `dilation_rate` value != 1.
#'
#' @param padding
#' one of `"valid"` or `"same"` (case-insensitive).
#' `"valid"` means no padding. `"same"` results in padding with zeros
#' evenly to the left/right or up/down of the input such that output has
#' the same height/width dimension as the input.
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch_size, height, width, channels)` while `channels_first`
#' corresponds to inputs with shape
#' `(batch_size, channels, height, width)`.
#' When unspecified, uses `image_data_format` value found in your Keras
#' config file at `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param dilation_rate
#' An integer or list of 2 integers, specifying
#' the dilation rate to use for dilated convolution.
#'
#' @param depth_multiplier
#' The number of depthwise convolution output channels
#' for each input channel.
#' The total number of depthwise convolution output
#' channels will be equal to `filters_in * depth_multiplier`.
#'
#' @param activation
#' Activation function to use.
#' If you don't specify anything, no activation is applied
#' (see `keras.activations`).
#'
#' @param use_bias
#' Boolean, whether the layer uses a bias vector.
#'
#' @param depthwise_initializer
#' An initializer for the depthwise convolution kernel
#' (see `keras.initializers`). If NULL, then the default initializer
#' ('glorot_uniform') will be used.
#'
#' @param pointwise_initializer
#' An initializer for the pointwise convolution kernel
#' (see `keras.initializers`). If NULL, then the default initializer
#' ('glorot_uniform') will be used.
#'
#' @param bias_initializer
#' An initializer for the bias vector. If NULL, the default
#' initializer ('zeros') will be used (see `keras.initializers`).
#'
#' @param depthwise_regularizer
#' Regularizer function applied to
#' the depthwise kernel matrix (see `keras.regularizers`).
#'
#' @param pointwise_regularizer
#' Regularizer function applied to
#' the pointwise kernel matrix (see `keras.regularizers`).
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector
#' (see `keras.regularizers`).
#'
#' @param activity_regularizer
#' Regularizer function applied to
#' the output of the layer (its "activation")
#' (see `keras.regularizers`).
#'
#' @param depthwise_constraint
#' Constraint function applied to
#' the depthwise kernel matrix
#' (see `keras.constraints`).
#'
#' @param pointwise_constraint
#' Constraint function applied to
#' the pointwise kernel matrix
#' (see `keras.constraints`).
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector
#' (see `keras.constraints`).
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_separable_conv_2d <-
function(object, filters, kernel_size, strides = list(1L, 1L),
    padding = "valid", data_format = NULL, dilation_rate = list(
        1L, 1L), depth_multiplier = 1L, activation = NULL, use_bias = TRUE,
    depthwise_initializer = "glorot_uniform", pointwise_initializer = "glorot_uniform",
    bias_initializer = "zeros", depthwise_regularizer = NULL,
    pointwise_regularizer = NULL, bias_regularizer = NULL, activity_regularizer = NULL,
    depthwise_constraint = NULL, pointwise_constraint = NULL,
    bias_constraint = NULL, ...)
{
    args <- capture_args(match.call(), list(filters = as.integer,
        kernel_size = as.integer, depth_multiplier = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$SeparableConv2D, object, args)
}


# <class 'keras.src.layers.rnn.simple_rnn.SimpleRNN'>
#' Fully-connected RNN where the output is to be fed back to input
#'
#' @details
#' See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)
#' for details about the usage of RNN API.
#'
#' Call arguments:
#'   inputs: A 3D tensor, with shape `[batch, timesteps, feature]`.
#'   mask: Binary tensor of shape `[batch, timesteps]` indicating whether
#'     a given timestep should be masked. An individual `TRUE` entry indicates
#'     that the corresponding timestep should be utilized, while a `FALSE`
#'     entry indicates that the corresponding timestep should be ignored.
#'   training: Python boolean indicating whether the layer should behave in
#'     training mode or in inference mode. This argument is passed to the cell
#'     when calling it. This is only relevant if `dropout` or
#'     `recurrent_dropout` is used.
#'   initial_state: List of initial state tensors to be passed to the first
#'     call of the cell.
#'
#' ```python
#' inputs = np.random.random([32, 10, 8]).astype(np.float32)
#' simple_rnn = tf.keras.layers.SimpleRNN(4)
#'
#' output = simple_rnn(inputs)  # The output has shape `[32, 4]`.
#'
#' simple_rnn = tf.keras.layers.SimpleRNN(
#'     4, return_sequences=TRUE, return_state=TRUE)
#'
#' # whole_sequence_output has shape `[32, 10, 4]`.
#' # final_state has shape `[32, 4]`.
#' whole_sequence_output, final_state = simple_rnn(inputs)
#' ```
#'
#' @param units
#' Positive integer, dimensionality of the output space.
#'
#' @param activation
#' Activation function to use.
#' Default: hyperbolic tangent (`tanh`).
#' If you pass NULL, no activation is applied
#' (ie. "linear" activation: `a(x) = x`).
#'
#' @param use_bias
#' Boolean, (default `TRUE`), whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix,
#' used for the linear transformation of the inputs. Default:
#' `glorot_uniform`.
#'
#' @param recurrent_initializer
#' Initializer for the `recurrent_kernel`
#' weights matrix, used for the linear transformation of the recurrent
#' state.  Default: `orthogonal`.
#'
#' @param bias_initializer
#' Initializer for the bias vector. Default: `zeros`.
#'
#' @param kernel_regularizer
#' Regularizer function applied to the `kernel` weights
#' matrix. Default: `NULL`.
#'
#' @param recurrent_regularizer
#' Regularizer function applied to the
#' `recurrent_kernel` weights matrix. Default: `NULL`.
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector.
#' Default: `NULL`.
#'
#' @param activity_regularizer
#' Regularizer function applied to the output of the
#' layer (its "activation"). Default: `NULL`.
#'
#' @param kernel_constraint
#' Constraint function applied to the `kernel` weights
#' matrix. Default: `NULL`.
#'
#' @param recurrent_constraint
#' Constraint function applied to the
#' `recurrent_kernel` weights matrix.  Default: `NULL`.
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector. Default:
#' `NULL`.
#'
#' @param dropout
#' Float between 0 and 1.
#' Fraction of the units to drop for the linear transformation of the
#' inputs. Default: 0.
#'
#' @param recurrent_dropout
#' Float between 0 and 1.
#' Fraction of the units to drop for the linear transformation of the
#' recurrent state. Default: 0.
#'
#' @param return_sequences
#' Boolean. Whether to return the last output
#' in the output sequence, or the full sequence. Default: `FALSE`.
#'
#' @param return_state
#' Boolean. Whether to return the last state
#' in addition to the output. Default: `FALSE`
#'
#' @param go_backwards
#' Boolean (default FALSE).
#' If TRUE, process the input sequence backwards and return the
#' reversed sequence.
#'
#' @param stateful
#' Boolean (default FALSE). If TRUE, the last state
#' for each sample at index i in a batch will be used as initial
#' state for the sample of index i in the following batch.
#'
#' @param unroll
#' Boolean (default FALSE).
#' If TRUE, the network will be unrolled,
#' else a symbolic loop will be used.
#' Unrolling can speed-up a RNN,
#' although it tends to be more memory-intensive.
#' Unrolling is only suitable for short sequences.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_simple_rnn <-
function(object, units, activation = "tanh", use_bias = TRUE,
    kernel_initializer = "glorot_uniform", recurrent_initializer = "orthogonal",
    bias_initializer = "zeros", kernel_regularizer = NULL, recurrent_regularizer = NULL,
    bias_regularizer = NULL, activity_regularizer = NULL, kernel_constraint = NULL,
    recurrent_constraint = NULL, bias_constraint = NULL, dropout = 0,
    recurrent_dropout = 0, return_sequences = FALSE, return_state = FALSE,
    go_backwards = FALSE, stateful = FALSE, unroll = FALSE, ...)
{
    args <- capture_args(match.call(), list(units = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$SimpleRNN, object, args)
}


# <class 'keras.src.layers.rnn.simple_rnn.SimpleRNNCell'>
#' Cell class for SimpleRNN
#'
#' @details
#' See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)
#' for details about the usage of RNN API.
#'
#' This class processes one step within the whole time sequence input, whereas
#' `tf.keras.layer.SimpleRNN` processes the whole sequence.
#'
#' Call arguments:
#'   inputs: A 2D tensor, with shape of `[batch, feature]`.
#'   states: A 2D tensor with shape of `[batch, units]`, which is the state
#'     from the previous time step. For timestep 0, the initial state provided
#'     by user will be feed to cell.
#'   training: Python boolean indicating whether the layer should behave in
#'     training mode or in inference mode. Only relevant when `dropout` or
#'     `recurrent_dropout` is used.
#'
#' ```python
#' inputs = np.random.random([32, 10, 8]).astype(np.float32)
#' rnn = tf.keras.layers.RNN(tf.keras.layers.SimpleRNNCell(4))
#'
#' output = rnn(inputs)  # The output has shape `[32, 4]`.
#'
#' rnn = tf.keras.layers.RNN(
#'     tf.keras.layers.SimpleRNNCell(4),
#'     return_sequences=TRUE,
#'     return_state=TRUE)
#'
#' # whole_sequence_output has shape `[32, 10, 4]`.
#' # final_state has shape `[32, 4]`.
#' whole_sequence_output, final_state = rnn(inputs)
#' ```
#'
#' @param units
#' Positive integer, dimensionality of the output space.
#'
#' @param activation
#' Activation function to use.
#' Default: hyperbolic tangent (`tanh`).
#' If you pass `NULL`, no activation is applied
#' (ie. "linear" activation: `a(x) = x`).
#'
#' @param use_bias
#' Boolean, (default `TRUE`), whether the layer uses a bias vector.
#'
#' @param kernel_initializer
#' Initializer for the `kernel` weights matrix,
#' used for the linear transformation of the inputs. Default:
#' `glorot_uniform`.
#'
#' @param recurrent_initializer
#' Initializer for the `recurrent_kernel`
#' weights matrix, used for the linear transformation of the recurrent
#' state.  Default: `orthogonal`.
#'
#' @param bias_initializer
#' Initializer for the bias vector. Default: `zeros`.
#'
#' @param kernel_regularizer
#' Regularizer function applied to the `kernel` weights
#' matrix. Default: `NULL`.
#'
#' @param recurrent_regularizer
#' Regularizer function applied to the
#' `recurrent_kernel` weights matrix. Default: `NULL`.
#'
#' @param bias_regularizer
#' Regularizer function applied to the bias vector.
#' Default: `NULL`.
#'
#' @param kernel_constraint
#' Constraint function applied to the `kernel` weights
#' matrix. Default: `NULL`.
#'
#' @param recurrent_constraint
#' Constraint function applied to the
#' `recurrent_kernel` weights matrix. Default: `NULL`.
#'
#' @param bias_constraint
#' Constraint function applied to the bias vector. Default:
#' `NULL`.
#'
#' @param dropout
#' Float between 0 and 1. Fraction of the units to drop for the
#' linear transformation of the inputs. Default: 0.
#'
#' @param recurrent_dropout
#' Float between 0 and 1. Fraction of the units to drop
#' for the linear transformation of the recurrent state. Default: 0.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_simple_rnn_cell <-
function(units, activation = "tanh", use_bias = TRUE, kernel_initializer = "glorot_uniform",
    recurrent_initializer = "orthogonal", bias_initializer = "zeros",
    kernel_regularizer = NULL, recurrent_regularizer = NULL,
    bias_regularizer = NULL, kernel_constraint = NULL, recurrent_constraint = NULL,
    bias_constraint = NULL, dropout = 0, recurrent_dropout = 0,
    ...)
{
    args <- capture_args(match.call(), list(units = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape))
    do.call(keras$layers$SimpleRNNCell, args)
}


# <class 'keras.src.layers.activation.softmax.Softmax'>
#' Softmax activation function
#'
#' @details
#' Example without mask:
#'
#' ```python
#' >>> inp = np.asarray([[1., 2., 1.]])
#' >>> layer = tf.keras.layers.Softmax()
#' >>> layer(inp).numpy()
#' array([[0.21194157, 0.5761169 , 0.21194157]], dtype=float32)
#' >>> mask = np.asarray([[TRUE, FALSE, TRUE]], dtype=bool)
#' >>> layer(inp, mask).numpy()
#' array([[0.5, 0. , 0.5]], dtype=float32)
#' ```
#'
#' Input shape:
#'     Arbitrary. Use the keyword argument `input_shape`
#'     (list of integers, does not include the samples axis)
#'     when using this layer as the first layer in a model.
#'
#' Output shape:
#'     Same shape as the input.
#'
#' Call arguments:
#'     inputs: The inputs, or logits to the softmax layer.
#'     mask: A boolean mask of the same shape as `inputs`. The mask
#'         specifies 1 to keep and 0 to mask. Defaults to `NULL`.
#'
#'     Softmaxed output with the same shape as `inputs`.
#'
#' @param axis
#' Integer, or list of Integers, axis along which the softmax
#' normalization is applied.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_activation_softmax <-
function(object, axis = -1L, ...)
{
    args <- capture_args(match.call(), list(axis = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$Softmax, object, args)
}


# <class 'keras.src.layers.regularization.spatial_dropout1d.SpatialDropout1D'>
#' Spatial 1D version of Dropout
#'
#' @details
#' This version performs the same function as Dropout, however, it drops
#' entire 1D feature maps instead of individual elements. If adjacent frames
#' within feature maps are strongly correlated (as is normally the case in
#' early convolution layers) then regular dropout will not regularize the
#' activations and will otherwise just result in an effective learning rate
#' decrease. In this case, SpatialDropout1D will help promote independence
#' between feature maps and should be used instead.
#'
#' Call arguments:
#'   inputs: A 3D tensor.
#'   training: Python boolean indicating whether the layer should behave in
#'     training mode (adding dropout) or in inference mode (doing nothing).
#' Input shape:
#'   3D tensor with shape: `(samples, timesteps, channels)`
#' Output shape: Same as input.
#' References: - [Efficient Object Localization Using Convolutional
#'     Networks](https://arxiv.org/abs/1411.4280)
#'
#' @param rate
#' Float between 0 and 1. Fraction of the input units to drop.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_spatial_dropout_1d <-
function(object, rate, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$SpatialDropout1D, object, args)
}


# <class 'keras.src.layers.regularization.spatial_dropout2d.SpatialDropout2D'>
#' Spatial 2D version of Dropout
#'
#' @details
#' This version performs the same function as Dropout, however, it drops
#' entire 2D feature maps instead of individual elements. If adjacent pixels
#' within feature maps are strongly correlated (as is normally the case in
#' early convolution layers) then regular dropout will not regularize the
#' activations and will otherwise just result in an effective learning rate
#' decrease. In this case, SpatialDropout2D will help promote independence
#' between feature maps and should be used instead.
#'
#' Call arguments:
#'   inputs: A 4D tensor.
#'   training: Python boolean indicating whether the layer should behave in
#'     training mode (adding dropout) or in inference mode (doing nothing).
#' Input shape:
#'   4D tensor with shape: `(samples, channels, rows, cols)` if
#'     data_format='channels_first'
#'   or 4D tensor with shape: `(samples, rows, cols, channels)` if
#'     data_format='channels_last'.
#' Output shape: Same as input.
#' References: - [Efficient Object Localization Using Convolutional
#'     Networks](https://arxiv.org/abs/1411.4280)
#'
#' @param rate
#' Float between 0 and 1. Fraction of the input units to drop.
#'
#' @param data_format
#' 'channels_first' or 'channels_last'. In 'channels_first'
#' mode, the channels dimension (the depth) is at index 1, in
#' 'channels_last' mode is it at index 3. When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#' `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_spatial_dropout_2d <-
function(object, rate, data_format = NULL, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$SpatialDropout2D, object, args)
}


# <class 'keras.src.layers.regularization.spatial_dropout3d.SpatialDropout3D'>
#' Spatial 3D version of Dropout
#'
#' @details
#' This version performs the same function as Dropout, however, it drops
#' entire 3D feature maps instead of individual elements. If adjacent voxels
#' within feature maps are strongly correlated (as is normally the case in
#' early convolution layers) then regular dropout will not regularize the
#' activations and will otherwise just result in an effective learning rate
#' decrease. In this case, SpatialDropout3D will help promote independence
#' between feature maps and should be used instead.
#'
#' Call arguments:
#'   inputs: A 5D tensor.
#'   training: Python boolean indicating whether the layer should behave in
#'     training mode (adding dropout) or in inference mode (doing nothing).
#' Input shape:
#'   5D tensor with shape: `(samples, channels, dim1, dim2, dim3)` if
#'     data_format='channels_first'
#'   or 5D tensor with shape: `(samples, dim1, dim2, dim3, channels)` if
#'     data_format='channels_last'.
#' Output shape: Same as input.
#' References: - [Efficient Object Localization Using Convolutional
#'     Networks](https://arxiv.org/abs/1411.4280)
#'
#' @param rate
#' Float between 0 and 1. Fraction of the input units to drop.
#'
#' @param data_format
#' 'channels_first' or 'channels_last'. In 'channels_first'
#' mode, the channels dimension (the depth) is at index 1, in
#' 'channels_last' mode is it at index 4. When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#' `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_spatial_dropout_3d <-
function(object, rate, data_format = NULL, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$SpatialDropout3D, object, args)
}


# <class 'keras.src.layers.normalization.spectral_normalization.SpectralNormalization'>
#' Performs spectral normalization on the weights of a target layer
#'
#' @details
#' This wrapper controls the Lipschitz constant of the weights of a layer by
#' constraining their spectral norm, which can stabilize the training of GANs.
#'
#' Wrap `keras.layers.Conv2D`:
#' ```python
#' >>> x = np.random.rand(1, 10, 10, 1)
#' >>> conv2d = SpectralNormalization(tf.keras.layers.Conv2D(2, 2))
#' >>> y = conv2d(x)
#' >>> y.shape
#' TensorShape([1, 9, 9, 2])
#' ```
#'
#' Wrap `keras.layers.Dense`:
#' ```python
#' >>> x = np.random.rand(1, 10, 10, 1)
#' >>> dense = SpectralNormalization(tf.keras.layers.Dense(10))
#' >>> y = dense(x)
#' >>> y.shape
#' TensorShape([1, 10, 10, 10])
#' ```
#'
#' Reference:
#'
#' - [Spectral Normalization for GAN](https://arxiv.org/abs/1802.05957).
#'
#' @param layer
#' A `keras.layers.Layer` instance that
#' has either a `kernel` (e.g. `Conv2D`, `Dense`...)
#' or an `embeddings` attribute (`Embedding` layer).
#'
#' @param power_iterations
#' int, the number of iterations during normalization.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_spectral_normalization <-
function(object, layer, power_iterations = 1L, ...)
{
    args <- capture_args(match.call(), list(power_iterations = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$SpectralNormalization, object,
        args)
}


# <class 'keras.src.layers.rnn.stacked_rnn_cells.StackedRNNCells'>
#' Wrapper allowing a stack of RNN cells to behave as a single cell
#'
#' @details
#' Used to implement efficient stacked RNNs.
#'
#' ```python
#' batch_size = 3
#' sentence_max_length = 5
#' n_features = 2
#' new_shape = (batch_size, sentence_max_length, n_features)
#' x = tf.constant(np.reshape(np.arange(30), new_shape), dtype = tf.float32)
#'
#' rnn_cells = [tf.keras.layers.LSTMCell(128) for _ in range(2)]
#' stacked_lstm = tf.keras.layers.StackedRNNCells(rnn_cells)
#' lstm_layer = tf.keras.layers.RNN(stacked_lstm)
#'
#' result = lstm_layer(x)
#' ```
#'
#' @param cells
#' List of RNN cell instances.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_stacked_rnn_cells <-
function(cells, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape))
    do.call(keras$layers$StackedRNNCells, args)
}


# <class 'keras.src.layers.preprocessing.string_lookup.StringLookup'>
#' A preprocessing layer which maps string features to integer indices
#'
#' @details
#' This layer translates a set of arbitrary strings into integer output via a
#' table-based vocabulary lookup. This layer will perform no splitting or
#' transformation of input strings. For a layer than can split and tokenize
#' natural language, see the `tf.keras.layers.TextVectorization` layer.
#'
#' The vocabulary for the layer must be either supplied on construction or
#' learned via `adapt()`. During `adapt()`, the layer will analyze a data set,
#' determine the frequency of individual strings tokens, and create a
#' vocabulary from them. If the vocabulary is capped in size, the most frequent
#' tokens will be used to create the vocabulary and all others will be treated
#' as out-of-vocabulary (OOV).
#'
#' There are two possible output modes for the layer.
#' When `output_mode` is `"int"`,
#' input strings are converted to their index in the vocabulary (an integer).
#' When `output_mode` is `"multi_hot"`, `"count"`, or `"tf_idf"`, input strings
#' are encoded into an array where each dimension corresponds to an element in
#' the vocabulary.
#'
#' The vocabulary can optionally contain a mask token as well as an OOV token
#' (which can optionally occupy multiple indices in the vocabulary, as set
#' by `num_oov_indices`).
#' The position of these tokens in the vocabulary is fixed. When `output_mode`
#' is `"int"`, the vocabulary will begin with the mask token (if set), followed
#' by OOV indices, followed by the rest of the vocabulary. When `output_mode`
#' is `"multi_hot"`, `"count"`, or `"tf_idf"` the vocabulary will begin with
#' OOV indices and instances of the mask token will be dropped.
#'
#' For an overview and full list of preprocessing layers, see the preprocessing
#' [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).
#'
#' **Creating a lookup layer with a known vocabulary**
#'
#' This example creates a lookup layer with a pre-existing vocabulary.
#'
#' ```python
#' >>> vocab = ["a", "b", "c", "d"]
#' >>> data = tf.constant([["a", "c", "d"], ["d", "z", "b"]])
#' >>> layer = tf.keras.layers.StringLookup(vocabulary=vocab)
#' >>> layer(data)
#' <tf.Tensor: shape=(2, 3), dtype=int64, numpy=
#' array([[1, 3, 4],
#'        [4, 0, 2]])>
#' ```
#'
#' **Creating a lookup layer with an adapted vocabulary**
#'
#' This example creates a lookup layer and generates the vocabulary by
#' analyzing the dataset.
#'
#' ```python
#' >>> data = tf.constant([["a", "c", "d"], ["d", "z", "b"]])
#' >>> layer = tf.keras.layers.StringLookup()
#' >>> layer.adapt(data)
#' >>> layer.get_vocabulary()
#' ['[UNK]', 'd', 'z', 'c', 'b', 'a']
#' ```
#'
#' Note that the OOV token `"[UNK]"` has been added to the vocabulary.
#' The remaining tokens are sorted by frequency
#' (`"d"`, which has 2 occurrences, is first) then by inverse sort order.
#'
#' ```python
#' >>> data = tf.constant([["a", "c", "d"], ["d", "z", "b"]])
#' >>> layer = tf.keras.layers.StringLookup()
#' >>> layer.adapt(data)
#' >>> layer(data)
#' <tf.Tensor: shape=(2, 3), dtype=int64, numpy=
#' array([[5, 3, 1],
#'        [1, 2, 4]])>
#' ```
#'
#' **Lookups with multiple OOV indices**
#'
#' This example demonstrates how to use a lookup layer with multiple OOV
#' indices.  When a layer is created with more than one OOV index, any OOV
#' values are hashed into the number of OOV buckets, distributing OOV values in
#' a deterministic fashion across the set.
#'
#' ```python
#' >>> vocab = ["a", "b", "c", "d"]
#' >>> data = tf.constant([["a", "c", "d"], ["m", "z", "b"]])
#' >>> layer = tf.keras.layers.StringLookup(vocabulary=vocab,
#' ...                                      num_oov_indices=2)
#' >>> layer(data)
#' <tf.Tensor: shape=(2, 3), dtype=int64, numpy=
#' array([[2, 4, 5],
#'        [0, 1, 3]])>
#' ```
#'
#' Note that the output for OOV value 'm' is 0, while the output for OOV value
#' 'z' is 1. The in-vocab terms have their output index increased by 1 from
#' earlier examples (a maps to 2, etc) in order to make space for the extra OOV
#' value.
#'
#' **One-hot output**
#'
#' Configure the layer with `output_mode='one_hot'`. Note that the first
#' `num_oov_indices` dimensions in the one_hot encoding represent OOV values.
#'
#' ```python
#' >>> vocab = ["a", "b", "c", "d"]
#' >>> data = tf.constant(["a", "b", "c", "d", "z"])
#' >>> layer = tf.keras.layers.StringLookup(
#' ...     vocabulary=vocab, output_mode='one_hot')
#' >>> layer(data)
#' <tf.Tensor: shape=(5, 5), dtype=float32, numpy=
#'   array([[0., 1., 0., 0., 0.],
#'          [0., 0., 1., 0., 0.],
#'          [0., 0., 0., 1., 0.],
#'          [0., 0., 0., 0., 1.],
#'          [1., 0., 0., 0., 0.]], dtype=float32)>
#' ```
#'
#' **Multi-hot output**
#'
#' Configure the layer with `output_mode='multi_hot'`. Note that the first
#' `num_oov_indices` dimensions in the multi_hot encoding represent OOV values.
#'
#' ```python
#' >>> vocab = ["a", "b", "c", "d"]
#' >>> data = tf.constant([["a", "c", "d", "d"], ["d", "z", "b", "z"]])
#' >>> layer = tf.keras.layers.StringLookup(
#' ...     vocabulary=vocab, output_mode='multi_hot')
#' >>> layer(data)
#' <tf.Tensor: shape=(2, 5), dtype=float32, numpy=
#'   array([[0., 1., 0., 1., 1.],
#'          [1., 0., 1., 0., 1.]], dtype=float32)>
#' ```
#'
#' **Token count output**
#'
#' Configure the layer with `output_mode='count'`. As with multi_hot output,
#' the first `num_oov_indices` dimensions in the output represent OOV values.
#'
#' ```python
#' >>> vocab = ["a", "b", "c", "d"]
#' >>> data = tf.constant([["a", "c", "d", "d"], ["d", "z", "b", "z"]])
#' >>> layer = tf.keras.layers.StringLookup(
#' ...     vocabulary=vocab, output_mode='count')
#' >>> layer(data)
#' <tf.Tensor: shape=(2, 5), dtype=float32, numpy=
#'   array([[0., 1., 0., 1., 2.],
#'          [2., 0., 1., 0., 1.]], dtype=float32)>
#' ```
#'
#' **TF-IDF output**
#'
#' Configure the layer with `output_mode="tf_idf"`. As with multi_hot output,
#' the first `num_oov_indices` dimensions in the output represent OOV values.
#'
#' Each token bin will output `token_count * idf_weight`, where the idf weights
#' are the inverse document frequency weights per token. These should be
#' provided along with the vocabulary. Note that the `idf_weight` for OOV
#' values will default to the average of all idf weights passed in.
#'
#' ```python
#' >>> vocab = ["a", "b", "c", "d"]
#' >>> idf_weights = [0.25, 0.75, 0.6, 0.4]
#' >>> data = tf.constant([["a", "c", "d", "d"], ["d", "z", "b", "z"]])
#' >>> layer = tf.keras.layers.StringLookup(output_mode="tf_idf")
#' >>> layer.set_vocabulary(vocab, idf_weights=idf_weights)
#' >>> layer(data)
#' <tf.Tensor: shape=(2, 5), dtype=float32, numpy=
#'   array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],
#'          [1.0 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)>
#' ```
#'
#' To specify the idf weights for oov values, you will need to pass the entire
#' vocabularly including the leading oov token.
#'
#' ```python
#' >>> vocab = ["[UNK]", "a", "b", "c", "d"]
#' >>> idf_weights = [0.9, 0.25, 0.75, 0.6, 0.4]
#' >>> data = tf.constant([["a", "c", "d", "d"], ["d", "z", "b", "z"]])
#' >>> layer = tf.keras.layers.StringLookup(output_mode="tf_idf")
#' >>> layer.set_vocabulary(vocab, idf_weights=idf_weights)
#' >>> layer(data)
#' <tf.Tensor: shape=(2, 5), dtype=float32, numpy=
#'   array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],
#'          [1.8 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)>
#' ```
#'
#' When adapting the layer in `"tf_idf"` mode, each input sample will be
#' considered a document, and IDF weight per token will be calculated as
#' `log(1 + num_documents / (1 + token_document_count))`.
#'
#' **Inverse lookup**
#'
#' This example demonstrates how to map indices to strings using this layer.
#' (You can also use `adapt()` with `inverse=TRUE`, but for simplicity we'll
#' pass the vocab in this example.)
#'
#' ```python
#' >>> vocab = ["a", "b", "c", "d"]
#' >>> data = tf.constant([[1, 3, 4], [4, 0, 2]])
#' >>> layer = tf.keras.layers.StringLookup(vocabulary=vocab, invert=TRUE)
#' >>> layer(data)
#' <tf.Tensor: shape=(2, 3), dtype=string, numpy=
#' array([[b'a', b'c', b'd'],
#'        [b'd', b'[UNK]', b'b']], dtype=object)>
#' ```
#'
#' Note that the first index correspond to the oov token by default.
#'
#' **Forward and inverse lookup pairs**
#'
#' This example demonstrates how to use the vocabulary of a standard lookup
#' layer to create an inverse lookup layer.
#'
#' ```python
#' >>> vocab = ["a", "b", "c", "d"]
#' >>> data = tf.constant([["a", "c", "d"], ["d", "z", "b"]])
#' >>> layer = tf.keras.layers.StringLookup(vocabulary=vocab)
#' >>> i_layer = tf.keras.layers.StringLookup(vocabulary=vocab, invert=TRUE)
#' >>> int_data = layer(data)
#' >>> i_layer(int_data)
#' <tf.Tensor: shape=(2, 3), dtype=string, numpy=
#' array([[b'a', b'c', b'd'],
#'        [b'd', b'[UNK]', b'b']], dtype=object)>
#' ```
#'
#' In this example, the input value `"z"` resulted in an output of `"[UNK]"`,
#' since 1000 was not in the vocabulary - it got represented as an OOV, and all
#' OOV values are returned as `"[UNK]"` in the inverse layer. Also, note that
#' for the inverse to work, you must have already set the forward layer
#' vocabulary either directly or via `adapt()` before calling
#' `get_vocabulary()`.
#'
#' @param max_tokens
#' Maximum size of the vocabulary for this layer. This should
#' only be specified when adapting the vocabulary or when setting
#' `pad_to_max_tokens=TRUE`. If NULL, there is no cap on the size of the
#' vocabulary. Note that this size includes the OOV and mask tokens.
#' Defaults to `NULL`.
#'
#' @param num_oov_indices
#' The number of out-of-vocabulary tokens to use. If this
#' value is more than 1, OOV inputs are hashed to determine their OOV
#' value. If this value is 0, OOV inputs will cause an error when calling
#' the layer.  Defaults to `1`.
#'
#' @param mask_token
#' A token that represents masked inputs. When `output_mode` is
#' `"int"`, the token is included in vocabulary and mapped to index 0. In
#' other output modes, the token will not appear in the vocabulary and
#' instances of the mask token in the input will be dropped. If set to
#' NULL, no mask term will be added. Defaults to `NULL`.
#'
#' @param oov_token
#' Only used when `invert` is TRUE. The token to return for OOV
#' indices. Defaults to `"[UNK]"`.
#'
#' @param vocabulary
#' Optional. Either an array of strings or a string path to a
#' text file. If passing an array, can pass a list, list, 1D numpy array,
#' or 1D tensor containing the string vocbulary terms. If passing a file
#' path, the file should contain one line per term in the vocabulary. If
#' this argument is set, there is no need to `adapt()` the layer.
#'
#' @param idf_weights
#' Only valid when `output_mode` is `"tf_idf"`. A list, list,
#' 1D numpy array, or 1D tensor or the same length as the vocabulary,
#' containing the floating point inverse document frequency weights, which
#' will be multiplied by per sample term counts for the final `tf_idf`
#' weight. If the `vocabulary` argument is set, and `output_mode` is
#' `"tf_idf"`, this argument must be supplied.
#'
#' @param invert
#' Only valid when `output_mode` is `"int"`. If TRUE, this layer will
#' map indices to vocabulary items instead of mapping vocabulary items to
#' indices. Defaults to `FALSE`.
#'
#' @param output_mode
#' Specification for the output of the layer. Values can be
#' `"int"`, `"one_hot"`, `"multi_hot"`, `"count"`, or `"tf_idf"`
#' configuring the layer as follows:
#'   - `"int"`: Return the raw integer indices of the input tokens.
#'   - `"one_hot"`: Encodes each individual element in the input into an
#'     array the same size as the vocabulary, containing a 1 at the element
#'     index. If the last dimension is size 1, will encode on that
#'     dimension. If the last dimension is not size 1, will append a new
#'     dimension for the encoded output.
#'   - `"multi_hot"`: Encodes each sample in the input into a single array
#'     the same size as the vocabulary, containing a 1 for each vocabulary
#'     term present in the sample. Treats the last dimension as the sample
#'     dimension, if input shape is (..., sample_length), output shape will
#'     be (..., num_tokens).
#'   - `"count"`: As `"multi_hot"`, but the int array contains a count of
#'     the number of times the token at that index appeared in the sample.
#'   - `"tf_idf"`: As `"multi_hot"`, but the TF-IDF algorithm is applied to
#'     find the value in each token slot.
#' For `"int"` output, any shape of input and output is supported. For all
#' other output modes, currently only output up to rank 2 is supported.
#' Defaults to `"int"`
#'
#' @param pad_to_max_tokens
#' Only applicable when `output_mode` is `"multi_hot"`,
#' `"count"`, or `"tf_idf"`. If TRUE, the output will have its feature axis
#' padded to `max_tokens` even if the number of unique tokens in the
#' vocabulary is less than max_tokens, resulting in a tensor of shape
#' [batch_size, max_tokens] regardless of vocabulary size. Defaults to
#' FALSE.
#'
#' @param sparse
#' Boolean. Only applicable when `output_mode` is `"multi_hot"`,
#' `"count"`, or `"tf_idf"`. If TRUE, returns a `SparseTensor` instead of a
#' dense `Tensor`. Defaults to `FALSE`.
#'
#' @param encoding
#' Optional. The text encoding to use to interpret the input
#' strings. Defaults to `"utf-8"`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_string_lookup <-
function(object, max_tokens = NULL, num_oov_indices = 1L, mask_token = NULL,
    oov_token = "[UNK]", vocabulary = NULL, idf_weights = NULL,
    encoding = "utf-8", invert = FALSE, output_mode = "int",
    sparse = FALSE, pad_to_max_tokens = FALSE, ...)
{
    args <- capture_args(match.call(), list(num_oov_indices = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$StringLookup, object, args)
}


# <class 'keras.src.layers.merging.subtract.Subtract'>
#' Layer that subtracts two inputs
#'
#' @details
#' It takes as input a list of tensors of size 2, both of the same shape, and
#' returns a single tensor, (inputs[0] - inputs[1]), also of the same shape.
#'
#' ```python
#'     import keras.src as keras
#'
#'     input1 = keras.layers.Input(shape=(16,))
#'     x1 = keras.layers.Dense(8, activation='relu')(input1)
#'     input2 = keras.layers.Input(shape=(32,))
#'     x2 = keras.layers.Dense(8, activation='relu')(input2)
#'     # Equivalent to subtracted = keras.layers.subtract([x1, x2])
#'     subtracted = keras.layers.Subtract()([x1, x2])
#'
#'     out = keras.layers.Dense(4)(subtracted)
#'     model = keras.models.Model(inputs=[input1, input2], outputs=out)
#' ```
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_subtract <-
function(inputs, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = c("...", "inputs"))
    dots <- split_dots_named_unnamed(list(...))
    if (missing(inputs))
        inputs <- NULL
    else if (!is.null(inputs) && !is.list(inputs))
        inputs <- list(inputs)
    inputs <- c(inputs, dots$unnamed)
    args <- c(args, dots$named)
    layer <- do.call(keras$layers$Subtract, args)
    if (length(inputs))
        layer(inputs)
    else layer
}


# <class 'keras.src.layers.preprocessing.text_vectorization.TextVectorization'>
#' A preprocessing layer which maps text features to integer sequences
#'
#' @details
#' This layer has basic options for managing text in a Keras model. It
#' transforms a batch of strings (one example = one string) into either a list
#' of token indices (one example = 1D tensor of integer token indices) or a
#' dense representation (one example = 1D tensor of float values representing
#' data about the example's tokens). This layer is meant to handle natural
#' language inputs. To handle simple string inputs (categorical strings or
#' pre-tokenized strings) see `tf.keras.layers.StringLookup`.
#'
#' The vocabulary for the layer must be either supplied on construction or
#' learned via `adapt()`. When this layer is adapted, it will analyze the
#' dataset, determine the frequency of individual string values, and create a
#' vocabulary from them. This vocabulary can have unlimited size or be capped,
#' depending on the configuration options for this layer; if there are more
#' unique values in the input than the maximum vocabulary size, the most
#' frequent terms will be used to create the vocabulary.
#'
#' The processing of each example contains the following steps:
#'
#' 1. Standardize each example (usually lowercasing + punctuation stripping)
#' 2. Split each example into substrings (usually words)
#' 3. Recombine substrings into tokens (usually ngrams)
#' 4. Index tokens (associate a unique int value with each token)
#' 5. Transform each example using this index, either into a vector of ints or
#'    a dense float vector.
#'
#' Some notes on passing callables to customize splitting and normalization for
#' this layer:
#'
#' 1. Any callable can be passed to this Layer, but if you want to serialize
#'    this object you should only pass functions that are registered Keras
#'    serializables (see `tf.keras.saving.register_keras_serializable` for more
#'    details).
#' 2. When using a custom callable for `standardize`, the data received
#'    by the callable will be exactly as passed to this layer. The callable
#'    should return a tensor of the same shape as the input.
#' 3. When using a custom callable for `split`, the data received by the
#'    callable will have the 1st dimension squeezed out - instead of
#'    `[["string to split"], ["another string to split"]]`, the Callable will
#'    see `["string to split", "another string to split"]`. The callable should
#'    return a Tensor with the first dimension containing the split tokens -
#'    in this example, we should see something like `[["string", "to",
#'    "split"], ["another", "string", "to", "split"]]`. This makes the callable
#'    site natively compatible with `tf.strings.split()`.
#'
#' For an overview and full list of preprocessing layers, see the preprocessing
#' [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).
#'
#' Example:
#'
#' This example instantiates a `TextVectorization` layer that lowercases text,
#' splits on whitespace, strips punctuation, and outputs integer vocab indices.
#'
#' ```python
#' >>> text_dataset = tf.data.Dataset.from_tensor_slices(["foo", "bar", "baz"])
#' >>> max_features = 5000  # Maximum vocab size.
#' >>> max_len = 4  # Sequence length to pad the outputs to.
#' >>>
#' >>> # Create the layer.
#' >>> vectorize_layer = tf.keras.layers.TextVectorization(
#' ...  max_tokens=max_features,
#' ...  output_mode='int',
#' ...  output_sequence_length=max_len)
#' >>>
#' >>> # Now that the vocab layer has been created, call `adapt` on the
#' >>> # text-only dataset to create the vocabulary. You don't have to batch,
#' >>> # but for large datasets this means we're not keeping spare copies of
#' >>> # the dataset.
#' >>> vectorize_layer.adapt(text_dataset.batch(64))
#' >>>
#' >>> # Create the model that uses the vectorize text layer
#' >>> model = tf.keras.models.Sequential()
#' >>>
#' >>> # Start by creating an explicit input layer. It needs to have a shape of
#' >>> # (1,) (because we need to guarantee that there is exactly one string
#' >>> # input per batch), and the dtype needs to be 'string'.
#' >>> model.add(tf.keras.Input(shape=(1,), dtype=tf.string))
#' >>>
#' >>> # The first layer in our model is the vectorization layer. After this
#' >>> # layer, we have a tensor of shape (batch_size, max_len) containing
#' >>> # vocab indices.
#' >>> model.add(vectorize_layer)
#' >>>
#' >>> # Now, the model can map strings to integers, and you can add an
#' >>> # embedding layer to map these integers to learned embeddings.
#' >>> input_data = [["foo qux bar"], ["qux baz"]]
#' >>> model.predict(input_data)
#' array([[2, 1, 4, 0],
#'        [1, 3, 0, 0]])
#' ```
#'
#' Example:
#'
#' This example instantiates a `TextVectorization` layer by passing a list
#' of vocabulary terms to the layer's `__init__()` method.
#'
#' ```python
#' >>> vocab_data = ["earth", "wind", "and", "fire"]
#' >>> max_len = 4  # Sequence length to pad the outputs to.
#' >>>
#' >>> # Create the layer, passing the vocab directly. You can also pass the
#' >>> # vocabulary arg a path to a file containing one vocabulary word per
#' >>> # line.
#' >>> vectorize_layer = tf.keras.layers.TextVectorization(
#' ...  max_tokens=max_features,
#' ...  output_mode='int',
#' ...  output_sequence_length=max_len,
#' ...  vocabulary=vocab_data)
#' >>>
#' >>> # Because we've passed the vocabulary directly, we don't need to adapt
#' >>> # the layer - the vocabulary is already set. The vocabulary contains the
#' >>> # padding token ('') and OOV token ('[UNK]') as well as the passed
#' >>> # tokens.
#' >>> vectorize_layer.get_vocabulary()
#' ['', '[UNK]', 'earth', 'wind', 'and', 'fire']
#' ```
#'
#' @param max_tokens
#' Maximum size of the vocabulary for this layer. This should
#' only be specified when adapting a vocabulary or when setting
#' `pad_to_max_tokens=TRUE`. Note that this vocabulary
#' contains 1 OOV token, so the effective number of tokens is
#' `(max_tokens - 1 - (1 if output_mode == "int" else 0))`.
#'
#' @param standardize
#' Optional specification for standardization to apply to the
#' input text. Values can be:
#' - `NULL`: No standardization.
#' - `"lower_and_strip_punctuation"`: Text will be lowercased and all
#'   punctuation removed.
#' - `"lower"`: Text will be lowercased.
#' - `"strip_punctuation"`: All punctuation will be removed.
#' - Callable: Inputs will passed to the callable function, which should
#'   be standardized and returned.
#'
#' @param split
#' Optional specification for splitting the input text. Values can be:
#' - `NULL`: No splitting.
#' - `"whitespace"`: Split on whitespace.
#' - `"character"`: Split on each unicode character.
#' - Callable: Standardized inputs will passed to the callable function,
#'   which should be split and returned.
#'
#' @param ngrams
#' Optional specification for ngrams to create from the
#' possibly-split input text. Values can be NULL, an integer or list of
#' integers; passing an integer will create ngrams up to that integer, and
#' passing a list of integers will create ngrams for the specified values
#' in the list. Passing NULL means that no ngrams will be created.
#'
#' @param output_mode
#' Optional specification for the output of the layer. Values
#' can be `"int"`, `"multi_hot"`, `"count"` or `"tf_idf"`, configuring the
#' layer as follows:
#'   - `"int"`: Outputs integer indices, one integer index per split string
#'     token. When `output_mode == "int"`, 0 is reserved for masked
#'     locations; this reduces the vocab size to
#'     `max_tokens - 2` instead of `max_tokens - 1`.
#'   - `"multi_hot"`: Outputs a single int array per batch, of either
#'     vocab_size or max_tokens size, containing 1s in all elements where
#'     the token mapped to that index exists at least once in the batch
#'     item.
#'   - `"count"`: Like `"multi_hot"`, but the int array contains a count of
#'     the number of times the token at that index appeared in the
#'     batch item.
#'   - `"tf_idf"`: Like `"multi_hot"`, but the TF-IDF algorithm is applied
#'     to find the value in each token slot.
#' For `"int"` output, any shape of input and output is supported. For all
#' other output modes, currently only rank 1 inputs (and rank 2 outputs
#' after splitting) are supported.
#'
#' @param output_sequence_length
#' Only valid in INT mode. If set, the output will
#' have its time dimension padded or truncated to exactly
#' `output_sequence_length` values, resulting in a tensor of shape
#' `(batch_size, output_sequence_length)` regardless of how many tokens
#' resulted from the splitting step. Defaults to `NULL`.
#'
#' @param pad_to_max_tokens
#' Only valid in  `"multi_hot"`, `"count"`, and `"tf_idf"`
#' modes. If TRUE, the output will have its feature axis padded to
#' `max_tokens` even if the number of unique tokens in the vocabulary is
#' less than max_tokens, resulting in a tensor of shape `(batch_size,
#' max_tokens)` regardless of vocabulary size. Defaults to `FALSE`.
#'
#' @param vocabulary
#' Optional. Either an array of strings or a string path to a
#' text file. If passing an array, can pass a list, list, 1D numpy array,
#' or 1D tensor containing the string vocabulary terms. If passing a file
#' path, the file should contain one line per term in the vocabulary. If
#' this argument is set, there is no need to `adapt()` the layer.
#'
#' @param idf_weights
#' Only valid when `output_mode` is `"tf_idf"`. A list, list,
#' 1D numpy array, or 1D tensor of the same length as the vocabulary,
#' containing the floating point inverse document frequency weights, which
#' will be multiplied by per sample term counts for the final `tf_idf`
#' weight. If the `vocabulary` argument is set, and `output_mode` is
#' `"tf_idf"`, this argument must be supplied.
#'
#' @param ragged
#' Boolean. Only applicable to `"int"` output mode. If TRUE, returns
#' a `RaggedTensor` instead of a dense `Tensor`, where each sequence may
#' have a different length after string splitting. Defaults to `FALSE`.
#'
#' @param sparse
#' Boolean. Only applicable to `"multi_hot"`, `"count"`, and
#' `"tf_idf"` output modes. If TRUE, returns a `SparseTensor` instead of a
#' dense `Tensor`. Defaults to `FALSE`.
#'
#' @param encoding
#' Optional. The text encoding to use to interpret the input
#' strings. Defaults to `"utf-8"`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_text_vectorization <-
function(object, max_tokens = NULL, standardize = "lower_and_strip_punctuation",
    split = "whitespace", ngrams = NULL, output_mode = "int",
    output_sequence_length = NULL, pad_to_max_tokens = FALSE,
    vocabulary = NULL, idf_weights = NULL, sparse = FALSE, ragged = FALSE,
    encoding = "utf-8", ...)
{
    args <- capture_args(match.call(), list(max_tokens = as_nullable_integer,
        output_sequence_length = as_nullable_integer, ngrams = function(x)
        if (length(x) > 1)
            as_integer_or_integer_tuple(x)
        else as_nullable_integer(x), input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$TextVectorization, object, args)
}


# <class 'keras.src.layers.activation.thresholded_relu.ThresholdedReLU'>
#' Thresholded Rectified Linear Unit
#'
#' @details
#' It follows:
#'
#' ```
#'     f(x) = x for x > theta
#'     f(x) = 0 otherwise`
#' ```
#'
#' Input shape:
#'     Arbitrary. Use the keyword argument `input_shape`
#'     (list of integers, does not include the samples axis)
#'     when using this layer as the first layer in a model.
#'
#' Output shape:
#'     Same shape as the input.
#'
#' @param theta
#' Float >= 0. Threshold location of activation.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_activation_thresholded_relu <-
function(object, theta = 1, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$ThresholdedReLU, object, args)
}


# <class 'keras.src.layers.rnn.time_distributed.TimeDistributed'>
#' This wrapper allows to apply a layer to every temporal slice of an input
#'
#' @details
#' Every input should be at least 3D, and the dimension of index one of the
#' first input will be considered to be the temporal dimension.
#'
#' Consider a batch of 32 video samples, where each sample is a 128x128 RGB
#' image with `channels_last` data format, across 10 timesteps.
#' The batch input shape is `(32, 10, 128, 128, 3)`.
#'
#' You can then use `TimeDistributed` to apply the same `Conv2D` layer to each
#' of the 10 timesteps, independently:
#'
#' ```python
#' >>> inputs = tf.keras.Input(shape=(10, 128, 128, 3))
#' >>> conv_2d_layer = tf.keras.layers.Conv2D(64, (3, 3))
#' >>> outputs = tf.keras.layers.TimeDistributed(conv_2d_layer)(inputs)
#' >>> outputs.shape
#' TensorShape([NULL, 10, 126, 126, 64])
#' ```
#'
#' Because `TimeDistributed` applies the same instance of `Conv2D` to each of
#' the timestamps, the same set of weights are used at each timestamp.
#'
#' Call arguments:
#'   inputs: Input tensor of shape (batch, time, ...) or nested tensors,
#'     and each of which has shape (batch, time, ...).
#'   training: Python boolean indicating whether the layer should behave in
#'     training mode or in inference mode. This argument is passed to the
#'     wrapped layer (only if the layer supports this argument).
#'   mask: Binary tensor of shape `(samples, timesteps)` indicating whether
#'     a given timestep should be masked. This argument is passed to the
#'     wrapped layer (only if the layer supports this argument).
#'
#' @param layer
#' a `tf.keras.layers.Layer` instance.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_time_distributed <-
function(object, layer, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$TimeDistributed, object, args)
}


# <class 'keras.src.layers.normalization.unit_normalization.UnitNormalization'>
#' Unit normalization layer
#'
#' @details
#' Normalize a batch of inputs so that each input in the batch has a L2 norm
#' equal to 1 (across the axes specified in `axis`).
#'
#' Example:
#'
#' ```python
#' >>> data = tf.constant(np.arange(6).reshape(2, 3), dtype=tf.float32)
#' >>> normalized_data = tf.keras.layers.UnitNormalization()(data)
#' >>> print(tf.reduce_sum(normalized_data[0, :] ** 2).numpy())
#' 1.0
#' ```
#'
#' @param axis
#' Integer or list. The axis or axes to normalize across.
#' Typically, this is the features axis or axes. The left-out axes are
#' typically the batch axis or axes. `-1` is the last dimension
#' in the input. Defaults to `-1`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_unit_normalization <-
function(object, axis = -1L, ...)
{
    args <- capture_args(match.call(), list(axis = as_axis, input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$UnitNormalization, object, args)
}


# <class 'keras.src.layers.reshaping.up_sampling1d.UpSampling1D'>
#' Upsampling layer for 1D inputs
#'
#' @details
#' Repeats each temporal step `size` times along the time axis.
#'
#' ```python
#' >>> input_shape = (2, 2, 3)
#' >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)
#' >>> print(x)
#' [[[ 0  1  2]
#'   [ 3  4  5]]
#'  [[ 6  7  8]
#'   [ 9 10 11]]]
#' >>> y = tf.keras.layers.UpSampling1D(size=2)(x)
#' >>> print(y)
#' tf.Tensor(
#'   [[[ 0  1  2]
#'     [ 0  1  2]
#'     [ 3  4  5]
#'     [ 3  4  5]]
#'    [[ 6  7  8]
#'     [ 6  7  8]
#'     [ 9 10 11]
#'     [ 9 10 11]]], shape=(2, 4, 3), dtype=int64)
#' ```
#'
#' Input shape:
#'   3D tensor with shape: `(batch_size, steps, features)`.
#'
#' Output shape:
#'   3D tensor with shape: `(batch_size, upsampled_steps, features)`.
#'
#' @param size
#' Integer. Upsampling factor.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_upsampling_1d <-
function(object, size = 2L, ...)
{
    args <- capture_args(match.call(), list(size = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$UpSampling1D, object, args)
}


# <class 'keras.src.layers.reshaping.up_sampling2d.UpSampling2D'>
#' Upsampling layer for 2D inputs
#'
#' @details
#' Repeats the rows and columns of the data
#' by `size[0]` and `size[1]` respectively.
#'
#' ```python
#' >>> input_shape = (2, 2, 1, 3)
#' >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)
#' >>> print(x)
#' [[[[ 0  1  2]]
#'   [[ 3  4  5]]]
#'  [[[ 6  7  8]]
#'   [[ 9 10 11]]]]
#' >>> y = tf.keras.layers.UpSampling2D(size=(1, 2))(x)
#' >>> print(y)
#' tf.Tensor(
#'   [[[[ 0  1  2]
#'      [ 0  1  2]]
#'     [[ 3  4  5]
#'      [ 3  4  5]]]
#'    [[[ 6  7  8]
#'      [ 6  7  8]]
#'     [[ 9 10 11]
#'      [ 9 10 11]]]], shape=(2, 2, 2, 3), dtype=int64)
#' ```
#'
#' Input shape:
#'   4D tensor with shape:
#'   - If `data_format` is `"channels_last"`:
#'       `(batch_size, rows, cols, channels)`
#'   - If `data_format` is `"channels_first"`:
#'       `(batch_size, channels, rows, cols)`
#'
#' Output shape:
#'   4D tensor with shape:
#'   - If `data_format` is `"channels_last"`:
#'       `(batch_size, upsampled_rows, upsampled_cols, channels)`
#'   - If `data_format` is `"channels_first"`:
#'       `(batch_size, channels, upsampled_rows, upsampled_cols)`
#'
#' @param size
#' Int, or list of 2 integers.
#' The upsampling factors for rows and columns.
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch_size, height, width, channels)` while `channels_first`
#' corresponds to inputs with shape
#' `(batch_size, channels, height, width)`.
#' When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#'  `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param interpolation
#' A string, one of `"area"`, `"bicubic"`, `"bilinear"`,
#' `"gaussian"`, `"lanczos3"`, `"lanczos5"`, `"mitchellcubic"`,
#' `"nearest"`.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_upsampling_2d <-
function(object, size = list(2L, 2L), data_format = NULL, interpolation = "nearest",
    ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$UpSampling2D, object, args)
}


# <class 'keras.src.layers.reshaping.up_sampling3d.UpSampling3D'>
#' Upsampling layer for 3D inputs
#'
#' @details
#' Repeats the 1st, 2nd and 3rd dimensions
#' of the data by `size[0]`, `size[1]` and `size[2]` respectively.
#'
#' ```python
#' >>> input_shape = (2, 1, 2, 1, 3)
#' >>> x = tf.constant(1, shape=input_shape)
#' >>> y = tf.keras.layers.UpSampling3D(size=2)(x)
#' >>> print(y.shape)
#' (2, 2, 4, 2, 3)
#' ```
#'
#' Input shape:
#'   5D tensor with shape:
#'   - If `data_format` is `"channels_last"`:
#'       `(batch_size, dim1, dim2, dim3, channels)`
#'   - If `data_format` is `"channels_first"`:
#'       `(batch_size, channels, dim1, dim2, dim3)`
#'
#' Output shape:
#'   5D tensor with shape:
#'   - If `data_format` is `"channels_last"`:
#'       `(batch_size, upsampled_dim1, upsampled_dim2, upsampled_dim3,
#'       channels)`
#'   - If `data_format` is `"channels_first"`:
#'       `(batch_size, channels, upsampled_dim1, upsampled_dim2,
#'       upsampled_dim3)`
#'
#' @param size
#' Int, or list of 3 integers.
#' The upsampling factors for dim1, dim2 and dim3.
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`
#' while `channels_first` corresponds to inputs with shape
#' `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.
#' When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#'  `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_upsampling_3d <-
function(object, size = list(2L, 2L, 2L), data_format = NULL,
    ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$UpSampling3D, object, args)
}


# <class 'keras.src.layers.rnn.base_wrapper.Wrapper'>
#' Abstract wrapper base class
#'
#' @details
#' Wrappers take another layer and augment it in various ways.
#' Do not use this class as a layer, it is only an abstract base class.
#' Two usable wrappers are the `TimeDistributed` and `Bidirectional` wrappers.
#'
#' @param layer
#' The layer to be wrapped.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_wrapper <-
function(object, layer, ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$Wrapper, object, args)
}


# <class 'keras.src.layers.reshaping.zero_padding1d.ZeroPadding1D'>
#' Zero-padding layer for 1D input (e.g. temporal sequence)
#'
#' @details
#'
#' ```python
#' >>> input_shape = (2, 2, 3)
#' >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)
#' >>> print(x)
#' [[[ 0  1  2]
#'   [ 3  4  5]]
#'  [[ 6  7  8]
#'   [ 9 10 11]]]
#' >>> y = tf.keras.layers.ZeroPadding1D(padding=2)(x)
#' >>> print(y)
#' tf.Tensor(
#'   [[[ 0  0  0]
#'     [ 0  0  0]
#'     [ 0  1  2]
#'     [ 3  4  5]
#'     [ 0  0  0]
#'     [ 0  0  0]]
#'    [[ 0  0  0]
#'     [ 0  0  0]
#'     [ 6  7  8]
#'     [ 9 10 11]
#'     [ 0  0  0]
#'     [ 0  0  0]]], shape=(2, 6, 3), dtype=int64)
#' ```
#'
#' Input shape:
#'     3D tensor with shape `(batch_size, axis_to_pad, features)`
#'
#' Output shape:
#'     3D tensor with shape `(batch_size, padded_axis, features)`
#'
#' @param padding
#' Int, or list of int (length 2).
#' - If int:
#' How many zeros to add at the beginning and end of
#' the padding dimension (axis 1).
#' - If list of int (length 2):
#' How many zeros to add at the beginning and the end of
#' the padding dimension (`(left_pad, right_pad)`).
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_zero_padding_1d <-
function(object, padding = 1L, ...)
{
    args <- capture_args(match.call(), list(padding = as.integer,
        input_shape = normalize_shape, batch_size = as_nullable_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$ZeroPadding1D, object, args)
}


# <class 'keras.src.layers.reshaping.zero_padding2d.ZeroPadding2D'>
#' Zero-padding layer for 2D input (e.g. picture)
#'
#' @details
#' This layer can add rows and columns of zeros
#' at the top, bottom, left and right side of an image tensor.
#'
#' ```python
#' >>> input_shape = (1, 1, 2, 2)
#' >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)
#' >>> print(x)
#' [[[[0 1]
#'    [2 3]]]]
#' >>> y = tf.keras.layers.ZeroPadding2D(padding=1)(x)
#' >>> print(y)
#' tf.Tensor(
#'   [[[[0 0]
#'      [0 0]
#'      [0 0]
#'      [0 0]]
#'     [[0 0]
#'      [0 1]
#'      [2 3]
#'      [0 0]]
#'     [[0 0]
#'      [0 0]
#'      [0 0]
#'      [0 0]]]], shape=(1, 3, 4, 2), dtype=int64)
#' ```
#'
#' Input shape:
#'   4D tensor with shape:
#'   - If `data_format` is `"channels_last"`:
#'       `(batch_size, rows, cols, channels)`
#'   - If `data_format` is `"channels_first"`:
#'       `(batch_size, channels, rows, cols)`
#'
#' Output shape:
#'   4D tensor with shape:
#'   - If `data_format` is `"channels_last"`:
#'       `(batch_size, padded_rows, padded_cols, channels)`
#'   - If `data_format` is `"channels_first"`:
#'       `(batch_size, channels, padded_rows, padded_cols)`
#'
#' @param padding
#' Int, or list of 2 ints, or list of 2 lists of 2 ints.
#' - If int: the same symmetric padding
#'   is applied to height and width.
#' - If list of 2 ints:
#'   interpreted as two different
#'   symmetric padding values for height and width:
#'   `(symmetric_height_pad, symmetric_width_pad)`.
#' - If list of 2 lists of 2 ints:
#'   interpreted as
#'   `((top_pad, bottom_pad), (left_pad, right_pad))`
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch_size, height, width, channels)` while `channels_first`
#' corresponds to inputs with shape
#' `(batch_size, channels, height, width)`.
#' When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#'  `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_zero_padding_2d <-
function(object, padding = list(1L, 1L), data_format = NULL,
    ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$ZeroPadding2D, object, args)
}


# <class 'keras.src.layers.reshaping.zero_padding3d.ZeroPadding3D'>
#' Zero-padding layer for 3D data (spatial or spatio-temporal)
#'
#' @details
#'
#' ```python
#' >>> input_shape = (1, 1, 2, 2, 3)
#' >>> x = np.arange(np.prod(input_shape)).reshape(input_shape)
#' >>> y = tf.keras.layers.ZeroPadding3D(padding=2)(x)
#' >>> print(y.shape)
#' (1, 5, 6, 6, 3)
#' ```
#'
#' Input shape:
#'   5D tensor with shape:
#'   - If `data_format` is `"channels_last"`:
#'       `(batch_size, first_axis_to_pad, second_axis_to_pad,
#'       third_axis_to_pad, depth)`
#'   - If `data_format` is `"channels_first"`:
#'       `(batch_size, depth, first_axis_to_pad, second_axis_to_pad,
#'       third_axis_to_pad)`
#'
#' Output shape:
#'   5D tensor with shape:
#'   - If `data_format` is `"channels_last"`:
#'       `(batch_size, first_padded_axis, second_padded_axis,
#'       third_axis_to_pad, depth)`
#'   - If `data_format` is `"channels_first"`:
#'       `(batch_size, depth, first_padded_axis, second_padded_axis,
#'         third_axis_to_pad)`
#'
#' @param padding
#' Int, or list of 3 ints, or list of 3 lists of 2 ints.
#' - If int: the same symmetric padding
#'   is applied to height and width.
#' - If list of 3 ints:
#'   interpreted as two different
#'   symmetric padding values for height and width:
#'   `(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad)`.
#' - If list of 3 lists of 2 ints:
#'   interpreted as
#'   `((left_dim1_pad, right_dim1_pad), (left_dim2_pad,
#'     right_dim2_pad), (left_dim3_pad, right_dim3_pad))`
#'
#' @param data_format
#' A string,
#' one of `channels_last` (default) or `channels_first`.
#' The ordering of the dimensions in the inputs.
#' `channels_last` corresponds to inputs with shape
#' `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`
#' while `channels_first` corresponds to inputs with shape
#' `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.
#' When unspecified, uses
#' `image_data_format` value found in your Keras config file at
#'  `~/.keras/keras.json` (if exists) else 'channels_last'.
#' Defaults to 'channels_last'.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export
layer_zero_padding_3d <-
function(object, padding = list(1L, 1L, 1L), data_format = NULL,
    ...)
{
    args <- capture_args(match.call(), list(input_shape = normalize_shape,
        batch_size = as_nullable_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$ZeroPadding3D, object, args)
}


#' Scaled Exponential Linear Unit (SELU)
#'
#' @details
#' The Scaled Exponential Linear Unit (SELU) activation function is defined as:
#'
#' - `if x > 0: return scale * x`
#' - `if x < 0: return scale * alpha * (exp(x) - 1)`
#'
#' where `alpha` and `scale` are pre-defined constants
#' (`alpha=1.67326324` and `scale=1.05070098`).
#'
#' Basically, the SELU activation function multiplies `scale` (> 1) with the
#' output of the `tf.keras.activations.elu` function to ensure a slope larger
#' than one for positive inputs.
#'
#' The values of `alpha` and `scale` are
#' chosen so that the mean and variance of the inputs are preserved
#' between two consecutive layers as long as the weights are initialized
#' correctly (see `tf.keras.initializers.LecunNormal` initializer)
#' and the number of input units is "large enough"
#' (see reference paper for more information).
#'
#' Example Usage:
#'
#' ```python
#' >>> num_classes = 10  # 10-class problem
#' >>> model = tf.keras.Sequential()
#' >>> model.add(tf.keras.layers.Dense(64, kernel_initializer='lecun_normal',
#' ...                                 activation='selu'))
#' >>> model.add(tf.keras.layers.Dense(32, kernel_initializer='lecun_normal',
#' ...                                 activation='selu'))
#' >>> model.add(tf.keras.layers.Dense(16, kernel_initializer='lecun_normal',
#' ...                                 activation='selu'))
#' >>> model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))
#' ```
#'
#'     The scaled exponential unit activation: `scale * elu(x, alpha)`.
#'
#' Notes:
#'     - To be used together with the
#'         `tf.keras.initializers.LecunNormal` initializer.
#'     - To be used together with the dropout variant
#'         `tf.keras.layers.AlphaDropout` (not regular dropout).
#'
#' References:
#'     - [Klambauer et al., 2017](https://arxiv.org/abs/1706.02515)
#'
#' @param x
#' A tensor or variable to compute the activation function for.
#'
#' @param ... standard layer arguments.
#'
#' @seealso
#'   +  <https://keras.io/api/layers>
#' @export

#@inheritDotParams layer_activation
layer_activation_selu <-
function (object, ...)
{
    layer_activation(object, activation = "selu", ...)
}
