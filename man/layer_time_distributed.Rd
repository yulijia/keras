% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/layers.R
\name{layer_time_distributed}
\alias{layer_time_distributed}
\title{This wrapper allows to apply a layer to every temporal slice of an input}
\usage{
layer_time_distributed(object, layer, ...)
}
\arguments{
\item{layer}{a \code{tf.keras.layers.Layer} instance.}

\item{...}{standard layer arguments.}
}
\description{
This wrapper allows to apply a layer to every temporal slice of an input
}
\details{
Every input should be at least 3D, and the dimension of index one of the
first input will be considered to be the temporal dimension.

Consider a batch of 32 video samples, where each sample is a 128x128 RGB
image with \code{channels_last} data format, across 10 timesteps.
The batch input shape is \verb{(32, 10, 128, 128, 3)}.

You can then use \code{TimeDistributed} to apply the same \code{Conv2D} layer to each
of the 10 timesteps, independently:

\if{html}{\out{<div class="sourceCode python">}}\preformatted{>>> inputs = tf.keras.Input(shape=(10, 128, 128, 3))
>>> conv_2d_layer = tf.keras.layers.Conv2D(64, (3, 3))
>>> outputs = tf.keras.layers.TimeDistributed(conv_2d_layer)(inputs)
>>> outputs.shape
TensorShape([NULL, 10, 126, 126, 64])
}\if{html}{\out{</div>}}

Because \code{TimeDistributed} applies the same instance of \code{Conv2D} to each of
the timestamps, the same set of weights are used at each timestamp.
}
\seealso{
\itemize{
\item \url{https://keras.io/api/layers}
}
}
