% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/layers-convolutional.R
\name{old_layer_cropping_2d}
\alias{old_layer_cropping_2d}
\title{Cropping layer for 2D input (e.g. picture).}
\usage{
old_layer_cropping_2d(
  object,
  cropping = list(c(0L, 0L), c(0L, 0L)),
  data_format = NULL,
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
}
\arguments{
\item{cropping}{int, or list of 2 ints, or list of 2 lists of 2 ints.
\itemize{
\item If int: the same symmetric cropping is applied to width and height.
\item If list of 2 ints: interpreted as two different symmetric cropping values for
height and width: \verb{(symmetric_height_crop, symmetric_width_crop)}.
\item If list of 2 lists of 2 ints: interpreted as \verb{((top_crop, bottom_crop), (left_crop,   right_crop))}
}}

\item{data_format}{A string, one of \code{channels_last} (default) or
\code{channels_first}.  The ordering of the dimensions in the inputs.
\code{channels_last} corresponds to inputs with shape \verb{(batch_size, height, width, channels)} while \code{channels_first} corresponds to inputs with
shape \verb{(batch_size, channels, height, width)}. If left unspecified, it
uses the \code{image_data_format} value found in your Keras config file at
\verb{~/.keras/keras.json} (if exists) else 'channels_last'.
Note that the \code{channels_first} format is currently not
supported by TensorFlow on CPU. Defaults to 'channels_last'.}
}
\description{
It crops along spatial dimensions, i.e. width and height.
}
\section{Input shape}{
 4D tensor with shape:
\itemize{
\item If \code{data_format} is \code{"channels_last"}: \verb{(batch, rows, cols, channels)}
\item If \code{data_format} is \code{"channels_first"}: \verb{(batch, channels, rows, cols)}
}
}

\section{Output shape}{
 4D tensor with shape:
\itemize{
\item If \code{data_format} is \code{"channels_last"}: \verb{(batch, cropped_rows, cropped_cols, channels)}
\item If \code{data_format} is \code{"channels_first"}: \verb{(batch, channels, cropped_rows, cropped_cols)}
}
}

\seealso{
Other convolutional layers: 
\code{\link{old_layer_conv_1d_transpose}()},
\code{\link{old_layer_conv_1d}()},
\code{\link{old_layer_conv_2d_transpose}()},
\code{\link{old_layer_conv_2d}()},
\code{\link{old_layer_conv_3d_transpose}()},
\code{\link{old_layer_conv_3d}()},
\code{\link{old_layer_conv_lstm_2d}()},
\code{\link{old_layer_cropping_1d}()},
\code{\link{old_layer_cropping_3d}()},
\code{\link{old_layer_depthwise_conv_1d}()},
\code{\link{old_layer_depthwise_conv_2d}()},
\code{\link{old_layer_separable_conv_1d}()},
\code{\link{old_layer_separable_conv_2d}()},
\code{\link{old_layer_upsampling_1d}()},
\code{\link{old_layer_upsampling_2d}()},
\code{\link{old_layer_upsampling_3d}()},
\code{\link{old_layer_zero_padding_1d}()},
\code{\link{old_layer_zero_padding_2d}()},
\code{\link{old_layer_zero_padding_3d}()}
}
\concept{convolutional layers}
